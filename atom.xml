<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>林夕的部落格</title>
  
  <subtitle>惟有不相忘，可抵岁月长！</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://ellenadams.github.io/"/>
  <updated>2019-07-29T02:48:05.106Z</updated>
  <id>http://ellenadams.github.io/</id>
  
  <author>
    <name>林夕_Yume</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>存在</title>
    <link href="http://ellenadams.github.io/2019/07/29/%E5%AD%98%E5%9C%A8/"/>
    <id>http://ellenadams.github.io/2019/07/29/存在/</id>
    <published>2019-07-29T02:48:05.106Z</published>
    <updated>2019-07-29T02:48:05.106Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;存在,英译为Existence，exist，being和Presence。之于此，想和大家聊一聊关于我们所存在的意义。<br>&emsp;&emsp;曾几何时，好友萦绕，我们三三俩俩围坐一旁，可以谈论一些鸡毛蒜皮但也很有感的琐事，当如今，霓虹灯下，车水马龙的街头，我们会否倍感失落亦或是孤独？可能有人会，有人不会，孩提至今，我们所想得早已不止那些大展宏图，更多的鸡毛蒜皮，人情琐碎如淅淅沥沥的碎屑闯入我们的生活。可能，过这一辈子，也未尝达到自己的所料所想，但这些琐碎却一遍一遍的剐过你我的灵魂和肉体。<br>&emsp;&emsp;说到灵魂，有人信也有人疑虑丛生，这厮究竟存在不？当然，于当下国内的信仰上来讲，那必是不存在的，不过，人活一世，究竟所活的是个什么，诸位思考过没有？我们是为了房子，车子和金钱而活还是？其实，也全然不是，说到底，这些不过是我们存在的一种物质的体现而已，即附带品。所谓存在，不仅仅是物质的一种存在，更多的在于它的价值和影响，是一种精神和物质的双重体现。那么如此拗口的言辞对于我们，又该作何解释呢？<br><img src="https://upload-images.jianshu.io/upload_images/13935362-7543bd21f70b7716?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="天鹅"><br>&emsp;&emsp;《平凡的世界》一书，翻看了不下六七遍，最终可能看到了：对于平凡的普通人而言，即便你再去努力，这辈子也逃不过“平凡”二字，但即便如此，我们仍需要努力去追寻生命的意义！此番，很多人不解，既然努力对于我们平凡人无益，那作者呕心沥血著作此书的含义在何处？当然，存在甚至是畅销肯定有它的意义在，能够想得到孙少平也好，晓霞也罢，他们有自己的历史局限性，但不碍于故事情节的描写和感情的抒发，之所以我觉得这本书甚至是电视剧能够对我们产生如此大的影响的原因是，可能上面的总结都正确的情况下，我们还是骨感的生活的体验者，目前浮躁的社会状态下，可能更急功近利的去追寻那些表面的不堪一用的东西，而忽略了我们精神上所真正追寻的真。身边有很多一夜暴富和各种某二代的例子，我们不否认别人家庭和祖辈创造出来的这些优势，妒忌也好，愤恨也罢，实际只是多了一个谩骂者而已，于自身并没有什么益处。我们可以做得，回到当下，那当然是无论生活多么假的去欺骗你，你仍然要去相信她，去相信未来所看不见的峰回路转。<br>&emsp;&emsp;是，我们缺钱，我们缺背景，缺资源和权利……<strong>我们所缺少得在我看来更多时候是对人的能动性的相信和对自己所追求的东西的那份执着。</strong>其实觉得有一句话说得真的很对：<strong>人生最大的辜负便是配不上自己的野心，也辜负了自己所受的苦难！</strong>有一颗伟大的心纵然可喜，但真正能够去落实，做到自律的平凡人相信也肯定会拿到自己想要的。<br>&emsp;&emsp;从另外一个方面讲，你我都有一颗文艺青年的心，但却没有文艺青年的“命”！每个人梦里都是环游世界，各地旅行，什么以梦为马，随处可栖，朝九晚五，浪迹天涯……回过头，那些鸡汤只不过是我们贫瘠的精神世界里所依仗的露珠罢了。回过头，还是洗把脸，出门左拐，面朝人群，挤上西二旗的地铁吧……<br>&emsp;&emsp;记得有一天，在地坛公园散步，走过这个公园的边边角角，也看到了很多和铁生先生在《我与地坛》一文中所描述的不尽相同的地方和场景。我们在这里，别无他求，达官显贵也好，贫贱小民也罢，我们所在的依旧是这个平常的公园，有中国跤的地坛，可能让我们看到了那些老人的生生不息和昂扬斗志，很平常，也很平凡的路人围在一堆，看他们和孩子脸上依旧是满满的笑靥，所谓平凡二字，实在是逃不过也逃不脱。我们不妥协也不放弃，我们追求美好的“强迫症”和“处女心”。史铁生也好，路遥也罢，相信在他们经历了人生中最为黑暗的时刻后，或曾，他们领悟到了些许用言语描述不出来的东西，在他们的字里行间用心去听，我听到了他们的声音！<br><img src="https://upload-images.jianshu.io/upload_images/13935362-7c8f5f9d223b12dd?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="小孩"><br>&emsp;&emsp;<strong>“等有资格结婚了，我要嫁给一个很平易近人的男人，他没有大大的啤酒肚，没有地中海似的大光头，没有鸡毛蒜皮都计较的小心眼，也没有莫名其妙就爆发的坏脾气，他要喜欢运动，充满男子气，他要喜欢唱歌就算走调让我哭笑不得，他要捧着我的脸说娶到你真是我的福气。”</strong>对于这个评论最好的回复却是：<strong>“多年以后他已经被世人的奸诈狡猾刺的浑身伤痕，被生意的应酬喝出了一个大大的啤酒肚，被日夜的焦虑头发变的稀疏了，为了赚钱养家变的斤斤计较了，没有时间再去运动了，时间把他变的苍老了，他喜欢听歌却唱的走调被人嘲笑再也不开口了，他捧着你的脸你一脸嫌弃，却未曾想过，他原来就是你最爱的样子啊？”</strong>是啊，我们被时间折磨得不堪一击，面容憔悴，但希望，回过头看你，仍是那颗从未变过的对爱的心！<br><img src="https://upload-images.jianshu.io/upload_images/13935362-9a27261e6073df7d?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="青橘"><br>&emsp;&emsp;我们仍旧满怀希冀，在拼命奔跑，想要去那些想去的地方，想要和想爱的人一起，想要父母家人身康体健，想要做很多事情……因为，我们本身存在着，那就别逼逼，来都来了，做就是啦，No Excuse!!!</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&amp;emsp;&amp;emsp;存在,英译为Existence，exist，being和Presence。之于此，想和大家聊一聊关于我们所存在的意义。&lt;br&gt;&amp;emsp;&amp;emsp;曾几何时，好友萦绕，我们三三俩俩围坐一旁，可以谈论一些鸡毛蒜皮但也很有感的琐事，当如今，霓虹灯下，车
      
    
    </summary>
    
      <category term="生活感触" scheme="http://ellenadams.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E8%A7%A6/"/>
    
      <category term="感受" scheme="http://ellenadams.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E8%A7%A6/%E6%84%9F%E5%8F%97/"/>
    
    
      <category term="个人" scheme="http://ellenadams.github.io/tags/%E4%B8%AA%E4%BA%BA/"/>
    
  </entry>
  
  <entry>
    <title>为爱涅槃</title>
    <link href="http://ellenadams.github.io/2019/07/27/%E4%B8%BA%E7%88%B1%E6%B6%85%E6%A7%83/"/>
    <id>http://ellenadams.github.io/2019/07/27/为爱涅槃/</id>
    <published>2019-07-27T09:24:11.393Z</published>
    <updated>2019-07-27T09:24:11.393Z</updated>
    
    <content type="html"><![CDATA[<h1 id="为爱涅槃"><a href="#为爱涅槃" class="headerlink" title="为爱涅槃"></a>为爱涅槃</h1><p>&emsp;&emsp;这是第一次在网上发文章。说好的写一篇传记的，但到头来还是成散文咯。想念，不知从何时而蔓延，只有当失去一个人才知道习惯的种种不适和反神经效应。<br>&emsp;&emsp;不知晓我是不是属于后知后觉型，总是在漫长的时日里将自己隐藏。在外人开来，没心没肺的似乎又少了一丝深沉。在过去的这一年间，没思索过，但时至今日，每每想起，都不知是一种什么感觉，可能是在不曾深入体会后的一种纠结吧！</p><p><img src="http://mmbiz.qpic.cn/mmbiz/9gt7J3GRK3oBOctDQxHhfRkkMazX5d5n2CBErS9zgbgW20yVlXAaTDtwTsVNJS725CIlcib8ClNPRPw0RK2JkGQ/640?wx_fmt=jpeg&tp=webp&wxfrom=5" alt="image"><br>&emsp;&emsp;我选择在你爱里沉醉，而你在久长岁月后已慢慢产生了距离和比对。太过理性就是会和感性说再见，爱，究竟是何种解药，无从得知。异地，或许是最不友好的爱的方式。<br>&emsp;&emsp;为了说，到底存在与否，我奔赴山峦，走过大河。只想在，静好岁月里能够一起过午后时光。然而，不解与误会逢迎而生。不愿解释，也不愿去挣扎与煎熬。或许为爱，放手是最好的抉择。<br>&emsp;&emsp;想走过318,219,314线，共同过着青葱常在，没有打扰的旅行，但经过许久才发现计划永远赶不上变化。也没有了那些听歌和共同行走的岁月。<br>&emsp;&emsp;爱的永远是在错误的时候，不过，静好岁月，一路走来，幸好有你!</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;为爱涅槃&quot;&gt;&lt;a href=&quot;#为爱涅槃&quot; class=&quot;headerlink&quot; title=&quot;为爱涅槃&quot;&gt;&lt;/a&gt;为爱涅槃&lt;/h1&gt;&lt;p&gt;&amp;emsp;&amp;emsp;这是第一次在网上发文章。说好的写一篇传记的，但到头来还是成散文咯。想念，不知从何时而蔓延，只有当失去
      
    
    </summary>
    
      <category term="生活感触" scheme="http://ellenadams.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E8%A7%A6/"/>
    
      <category term="感受" scheme="http://ellenadams.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E8%A7%A6/%E6%84%9F%E5%8F%97/"/>
    
    
      <category term="个人" scheme="http://ellenadams.github.io/tags/%E4%B8%AA%E4%BA%BA/"/>
    
  </entry>
  
  <entry>
    <title>Flink 1.7 State Evolution</title>
    <link href="http://ellenadams.github.io/2019/07/27/flinkstateevolution/"/>
    <id>http://ellenadams.github.io/2019/07/27/flinkstateevolution/</id>
    <published>2019-07-27T06:05:49.166Z</published>
    <updated>2019-07-27T06:05:49.166Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-状态schema演变"><a href="#1-状态schema演变" class="headerlink" title="1.状态schema演变"></a>1.状态schema演变</h1><p>Apache Flink流应用程序通常设计为无限期或长时间运行。对于所有长期运行的服务，需要更新应用程序以适应不断变化的需求。对于应用程序所针对的数据schema也是如此;它们随着应用程序的发展而发展。</p><p>本章概述了如何演进状态类型的数据schema。当前的限制因不同类型和state结构(ValueState、ListState等)而不同。需要注意的是，<a href="https://ci.apache.org/projects/flink/flink-docs-master/dev/types_serialization.html" target="_blank" rel="noopener">只有在使用由Flink自己的类型序列化框架生成的状态序列化器时</a>，本章所述的信息才是与其相关的。也就是说，在声明状态时，所提供的状态描述符没有配置使用特定的类型序列化器或类型信息，在这种情况下，Flink会推断出关于状态类型的信息:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ListStateDescriptor&lt;MyPojoType&gt; descriptor =</span><br><span class="line">    <span class="keyword">new</span> ListStateDescriptor&lt;&gt;(</span><br><span class="line">        <span class="string">"state-name"</span>,</span><br><span class="line">        MyPojoType.class);</span><br><span class="line"></span><br><span class="line">checkpointedState = getRuntimeContext().getListState(descriptor);</span><br></pre></td></tr></table></figure><p>实际上，状态schema是否可以演化取决于用于读写持久状态字节的序列化器。简单地说，注册状态的schema只有在其序列化器正确支持它的情况下才能演化。这是由Flink类型序列化框架生成的序列化器透明地处理的(当前支持仅avro类型)。</p><p>如果你打算为你的状态类型实现自定义类型序列化器，并且想了解如何实现该序列化器以支持状态schema演化，请参阅<strong><em>自定义状态序列化</em></strong>一节内容。该节还包括关于状态序列化器和Flink的状态后端之间相互作用的必要内部细节，以支持状态schema演化。</p><h2 id="1-1-演化状态schema"><a href="#1-1-演化状态schema" class="headerlink" title="1.1 演化状态schema"></a>1.1 演化状态schema</h2><p>要演化给定状态类型的schema，可以采取以下步骤:</p><ol><li>为Flink流作业创建一个savepoint；</li><li>更新应用程序中的状态类型(例如，修改Avro类型schema)；</li><li>从savepoint恢复作业。在第一次访问状态时，Flink将评估schema是否根据状态而改变，并在必要时迁移状态schema。</li></ol><p>为适应更改的schema而迁移状态的过程自动地、独立地针对每个状态来进行。这个过程由Flink在内部执行，首先检查状态的新序列化器是否具有与前一个序列化器不同的序列化schema;如果是，则使用前面的序列化器将状态读入对象，并使用新的序列化器再次将状态写入字节。<br>关于迁移过程的更多细节超出了本文档的范围;请参考<strong>自定义状态序列化</strong>。</p><h2 id="1-2-状态schema支持的数据类型"><a href="#1-2-状态schema支持的数据类型" class="headerlink" title="1.2 状态schema支持的数据类型"></a>1.2 状态schema支持的数据类型</h2><p>目前，schema演化仅支持Avro。因此，如果关心状态的schema演化的话，目前建议始终对状态数据类型使用Avro。<br>计划扩展对更多复合类型(如pojo)的支持;详情请参考<a href="https://issues.apache.org/jira/browse/FLINK-10897" target="_blank" rel="noopener">FLINK-10897</a>。</p><p><strong>Avro类型</strong></p><p>Flink完全支持Avro类型状态的演进模式，只要<a href="http://avro.apache.org/docs/current/spec.html#Schema+Resolution" target="_blank" rel="noopener">Avro的schema解析规则</a>认为是与其相兼容的schema更改即可。</p><p>目前存在的一个限制是，当作业恢复时，Avro生成的用作状态类型的类不能被重新定位或具有不同的名称空间。</p><h1 id="2-自定义状态序列化"><a href="#2-自定义状态序列化" class="headerlink" title="2.自定义状态序列化"></a>2.自定义状态序列化</h1><p>在Flink 1.7之前，序列化器快照是作为TypeSerializerConfigSnapshot实现的(现在已经弃用了，将来会被删除，完全由1.7中引入的新TypeSerializerSnapshot接口替代)。此外，序列化器模式兼容性检查的职责存在于TypeSerializer中，在TypeSerializer#ensureCompatibility(TypeSerializerConfigSnapshot)方法中实现。</p><p>为了避免将来的问题，并具有迁移状态序列化器和schema的灵活性，强烈建议从旧的抽象迁移。详细信息和迁移指南我们现在开始。</p><p>此章节目标是为需要对其状态使用自定义序列化的用户提供指导方针，包括如何提供自定义状态序列化器，以及实现允许状态模式演化的序列化器的指导方针和最佳实践。<br>如果只是使用Flink自己的序列化器，那么此章节无影响。</p><h2 id="2-1-使用自定义状态序列化器"><a href="#2-1-使用自定义状态序列化器" class="headerlink" title="2.1 使用自定义状态序列化器"></a>2.1 使用自定义状态序列化器</h2><p>在注册一个托管的operator或者keyed state时，需要一个状态描述符来指定状态的名称以及关于状态类型的信息。Flink的类型序列化框架使用类型信息为状态创建适当的序列化器。</p><p>也可以完全绕过它，让Flink使用自定义序列化器来序列化托管state，只需使用自定义的TypeSerializer实现类来直接创建StateDescriptor:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">class CustomTypeSerializer extends TypeSerializer[(String, Integer)] &#123;...&#125;</span><br><span class="line"></span><br><span class="line">val descriptor = <span class="keyword">new</span> ListStateDescriptor[(String, Integer)](</span><br><span class="line">    <span class="string">"state-name"</span>,</span><br><span class="line">    <span class="keyword">new</span> CustomTypeSerializer)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">checkpointedState = getRuntimeContext.getListState(descriptor)</span><br></pre></td></tr></table></figure><h2 id="2-2-状态序列化器及schema演变"><a href="#2-2-状态序列化器及schema演变" class="headerlink" title="2.2 状态序列化器及schema演变"></a>2.2 状态序列化器及schema演变</h2><p>本节解释与状态序列化和模式演化相关的面向用户的抽象，以及Flink如何与这些抽象交互的必要内部细节。</p><p>当从保存点恢复时，Flink允许更改用于读写以前注册过地state序列化器，这样用户就不会被锁定在任何特定的序列化模式中。当状态恢复时，将为该状态注册一个新的序列化器(即与用于访问还原作业中的状态的StateDescriptor一起提供的序列化器)。这个新的序列化器可能具有与前一个序列化器不同的模式。因此，在实现状态序列化器时，除了读取/写入数据的基本逻辑之外，另一件需要记住的重要事情是如何在将来更改序列化模式。</p><p>当谈到schema时，在这种上下文中，这个术语在引用状态类型的数据模型和序列化二进制格式之间是可以互换的。一般来说，schema可以在以下几种情况下改变:</p><ol><li>状态类型的数据schema已经改变，即从用作状态类型的POJO类中添加或删除字段；</li><li>一般来说，在更改数据schema之后，需要升级序列化器的序列化格式;</li><li>序列化器的配置已经更改。</li></ol><p>为了让新的执行程序获得关于已写state schema的信息并检测它是否已更改，在获取operator的state的保存点后，需要将状态序列化器的快照与状态字节一起写入。这是一个TypeSerializerSnapshot的抽象，在下一小节中解释。</p><h3 id="2-2-1-TypeSerializerSnapshot"><a href="#2-2-1-TypeSerializerSnapshot" class="headerlink" title="2.2.1 TypeSerializerSnapshot"></a>2.2.1 TypeSerializerSnapshot</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">TypeSerializerSnapshot</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">getCurrentVersion</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">writeSnapshot</span><span class="params">(DataOuputView out)</span> <span class="keyword">throws</span> IOException</span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">readSnapshot</span><span class="params">(<span class="keyword">int</span> readVersion, DataInputView in, ClassLoader userCodeClassLoader)</span> <span class="keyword">throws</span> IOException</span>;</span><br><span class="line">    <span class="function">TypeSerializerSchemaCompatibility&lt;T&gt; <span class="title">resolveSchemaCompatibility</span><span class="params">(TypeSerializer&lt;T&gt; newSerializer)</span></span>;</span><br><span class="line">    <span class="function">TypeSerializer&lt;T&gt; <span class="title">restoreSerializer</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">TypeSerializer</span>&lt;<span class="title">T</span>&gt; </span>&#123;    </span><br><span class="line">    </span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> TypeSerializerSnapshot&lt;T&gt; <span class="title">snapshotConfiguration</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>序列化的TypeSerializerSnapshot是一个时间点信息，它作为state序列化的写schema的唯一来源，以及恢复与给定时间点相同的序列化所必需的任何附加信息。在writeSnapshot和readSnapshot方法中定义了关于在还原时作为序列化器快照应该写入和读取什么内容的逻辑。</p><p>注意，快照自己写schema时也可能需要随着时间的推移而改变(例如，当您希望向快照中添加关于序列化器的更多信息时)。为了方便实现这一点，需要对快照进行版本控制，并在getCurrentVersion方法中定义当前版本号。在还原时，当从保存点读取序列化快照时，写入快照的schema版本将提供给readSnapshot方法，以便读取实现能够处理不同的版本。</p><p>在还原时，应该在resolveSchemaCompatibility方法中实现检测新序列化schema是否更改的逻辑。当在operator的恢复执行中，使用新的序列化器再次注册以前的已注册的state时，将通过此方法将新的序列化器提供给前一个序列化器的快照。该方法返回一个TypeSerializerSchemaCompatibility，表示兼容性解析的结果，该结果可以是以下情况之一:</p><ol><li><strong>TypeSerializerSchemaCompatibility.compatible bleasis()</strong>:这个结果表明新的序列化器是兼容的，这意味着新的序列化器具有与前一个序列化器相同的schema。可能在resolveSchemaCompatibility方法中重新配置了新的序列化器，使其兼容;</li><li><strong>TypeSerializerSchemaCompatibility.compatibleAfterMigration()</strong>:这一结果表明新的序列化器有不同的序列化schema,并可以从旧模式通过使用前面的序列化器(承认旧模式)读取字节状态对象,然后重写对象回到字节与新的序列化上(承认新模式)。</li><li><strong>TypeSerializerSchemaCompatibility.incompatible()</strong>:这个结果表明新的序列化具有不同的序列化schema，但是不能从旧的schema迁移。</li></ol><p>最后一点是要在需要迁移的情况下如何获得前面的序列化方式。已经序列化的TypeSerializerSnapshot的另一个重要作用是，它作为一个工厂类来恢复之前的序列化方式。更具体地说，TypeSerializerSnapshot应该实现restoreSerializer方法来创建一个序列化实例，该实例识别前一个序列化方式的schema和配置，因此可以安全地读取前一个序列化方式编写的数据。</p><h3 id="2-2-2-Flink如何与TypeSerializer和TypeSerializerSnapshot抽象交互"><a href="#2-2-2-Flink如何与TypeSerializer和TypeSerializerSnapshot抽象交互" class="headerlink" title="2.2.2 Flink如何与TypeSerializer和TypeSerializerSnapshot抽象交互"></a>2.2.2 Flink如何与TypeSerializer和TypeSerializerSnapshot抽象交互</h3><p>最后，本节总结Flink，或者更具体地说是state后端，如何与抽象进行交互。state后端的交互略有不同，但这与状态序列化器及其序列化快照的实现是一样的。</p><p><strong>堆外state后端</strong>(例如rocksdbstatebacked)</p><ol><li>使用schema A序列化方式来注册新state</li></ol><ul><li>用于在每个state访问上读/写state的已注册的TypeSerializer;</li><li>state是在schema A中编写的;</li></ul><ol start="2"><li>取一个保存点</li></ol><ul><li>序列化快照是通过TypeSerializer#snapshotConfiguration方法提取的；</li><li>序列化器快照被写入保存点，并且状态字节已用模式A序列化了；</li></ul><ol start="3"><li>已修复的执行程序使用具有模式B的state序列化方式重新访问已恢复的状态字节；</li></ol><ul><li>恢复前一个状态序列化的快照；</li><li>状态字节在还原时不被反序列化，只加载回state后端(因此，仍然在模式A中);</li><li>在接收到新的序列化器后，通过TypeSerializer# resolveschemacompatiability将其传给已恢复的前一个序列化器的快照，以检查模式兼容性;</li></ul><ol start="4"><li>将后端中的状态字节从模式A迁移到模式B</li></ol><ul><li>如果兼容性解决方案反映schema已经更改，并且可以迁移，则执行schema迁移。识别schema A的前一个状态序列化器将通过TypeSerializerSnapshot#restoreSerializer()从序列化器快照中获得，并用于将状态字节反序列化到对象中，对象又会被新的序列化器重新编写，新的序列化器识别模式B以完成迁移。在继续处理之前，将所有被访问状态一起迁移；</li><li>如果不兼容，则状态访问将失败；</li></ul><p><strong>堆内state后端</strong>(如memorystatebacked、fsstatebacked)</p><ol><li>使用具有schema A的状态序列化器注册新状态</li></ol><ul><li>已注册的类型序列化器由状态后端维护;</li></ul><ol start="2"><li>取一个保存点，用schema A 序列化所有状态</li></ol><ul><li>序列化器快照是通过TypeSerializer#snapshotConfiguration方法提取的;</li><li>序列化器快照被写入保存点;</li><li>状态对象现在使用schema A来将序列化写入到保存点;</li></ul><ol start="3"><li>还原时，将状态反序列化为堆中的对象</li></ol><ul><li>恢复前一个状态序列化器的快照；</li><li>前面的序列化器识别schema A，它通过TypeSerializerSnapshot#restoreSerializer()从序列化器快照获得，用于将状态字节反序列化到对象；</li><li>从现在开始，所有的状态都已反序列化；</li></ul><p>4.已恢复的执行程序使用具有schema B的state序列化器重新访问以前的状态</p><ul><li>在接收到新的序列化器后，通过TypeSerializer# resolveschemacompatiability将其提供给已恢复的前一个序列化器的快照，以检查模式兼容性;</li><li>如果兼容性检查表明需要迁移，那么在这种情况下不会发生任何事情，因为对于堆后端，所有状态都已经反序列化为对象;</li><li>如果表明不兼容，则状态访问将异常失败;</li></ul><ol start="5"><li>以另一个保存点为例，使用schema B序列化所有状态</li></ol><ul><li>与步骤2相同，但现在状态字节都在模式B中。</li></ul><h2 id="2-3-实现说明和最佳实践"><a href="#2-3-实现说明和最佳实践" class="headerlink" title="2.3 实现说明和最佳实践"></a>2.3 实现说明和最佳实践</h2><p><strong>1. Flink通过用类名实例化来恢复序列化器快照</strong></p><p>序列化快照是已注册状态序列化的唯一来源，它作为保存点中读取状态的入口，为了能够恢复和访问以前的状态，必须能够恢复以前的状态序列化器的快照。</p><p>Flink通过首先实例化TypeSerializerSnapshot及其类名(与快照字节一起编写)来恢复序列化器快照。因此，为了避免意外更改类名或实例化失败，TypeSerializerSnapshot类应该:</p><ul><li>避免被实现为匿名类或嵌套类；</li><li>实体类有一个公共的空构造函数；</li></ul><p><strong>2. 避免在不同的序列化器之间共享相同的TypeSerializerSnapshot类</strong></p><p>由于schema兼容性检查要通过序列化器快照，因此让多个序列化器返回与其快照相同的TypeSerializerSnapshot类将使TypeSerializerSnapshot# resolveschemacompatiability和TypeSerializerSnapshot#restoreSerializer()方法的实现变得复杂。</p><p>这也将是一个糟糕的关注点分离;单个序列化器的schema、序列化配置以及如何恢复，应该整合到它专用的TypeSerializerSnapshot类中。</p><p><strong>3.为包含嵌套序列化器的序列化器使用CompositeSerializerSnapshot实用程序</strong></p><p>在某些情况下，类型序列化器依赖于其他嵌套的类型序列化器;以Flink的TupleSerializer为例，其中为tuple字段配置了嵌套的类型序列化器。在这种情况下，最外层序列化器的快照还应该包含嵌套序列化器的快照。</p><p>CompositeSerializerSnapshot可以专门用于这个场景。它封装了解析复合序列化器的总体模式兼容性检查结果的逻辑。关于如何使用它的示例，可以参考Flink的ListSerializerSnapshot实现。</p><h2 id="2-4-在Flink-1-7之前从废弃的序列化器快照api进行迁移"><a href="#2-4-在Flink-1-7之前从废弃的序列化器快照api进行迁移" class="headerlink" title="2.4 在Flink 1.7之前从废弃的序列化器快照api进行迁移"></a>2.4 在Flink 1.7之前从废弃的序列化器快照api进行迁移</h2><p>本节介绍如何从Flink 1.7之前的序列化器和序列化器快照迁移API。</p><p>在Flink 1.7之前，序列化器快照是作为TypeSerializerConfigSnapshot实现的(现在已经弃用了，将来会被删除，完全由新的TypeSerializerSnapshot接口替代)。此外，序列化器schema兼容性检查的职责存在于TypeSerializer中，在TypeSerializer#ensureCompatibility(TypeSerializerConfigSnapshot)方法中实现。</p><p>新旧抽象之间的另一个主要区别是，已弃用的TypeSerializerConfigSnapshot不具备实例化前一个序列化器的能力。因此，如果序列化器仍然返回TypeSerializerConfigSnapshot的子类作为其快照，则序列化器实例本身将始终使用Java序列化被写入保存点，以便在还原时可以使用上一个序列化器。这是非常不可取的，因为恢复作业是否成功取决于前一个序列化器的类的可用性，或者通常情况下，是否可以在还原时使用Java序列化读回序列化器实例。这意味着您的状态只能使用相同的序列化器，一旦您想要升级序列化器类或执行模式迁移，就会出现问题。<br>为了避免将来的问题，并具有迁移状态序列化器和模式的灵活性，强烈建议从旧的抽象迁移。这样做的步骤如下:</p><ol><li>实现TypeSerializerSnapshot的新子类。这将是序列化器的新快照；</li><li>在TypeSerializer#snapshotConfiguration()方法中，返回新的TypeSerializerSnapshot作为序列化器的序列化器快照；</li><li>从Flink 1.7之前存在的保存点恢复作业，然后再次获取保存点。注意，在此步骤中，序列化器的旧TypeSerializerConfigSnapshot必须仍然存在于类路径中，并且不能删除TypeSerializer#ensureCompatibility(TypeSerializerConfigSnapshot)方法的实现。这个过程的目的是用序列化器新实现的TypeSerializerSnapshot替换用旧保存点编写的TypeSerializerConfigSnapshot；</li><li>一旦您使用Flink 1.7获取了一个保存点，保存点将包含TypeSerializerSnapshot作为状态序列化器快照，并且序列化器实例将不再被写入保存点。现在，可以安全地从序列化器中删除旧抽象的所有实现(删除旧的TypeSerializerConfigSnapshot实现，以及从序列化器中删除TypeSerializer#ensureCompatibility(TypeSerializerConfigSnapshot))。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-状态schema演变&quot;&gt;&lt;a href=&quot;#1-状态schema演变&quot; class=&quot;headerlink&quot; title=&quot;1.状态schema演变&quot;&gt;&lt;/a&gt;1.状态schema演变&lt;/h1&gt;&lt;p&gt;Apache Flink流应用程序通常设计为无限期或长时间运
      
    
    </summary>
    
      <category term="实用技术" scheme="http://ellenadams.github.io/categories/%E5%AE%9E%E7%94%A8%E6%8A%80%E6%9C%AF/"/>
    
      <category term="Flink" scheme="http://ellenadams.github.io/categories/%E5%AE%9E%E7%94%A8%E6%8A%80%E6%9C%AF/Flink/"/>
    
    
      <category term="flink" scheme="http://ellenadams.github.io/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>6.Otter操作流程</title>
    <link href="http://ellenadams.github.io/2019/07/27/6.Otter%E6%93%8D%E4%BD%9C%E6%B5%81%E7%A8%8B/"/>
    <id>http://ellenadams.github.io/2019/07/27/6.Otter操作流程/</id>
    <published>2019-07-27T04:54:33.074Z</published>
    <updated>2019-07-27T04:54:33.074Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Otter操作流程"><a href="#Otter操作流程" class="headerlink" title="Otter操作流程"></a>Otter操作流程</h1><h2 id="1-步骤"><a href="#1-步骤" class="headerlink" title="1.步骤"></a>1.步骤</h2><ol><li>首先要去otter配置相应属性；</li><li>其次，配合数仓以及实时kafka部分建表建主题；</li><li>配置otter 从库表信息；</li><li>开启sqoop倒全量，之后otter开启倒增量；</li></ol><h2 id="2-详细流程"><a href="#2-详细流程" class="headerlink" title="2.详细流程"></a>2.详细流程</h2><ol><li>先去到从库–即自己的otter库建一张和原始表结构相同的表；</li><li>从Otter数据源部分添加master和slave节点信息，包括url,user,pwd等；</li><li>从Otter数据表部分添加master和slave表信息，schema为原始库名，其中涉及数据源部分则去选择相应的数据源；</li><li>去到canal部分，关联需要同步binlog的表信息，此步骤为第一次同步的数据库进行，配置master的url等信息；</li><li>同步管理进行channel设置，在channel下选择otter node节点，然后再去选择刚才配置好的canal信息；</li><li>添加表以及我们从Otter–&gt;kafka的程序全类名，添加的表包括源表和目标表；</li><li>先去创建好相应的主题，主题名在otter的node节点上配置或者是在ZK节点里配置，数仓部分在平台上建好相应的表；</li><li>然后开始执行hbase和hive建表脚本，之后执行sqoop倒全量数据脚本，待数据倒完后，去启动Otter导增量按钮（一般正在执行要停止时需要等到每个小时五分过后）。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Otter操作流程&quot;&gt;&lt;a href=&quot;#Otter操作流程&quot; class=&quot;headerlink&quot; title=&quot;Otter操作流程&quot;&gt;&lt;/a&gt;Otter操作流程&lt;/h1&gt;&lt;h2 id=&quot;1-步骤&quot;&gt;&lt;a href=&quot;#1-步骤&quot; class=&quot;headerli
      
    
    </summary>
    
      <category term="实用技术" scheme="http://ellenadams.github.io/categories/%E5%AE%9E%E7%94%A8%E6%8A%80%E6%9C%AF/"/>
    
      <category term="Otter" scheme="http://ellenadams.github.io/categories/%E5%AE%9E%E7%94%A8%E6%8A%80%E6%9C%AF/Otter/"/>
    
    
      <category term="Otter" scheme="http://ellenadams.github.io/tags/Otter/"/>
    
  </entry>
  
  <entry>
    <title>5.Otter常见问题</title>
    <link href="http://ellenadams.github.io/2019/07/27/5.Otter%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"/>
    <id>http://ellenadams.github.io/2019/07/27/5.Otter常见问题/</id>
    <published>2019-07-27T04:53:26.380Z</published>
    <updated>2019-07-27T04:53:26.380Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><h1 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h1><h2 id="1-canal和otter的关系？"><a href="#1-canal和otter的关系？" class="headerlink" title="1.  canal和otter的关系？"></a>1.  canal和otter的关系？</h2><p> 答： 在回答这问题之前，首先来看一张canal&amp;otter和mysql复制的类比图.<br><img src="https://upload-images.jianshu.io/upload_images/13935362-3b7e7e127a2d97c3?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></p><p>mysql的自带复制技术可分成三步：</p><ol><li>master将改变记录到二进制日志(binary log)中（这些记录叫做二进制日志事件，binary log events，可以通过show binlog events进行查看）；</li><li>slave将master的binary log events拷贝到它的中继日志(relay log)，这里是I/O thread线程.  </li><li>slave重做中继日志中的事件，将改变反映它自己的数据，这里是SQL thread线程. </li></ol><p>基于canal&amp;otter的复制技术和mysql复制类似，具有类比性.  </p><ol><li>Canal对应于I/O thread，接收Master Binary Log. </li><li>Otter对应于SQL thread，通过Canal获取Binary Log数据，执行同步插入数据库. </li></ol><p>两者的区别在于：</p><ol><li><p>otter目前嵌入式依赖canal，部署为同一个jvm，目前设计为不产生Relay Log，数据不落地. </p></li><li><p>otter目前允许自定义同步逻辑，解决各类需求.</p><p> a.  ETL转化.  比如Slave上目标表的表名，字段名，字段类型不同，字段个数不同等.</p><p> b.  异构数据库.  比如Slave可以是oracle或者其他类型的存储,nosql等.</p><p> c.  M-M部署，解决数据一致性问题</p><p> d.  基于manager部署，方便监控同步状态和管理同步任务.  </p></li></ol><h2 id="2-canal目前支持的数据库版本？"><a href="#2-canal目前支持的数据库版本？" class="headerlink" title="2.  canal目前支持的数据库版本？"></a>2.  canal目前支持的数据库版本？</h2><p>答： 支持mysql系列的5.1 ~ 5.6/5.7版本，mariadb 5/10版本.   (全面支持ROW/STATEMENT/MIXED几种binlog格式的解析)</p><h2 id="3-otter目前支持的数据库情况？"><a href="#3-otter目前支持的数据库情况？" class="headerlink" title="3.  otter目前支持的数据库情况？"></a>3.  otter目前支持的数据库情况？</h2><p>答：这里总结了一下</p><ol><li>从问题1中的图中看到，otter依赖canal解决数据库增量日志，所以会收到canal的版本支持限制，仅支持mysql系列，不支持oracle做为master库进行解析. </li><li>mysql做为master，otter只支持ROW模式的数据同步，其他两种模式不支持.  (只有ROW模式可保证数据的最终一致性)</li><li>目标库，也就是slave，可支持mysql/oracle，也就是说可以将mysql的数据同步到oracle库中，反过来不行. </li></ol><h2 id="4-otter目前存在的同步限制？"><a href="#4-otter目前存在的同步限制？" class="headerlink" title="4.  otter目前存在的同步限制？"></a>4.  otter目前存在的同步限制？</h2><p>答：这里总结了一下</p><ol><li>暂不支持无主键表同步.  (同步的表必须要有主键，无主键表update会是一个全表扫描，效率比较差)</li><li>支持部分ddl同步  (支持create table / drop table / alter table / truncate table / rename table / create index / drop index，其他类型的暂不支持，比如grant,create user,trigger等等)，同时ddl语句不支持幂等性操作，所以出现重复同步时，会导致同步挂起，可通过配置高级参数:跳过ddl异常，来解决这个问题.  </li><li>不支持带外键的记录同步.  (数据载入算法会打散事务，进行并行处理，会导致外键约束无法满足)</li><li>数据库上trigger配置慎重.  (比如源库，有一张A表配置了trigger，将A表上的变化记录到B表中，而B表也需要同步。如果目标库也有这trigger，在同步时会插入一次A表，2次B表，因为A表的同步插入也会触发trigger插入一次B表，所以有2次B表同步.)</li></ol><h2 id="5-otter同步相比于mysql的优势？"><a href="#5-otter同步相比于mysql的优势？" class="headerlink" title="5.  otter同步相比于mysql的优势？"></a>5.  otter同步相比于mysql的优势？</h2><p>答：</p><ol><li>管理&amp;运维方便.  otter为纯java开发的系统，提供web管理界面，一站式管理整个公司的数据库同步任务.  </li><li>同步效率提升.  在保证数据一致性的前提下，拆散原先Master的事务内容，基于pk hash的并发同步，可以有效提升5倍以上的同步效率. </li><li>自定义同步功能.   支持基于增量复制的前提下，定义ETL转化逻辑，完成特殊功能. </li><li>异地机房同步.   相比于mysql异地长距离机房的复制效率，比如阿里巴巴杭州和美国机房，复制可以提升20倍以上. 长距离传输时，master向slave传输binary log可能会是一个瓶颈.</li><li>双A机房同步.   目前mysql的M-M部署结构，不支持解决数据的一致性问题，基于otter的双向复制+一致性算法，可完美解决这个问题，真正实现双A机房. </li><li>特殊功能.  支持图片同步.  数据库中的一条记录，比如产品记录，会在数据库里存在一张图片的path路径，可定义规则，在同步数据的同时，将图片同步到目标.  </li></ol><h2 id="6-node-jvm内存不够用，如何解决？"><a href="#6-node-jvm内存不够用，如何解决？" class="headerlink" title="6.  node jvm内存不够用，如何解决？"></a>6.  node jvm内存不够用，如何解决？</h2><p>node出现java.lang.OutOfMemoryError : Gc overhead limit exceeded. </p><p>答：</p><p>单node建议的同步任务，建议控制下1~2wtps以下，不然内存不够用.  出现不够用时，具体的解决方案:</p><ol><li><p>调大node的-Xms,-Xmx内存设置，默认为3G,heap区大概是2GB</p></li><li><p>减少每个同步的任务内存配置.</p><p>  a. canal配置里有个内存存储buffer记录数参数，默认是32768，代表32MB的binlog，解析后在内存中会占用100MB的样子.</p><p> b. pipeline配置里有个批次大小设置，默认是6000，代表每次获取6MB左右，解析后在内存占用=并行度<em>6MB</em>3，大概也是100MB的样子. </p></li></ol><p>   所以默认参数，全速跑时，单个通道占用200MB的样子，2GB能跑几个大概能估算出来了</p><h2 id="7-源库binlog不正确，如何重置同步使用新的位点开始同步？"><a href="#7-源库binlog不正确，如何重置同步使用新的位点开始同步？" class="headerlink" title="7.  源库binlog不正确，如何重置同步使用新的位点开始同步？"></a>7.  源库binlog不正确，如何重置同步使用新的位点开始同步？</h2><p>场景：</p><ul><li>源库binlog被删除，比如出现：Could not find first log file name in binary log index file</li><li>源库binlog出现致命解析错误，比如运行过程使用了删除性质的ddl，drop table操作，导致后续binlog在解析时无法获取表结构.<br>答：</li></ul><p>首先需要理解一下canal的位置管理，主要有两个位点信息：起始位置 和 运行位置(记录最后一次正常消费的位置).   优先加载运行位置，第一次启动无运行位置，就会使用起始位置进行初始化，第一次客户端反馈了ack信号后，就会记录运行位置.   </p><p>所以重置位置的几步操作：</p><ol><li>删除运行位置.    (pipeline同步进度页面配置)<br><img src="https://upload-images.jianshu.io/upload_images/13935362-dde0cf0d79938283?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></li><li>配置起始位置.   (canal配置页面)<img src="https://upload-images.jianshu.io/upload_images/13935362-3ba8f2c4e97cc74f?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></li><li>检查是否生效.  (pipeline对应的日志)<img src="https://upload-images.jianshu.io/upload_images/13935362-12f84275aab75d52?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"><br>注意点：</li></ol><ul><li>如果日志中出现prepare to find start position just last position. 即代表是基于运行位置启动，新设置的位点并没有生效。 (此时需要检查下位点删除是否成功 或者 canal是否被多个pipeline引用，导致位点删除后，被另一个pipeline重新写入，导致新设置的位点没有生效.)</li><li>otter中使用canal，不允许pipeline共享一个canal.  otter中配置的canal即为一个instance，而otter就是为其一个client，目前canal不支持一个instance多个client的模式，会导致数据丢失，慎重. </li></ul><h2 id="8-日志列表中出现POSITIONTIMOUT后，数据进行重复同步？"><a href="#8-日志列表中出现POSITIONTIMOUT后，数据进行重复同步？" class="headerlink" title="8.  日志列表中出现POSITIONTIMOUT后，数据进行重复同步？"></a>8.  日志列表中出现POSITIONTIMOUT后，数据进行重复同步？</h2><p>答：</p><p>首先需要理解下Position超时监控，该监控主要是监控当前同步进度中的位点的最后更新时间和当前时间的差值，简单点说就是看你同步进度的位点多少时间没有更新了，超过阀值后触发该报警规则. </p><p>还有一点需要说明，同步进度中的位点只会记录一个事务的BEGIN/COMMIT位置，保证事务处理的完整性，不会记录事务中的中间位置. </p><p>几种情况下会出现同步进度位点长时间无更新：</p><ol><li>源库出现大事务，比如进行load data/ delete * from xxx，同时操作几百万/千万的数据，同步该事务数据时，位点信息一直不会被更新，比如默认超过10分钟后，就会触发Position超时监控，此时就是一个误判，触发自动恢复，又进入重新同步，然后进入死循环。</li><li>otter系统未知bug，导致系统的调度算法出现死锁，无法正常的同步数据，导致同步进度无法更新，触发该Position超时监控。此时：自动恢复的一次停用+启用同步任务，就可以恢复正常. </li><li>ps.  该Position超时监控，可以说是主要做为一种otter的系统保险机制，可以平衡一下，如果误判的影响&gt;系统bug触发的概率，可以考虑关闭Position超时监控，一般超时监控也会发出报警. </li></ol><h2 id="9-日志列表中出现miss-data-with-keys异常，同步出现挂起后又自动恢复？"><a href="#9-日志列表中出现miss-data-with-keys异常，同步出现挂起后又自动恢复？" class="headerlink" title="9.  日志列表中出现miss data with keys异常，同步出现挂起后又自动恢复？"></a>9.  日志列表中出现miss data with keys异常，同步出现挂起后又自动恢复？</h2><p>异常信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pid:2 nid:2 exception:setl:load miss data with</span><br><span class="line">keys:[MemoryPipeKey[identity=Identity[channelId=</span><br><span class="line">1,pipelineId=2,processId=4991953],time=138319000</span><br><span class="line">1987,dataType=DB_BATCH]]</span><br></pre></td></tr></table></figure><p>答：<br>   要理解该异常，需要先了解一下otter调度模型，里面SEDA中多个stage之间通过pipe进行数据交互，比如T模块完成后会将数据存到pipe中，然后通知SEDA中心，中心会通知L模块起来工作，L模块就会根据T传给中心的pipeKey去提取数据，而该异常就是当L模块根据pipeKey去提取数据时，发现数据没了。 主要原因：pipe在设计时，如果是单机传输时，会使用softReference来存储，所以当jvm内存不足时就会被GC掉，所以就会出现无数据的情况.<br>  ps. 如果miss data with keys异常非常多的时候，你就得考虑是否当前node已经超负载运行，内存不够，需要将上面的部分同步任务迁移出去。如果是偶尔的异常，那可以忽略，该异常会有自动恢复RESTART同步任务的处理。</p><h2 id="10-日志列表中出现manager异常？"><a href="#10-日志列表中出现manager异常？" class="headerlink" title="10.  日志列表中出现manager异常？"></a>10.  日志列表中出现manager异常？</h2><p>异常信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pid:2 nid:null exception:channel:can&apos;t restart by no select live node</span><br></pre></td></tr></table></figure><p>该异常代表pipelineId = 2，select模块的node没有可用的节点. </p><p>异常信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pid:-1 nid:null exception:cid:2 restart recovery successful for rid:-1</span><br></pre></td></tr></table></figure><p>该异常代表channelId = 2，成功发起了一次restart同步任务的操作. </p><p>异常信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pid:-1 nid:null exception:nid:2 is dead and restart cids:[1,2]</span><br></pre></td></tr></table></figure><p>该异常代表node id = 2，因为该node挂了，触发了channelId = 1 / 2的两个同步任务发起restart同步任务的操作.  (一种failover的机制)</p><h2 id="11-otter针对跨机房同步时如何部署？"><a href="#11-otter针对跨机房同步时如何部署？" class="headerlink" title="11.  otter针对跨机房同步时如何部署？"></a>11.  otter针对跨机房同步时如何部署？</h2><p><img src="https://upload-images.jianshu.io/upload_images/13935362-5d4c5a09467dc2cb?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"><br>几点说明：</p><ol><li>针对zookeeper observer介绍：<a href="http://zookeeper.apache.org/doc/trunk/zookeeperObservers.html" target="_blank" rel="noopener">http://zookeeper.apache.org/doc/trunk/zookeeperObservers.html</a></li><li>以上的配置主要针对机房容灾 (即允许单个机房挂了，而不影响系统可用性)，最简配置如下：<br>杭州： manager(1台) +  zookeeper(1台 standalone模式)  +  node(1..n台)<br>美国： node(1..n台).   </li><li>zookeeper的部署建议为奇数，主要是paxos算法决定了，2n偶数台的HA效果和2n-1台的效果一样，observer无这样的限制，可为偶数台. </li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[toc]&lt;/p&gt;
&lt;h1 id=&quot;常见问题&quot;&gt;&lt;a href=&quot;#常见问题&quot; class=&quot;headerlink&quot; title=&quot;常见问题&quot;&gt;&lt;/a&gt;常见问题&lt;/h1&gt;&lt;h2 id=&quot;1-canal和otter的关系？&quot;&gt;&lt;a href=&quot;#1-canal和otter的关
      
    
    </summary>
    
      <category term="实用技术" scheme="http://ellenadams.github.io/categories/%E5%AE%9E%E7%94%A8%E6%8A%80%E6%9C%AF/"/>
    
      <category term="Otter" scheme="http://ellenadams.github.io/categories/%E5%AE%9E%E7%94%A8%E6%8A%80%E6%9C%AF/Otter/"/>
    
    
      <category term="Otter" scheme="http://ellenadams.github.io/tags/Otter/"/>
    
  </entry>
  
  <entry>
    <title>4.Otter操作简介</title>
    <link href="http://ellenadams.github.io/2019/07/27/4.Otter%E6%93%8D%E4%BD%9C%E7%AE%80%E4%BB%8B/"/>
    <id>http://ellenadams.github.io/2019/07/27/4.Otter操作简介/</id>
    <published>2019-07-27T04:52:50.670Z</published>
    <updated>2019-07-27T04:52:50.670Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Adminguide"><a href="#Adminguide" class="headerlink" title="Adminguide"></a>Adminguide</h1><h1 id="1-几点说明"><a href="#1-几点说明" class="headerlink" title="1.几点说明"></a>1.几点说明</h1><p>otter系统自带了manager，所以简化了一些admin管理上的操作成本，比如可以通过manager发布同步任务配置，接收同步任务反馈的状态信息等。</p><p>目前manager的操作可分为两部分：</p><ul><li>同步配置管理</li></ul><ol><li>添加数据源</li><li>canal解析配置</li><li>添加数据表</li><li>同步任务</li></ol><ul><li>同步状态查询</li></ul><ol><li>查询延迟</li><li>查询吞吐量</li><li>查询同步进度</li><li>查询报警&amp;异常日志</li></ol><p>manager的用户权限在设计的时候，主要分为三类：</p><ul><li>ADMIN : 超级管理员</li><li>OPERATOR : 普通用户，管理某个同步任务下的同步配置，添加数据表，修改canal配置等</li><li>ANONYMOUS : 匿名用户，只能进行同步状态查询的操作.</li></ul><h1 id="2-Manager配置介绍"><a href="#2-Manager配置介绍" class="headerlink" title="2.Manager配置介绍"></a>2.Manager配置介绍</h1><p>deep edited this page on 19 Dec 2017 · 7 revisions</p><h2 id="2-1-操作演示"><a href="#2-1-操作演示" class="headerlink" title="2.1 操作演示"></a>2.1 操作演示</h2><p>演示视频（5分钟教你配置一个同步任务）：请点击图片或者这里<br><a href="http://www.tudou.com/programs/view/Q-qnCg7d-ew" target="_blank" rel="noopener"><img src="https://upload-images.jianshu.io/upload_images/13935362-6cd59f2a2589a445.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="ScreenShot"></a><br>演示说明：</p><ol><li>搭建一个数据库同步任务，源数据库ip为：10.20.144.25，目标数据库ip为：10.20.144.29. 源数据库已开启binlog，并且binlog_format为ROW.</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like &apos;%binlog_format%&apos;;</span><br><span class="line">+---------------+-------+</span><br><span class="line">| Variable_name | Value |</span><br><span class="line">+---------------+-------+</span><br><span class="line">| binlog_format | ROW   |</span><br><span class="line">+---------------+-------+</span><br></pre></td></tr></table></figure><ol start="2"><li><p>数据同步精确到一张表进行测试，测试的表名为test.example，简单包含两个子段，测试过程中才创建.</p></li><li><p>配置完成后，手动在源库插入数据，然后快速在目标库进行查看数据，验证数据是否同步成功.</p></li></ol><hr><p>视频中的演示文本：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE  `test`.`example` (</span><br><span class="line">  `id` int(11)  NOT NULL AUTO_INCREMENT,</span><br><span class="line">  `name` varchar(32) COLLATE utf8_bin DEFAULT NULL ,</span><br><span class="line">   PRIMARY KEY (`ID`)</span><br><span class="line">) ENGINE=InnoDB DEFAULT CHARSET=utf8;</span><br><span class="line"></span><br><span class="line">insert into test.example(id,name) values(null,&apos;hello&apos;);</span><br><span class="line"></span><br><span class="line">-----</span><br><span class="line">Otter QuickStart 如何配置一个任务</span><br><span class="line">-----</span><br><span class="line">操作步骤：</span><br><span class="line">1.  添加数据库</span><br><span class="line">    a.  源库 jdbc:mysql://10.20.144.25:3306</span><br><span class="line">    b.  目标库 jdbc:mysql://10.20.144.29:3306</span><br><span class="line">2.  添加canal</span><br><span class="line">    a.  提供数据库ip信息 </span><br><span class="line">3.  添加同步表信息</span><br><span class="line">    a.  源数据表 test.example</span><br><span class="line">    b.  目标数据表 test.example</span><br><span class="line">4.  添加channel</span><br><span class="line">5.  添加pipeline</span><br><span class="line">    a.  选择node节点</span><br><span class="line">    b.  选择canal</span><br><span class="line">6.  添加同步映射规则</span><br><span class="line">    a.  定义源表和目标表的同步关系</span><br><span class="line">7.  启动</span><br><span class="line">8.  测试数据</span><br></pre></td></tr></table></figure><h2 id="2-2-通道配置说明"><a href="#2-2-通道配置说明" class="headerlink" title="2.2 通道配置说明"></a>2.2 通道配置说明</h2><h3 id="2-2-1-多种同步方式配置"><a href="#2-2-1-多种同步方式配置" class="headerlink" title="2.2.1 多种同步方式配置"></a>2.2.1 多种同步方式配置</h3><h4 id="a-单向同步"><a href="#a-单向同步" class="headerlink" title="a. 单向同步"></a>a. 单向同步</h4><p>单向同步为最基本的同步方式，目前支持mysql -&gt; mysql/oracle的同步.</p><p>基本配置方式就如操作视频中所演示的，操作步骤：</p><p>配置一个channel<br>配置一个pipeline<br>对应node机器选择时，建议遵循：S/E节点选择node需尽可能离源数据库近，T/L节点选择node则离目标数据库近. 如果无法提供双节点，则选择离目标数据库近的node节点相对合适.<br>配置一个canal<br>定义映射关系.<br>canal中配置解析的数据库ip需要和映射关系中源表对应的数据库ip一致. ps. 映射关系进行匹配的时候是基于表名，虽然数据库ip不匹配也会是有效.</p><h4 id="b-双向同步"><a href="#b-双向同步" class="headerlink" title="b. 双向同步"></a>b. 双向同步</h4><p>双向同步可以理解为两个单向同步的组合，但需要额外处理避免回环同步. 回环同步算法： Otter双向回环控制 .</p><p>同时，因为双向回环控制算法会依赖一些系统表，需要在需要做双向同步的数据库上初始化所需的系统表.</p><p>获取初始sql:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://raw.github.com/alibaba/otter/master/node/deployer/src/main/resources/sql/otter-system-ddl-mysql.sql</span><br></pre></td></tr></table></figure><p>配置上相比于单向同步有一些不同，操作步骤：</p><p>配置一个channel<br>配置两个pipeline<br>注意：两个单向的canal和映射配置，在一个channel下配置为两个pipeline. 如果是两个channel，每个channel一个pipeline，将不会使用双向回环控制算法，也就是会有重复回环同步.<br>每个pipeline各自配置canal，定义映射关系</p><h4 id="c-双A同步"><a href="#c-双A同步" class="headerlink" title="c. 双A同步"></a>c. 双A同步</h4><p>双A同步相比于双向同步，主要区别是双A机房会在两地修改同一条记录，而双向同步只是两地的数据做互相同步，两地修改的数据内容无交集.</p><p>所以双A同步需要额外处理数据同步一致性问题. 同步一致性算法：Otter数据一致性 ，目前开源版本主要是提供了单向回环补救的一致性方案.</p><p>双A同步相比于双向同步，整个配置主要是一些参数上有变化，具体步骤：</p><ol><li>配置一个channel<br><img src="https://upload-images.jianshu.io/upload_images/13935362-83a13f782fb4822b?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></li><li>配置两个pipeline<br><img src="https://upload-images.jianshu.io/upload_images/13935362-dbee08c03f83a936?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></li></ol><ul><li>注意：除了需要定义一个主站点外，需要在高级设置中将一个pipeline的“支持DDL”设置为false，另一个设置为true，否则将提示“一个channel中只允许开启单向ddl同步!”错误<br>每个pipeline各自配置canal，定义映射关系</li></ul><h4 id="d-级联同步"><a href="#d-级联同步" class="headerlink" title="d. 级联同步"></a>d. 级联同步</h4><p>单向同步/双向同步，都是针对一个channel下的多pipeline配置进行控制，是否可以使用多个channel完成类似级联同步的功能.</p><p>几种级联同步.</p><ul><li>A-&gt;B-&gt;C ，A单向同步到B，B再单向同步到C</li><li>A&lt;-&gt;B-&gt;C，A和B组成一个双向，B再单向同步到C</li><li>A&lt;-&gt;B&lt;-C，A和B组成一个双向，C将数据单向同步B，也就是B是一个接受多M同步写入的的节点，目前mysql不支持</li><li>A&lt;-&gt;B-&gt;C，B-/-&gt;D，A和B组成一个双向，B再单向同步到C，但A同步到B的数据不同步到D，但B地写入的数据同步到D，目前mysql不支持.<br>对应操作步骤：</li></ul><ol><li>目前channel之间的级联同步，不需要设置任何参数，只要通过canal进行binlog解析即可.</li><li>针对级联屏蔽同步，需要利用到自定义同步标记的功能，比如A-&gt;B，B同步到C但不同步到D。需要在A-&gt;B的同步高级参数里定义NOT_DDD，然后在B同步到D的高级参数里也定义NOT_DDD. </li><li>原理：这样在B解析到A-&gt;B写入的同步标记为NOT_DDD，与当前同步定义的NOT_DDD进行匹配，就会忽略此同步.<img src="https://upload-images.jianshu.io/upload_images/13935362-64f51582fea708d0?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></li></ol><h4 id="e-多A同步"><a href="#e-多A同步" class="headerlink" title="e. 多A同步"></a>e. 多A同步</h4><p>基于以上的单向/双向/双A/级联同步，可以随意搭建出多A同步，不过目前受限于同步数据的一致性算法，只能通过星形辐射，通过级联同步的方式保证全局多A机房的数据一致性.<br>比如图中B和C之前的一致性同步，需要通过主站点A来保证.</p><h3 id="2-2-2-自定义数据同步-自-由-门"><a href="#2-2-2-自定义数据同步-自-由-门" class="headerlink" title="2.2.2 自定义数据同步(自 由 门)"></a>2.2.2 自定义数据同步(自 由 门)</h3><p>主要功能是在不修改原始表数据的前提下，触发一下数据表中的数据同步。</p><p>可用于：</p><ul><li>同步数据订正</li><li>全量数据同步. (自 由 门触发全量，同时otter增量同步，需要配置为行记录模式，避免update时因目标库不存在记录而丢失update操作)<br>主要原理：</li></ul><p>a. 基于otter系统表retl_buffer，插入特定的数据，包含需要同步的表名，pk信息。</p><p>b. otter系统感知后会根据表名和pk提取对应的数据(整行记录)，和正常的增量同步一起同步到目标库。</p><p>目前otter系统感知的自 由 门数据方式为：</p><ul><li>日志记录. (插入表数据的每次变更，需要开启binlog，otter获取binlog数据，提取同步的表名，pk信息，然后回表查询整行记录)<br>retl_buffer表结构：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE retl_buffer </span><br><span class="line">   (    </span><br><span class="line">    ID BIGINT AUTO_INCREMENT,   ## 无意义，自增即可</span><br><span class="line">    TABLE_ID INT(11) NOT NULL,   ## tableId, 可通过该链接查询：http://otter.alibaba-inc.com/data_media_list.htm，即序号这一列，如果配置的是正则，需要指定full_name，当前table_id设置为0. </span><br><span class="line">    FULL_NAME varchar(512),  ## schemaName + &apos;.&apos; +  tableName  (如果明确指定了table_id，可以不用指定full_name)</span><br><span class="line">    TYPE CHAR(1) NOT NULL,   ## I/U/D ，分别对应于insert/update/delete</span><br><span class="line">    PK_DATA VARCHAR(256) NOT NULL, ## 多个pk之间使用char(1)进行分隔</span><br><span class="line">    GMT_CREATE TIMESTAMP NOT NULL, ## 无意义，系统时间即可</span><br><span class="line">    GMT_MODIFIED TIMESTAMP NOT NULL,  ## 无意义，系统时间即可</span><br><span class="line">    CONSTRAINT RETL_BUFFER_ID PRIMARY KEY (ID) </span><br><span class="line">   )  ENGINE=InnoDB DEFAULT CHARSET=utf8;</span><br></pre></td></tr></table></figure><p>全量同步操作示例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">insert into retl.retl_buffer(ID,TABLE_ID,</span><br><span class="line">FULL_NAME,TYPE,PK_DATA,GMT_CREATE,GMT_MODIFIED)</span><br><span class="line">(select null,0,&apos;$schema.table$&apos;,&apos;I&apos;,id,now(),now</span><br><span class="line">() from $schema.table$);</span><br></pre></td></tr></table></figure><p>如果针对多主键时，对应的PK_DATA需要将需要同步表几个主键按照(char)1进行拼接,比如 concat(id,char(1),name)</p><h2 id="2-3-具体参数详解"><a href="#2-3-具体参数详解" class="headerlink" title="2.3 具体参数详解"></a>2.3 具体参数详解</h2><h3 id="2-3-1-channel参数"><a href="#2-3-1-channel参数" class="headerlink" title="2.3.1 channel参数"></a>2.3.1 channel参数</h3><ol><li>同步一致性. ==&gt; 基于数据库反查(根据binlog反查数据库)，基于当前变更(binlog数据)。针对数据库反查，在延迟比较大时比较有效，可将最新的版本快速同步到目标，但会对源库有压力.</li><li>同步模式. ==&gt; 行模式，列模式。行模式特点：如果目标库不存在记录时，执行插入。列模式主要是变更哪个字段，只会单独修改该字段，在双Ａ同步时，为减少数据冲突，建议选择列模式。</li><li>是否开启数据一致性. ==&gt;　请查看数据一致性文档：Otter数据一致性<br>a. 数据一致性算法<br>b. 一致性反查数据库延迟阀值</li></ol><h3 id="2-3-2-pipeline参数"><a href="#2-3-2-pipeline参数" class="headerlink" title="2.3.2 pipeline参数"></a>2.3.2 pipeline参数</h3><ol><li>并行度. ==&gt; 查看文档：Otter调度模型，主要是并行化调度参数.(滑动窗口大小)</li><li>数据反查线程数. ==&gt; 如果选择了同步一致性为反查数据库，在反查数据库时的并发线程数大小</li><li>数据载入线程数. ==&gt; 在目标库执行并行载入算法时并发线程数大小</li><li>文件载入线程数. ==&gt; 数据带文件同步时处理的并发线程数大小</li><li>主站点. ==&gt; 双Ａ同步中的主站点设置　</li><li>消费批次大小. ==&gt; 获取canal数据的batchSize参数</li><li>获取批次超时时间. ==&gt; 获取canal数据的timeout参数<br>pipeline 高级设置</li></ol><ul><li>使用batch. ==&gt; 是否使用jdbc batch提升效率，部分分布式数据库系统不一定支持batch协议</li><li>跳过load异常. ==&gt; 比如同步时出现目标库主键冲突，开启该参数后，可跳过数据库执行异常</li><li>仲裁器调度模式. ==&gt; 查看文档：Otter调度模型</li><li>负载均衡算法. ==&gt; 查看文档：Otter调度模型</li><li>传输模式. ==&gt; 多个node节点之间的传输方式，RPC或HTTP. HTTP主要就是使用aria2c，如果测试环境不装aria2c，可强制选择为RPC</li><li>记录selector日志. ==&gt; 是否记录简单的canal抓取binlog的情况</li><li>记录selector详细日志. ==&gt; 是否记录canal抓取binlog的数据详细内容</li><li>记录load日志. ==&gt; 是否记录otter同步数据详细内容</li><li>dryRun模式. ==&gt; 只记录load日志，不执行真实同步到数据库的操作</li><li>支持ddl同步. ==&gt; 是否同步ddl语句</li><li>是否跳过ddl异常. ==&gt; 同步ddl出错时，是否自动跳过</li><li>文件重复同步对比 ==&gt; 数据带文件同步时，是否需要对比源和目标库的文件信息，如果文件无变化，则不同步，减少网络传输量.</li><li>文件传输加密 ==&gt; 基于HTTP协议传输时，对应文件数据是否需要做加密处理</li><li>启用公网同步 ==&gt; 每个node节点都会定义一个外部ip信息，如果启用公网同步，同步时数据传递会依赖外部ip.</li><li>跳过自 由 门数据 ==&gt; 自定义数据同步的内容</li><li>跳过反查无记录数据 ==&gt; 反查记录不存在时，是否需要进行忽略处理，不建议开启.</li><li>启用数据表类型转化 ==&gt; 源库和目标库的字段类型不匹配时，开启改功能，可自动进行字段类型转化</li><li>兼容字段新增同步 ==&gt; 同步过程中，源库新增了一个字段(必须无默认值)，而目标库还未增加，是否需要兼容处理</li><li>自定义同步标记 ==&gt; 级联同步中屏蔽同步的功能.</li></ul><h3 id="2-3-3-Canal参数"><a href="#2-3-3-Canal参数" class="headerlink" title="2.3.3 Canal参数"></a>2.3.3 Canal参数</h3><ol><li>数据源信息:<br> 单库配置： 10.20.144.34:3306;<br> 多库合并配置： 10.20.144.34:3306,10.20.144.35:3306; (逗号分隔)<br>主备库配置：10.20.144.34:3306;10.20.144.34:3307; (分号分隔)</li><li>数据库帐号</li><li>数据库密码</li><li>connectionCharset ==&gt; 获取binlog时指定的编码</li><li>位点自定义设置 ==&gt; 格式：{“journalName”:””,”position”:0,”timestamp”:0};<br>指定位置：{“journalName”:””,”position”:0};<br>指定时间：{“timestamp”:0};</li><li>内存存储batch获取模式　==&gt; MEMSIZE/ITEMSIZE，前者为内存控制，后者为数量控制. 　针对MEMSIZE模式的内存大小计算 = 记录数 * 记录单元大小</li><li>内存存储buffer记录数</li><li>内存存储buffer记录单元大小</li><li>HA机制</li><li>心跳SQL配置 ==&gt; 可配置对应心跳SQL，如果配置 是否启用心跳HA，当心跳ＳＱＬ检测失败后，canal就会自动进行主备切换.</li></ol><h3 id="2-3-4-Node参数"><a href="#2-3-4-Node参数" class="headerlink" title="2.3.4 Node参数"></a>2.3.4 Node参数</h3><ol><li>机器名称 ==&gt; 自定义名称，方便记忆</li><li>机器ip ==&gt; 机器外部可访问的ip，不能选择127.0.0.1</li><li>机器端口 ==&gt; 和manager/node之间RPC通讯的端口</li><li>下载端口 ==&gt; 和node之间HTTP通讯的端口</li><li>外部Ip ==&gt; node机器可以指定多IP，通过pipeline配置决定是否启用</li><li>zookeeper集群 ==&gt; 就近选择zookeeper集群</li></ol><h3 id="2-3-5-Zookeeper集群参数"><a href="#2-3-5-Zookeeper集群参数" class="headerlink" title="2.3.5 Zookeeper集群参数"></a>2.3.5 Zookeeper集群参数</h3><ol><li>集群名字 ==&gt; 自定义名称，方便记忆</li><li>zookeeper集群 ==&gt; zookeeper集群机器列表，逗号分隔，最后以分号结束<h3 id="3-6-主备配置参数"><a href="#3-6-主备配置参数" class="headerlink" title="3.6 主备配置参数"></a>3.6 主备配置参数</h3></li><li>group Key ==&gt; 自定义名称，otter其他地方基于该名称进行引用</li><li>master / slave ==&gt; 主备库ip信息<br>生成了groupKey，1. 可以在数据库配置时，设置url：jdbc:mysql://groupKey=key (更改 key). 2. 在canal配置时，选择HA机制为media，可填入该groupKey进行引用</li></ol><p>deep</p><h1 id="3-Manager使用介绍"><a href="#3-Manager使用介绍" class="headerlink" title="3. Manager使用介绍"></a>3. Manager使用介绍</h1><h2 id="3-1-背景"><a href="#3-1-背景" class="headerlink" title="3.1 背景"></a>3.1 背景</h2><p>otter4.0发布至今也差不多有近一年的时间，中间过程有着比较曲折经历，拥抱了许多变化，目前otter4已经在逐步替换otter3，继续服务icbu的相关中美同步业务，otter3即将成为过去式。</p><h2 id="3-2-otter4管理系统-manager"><a href="#3-2-otter4管理系统-manager" class="headerlink" title="3.2 otter4管理系统(manager)"></a>3.2 otter4管理系统(manager)</h2><p>比如我们内部系统使用了otter.alibaba-inc.com的域名，后续文档描述的时候会基于此域名链接</p><h3 id="3-2-1-系统登录"><a href="#3-2-1-系统登录" class="headerlink" title="3.2.1 系统登录"></a>3.2.1 系统登录</h3><p>匿名访问时只拥有同步状态的查询权限，可考虑与自己用户授权管理.</p><h3 id="3-2-2-同步管理"><a href="#3-2-2-同步管理" class="headerlink" title="3.2.2 同步管理"></a>3.2.2 同步管理</h3><p><img src="https://upload-images.jianshu.io/upload_images/13935362-6812bebbadf3f55f?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></p><h3 id="3-2-3-同步模式配置"><a href="#3-2-3-同步模式配置" class="headerlink" title="3.2.3 同步模式配置"></a>3.2.3 同步模式配置</h3><p><img src="https://upload-images.jianshu.io/upload_images/13935362-3af7a7351420032b?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"><br>说明：</p><p>a. 同步一致性</p><ol><li><p>基于数据库反查 (简单点说，就是强制反查数据库，从binlog中拿到pk，直接反查对应数据库记录进行同步，回退到几天前binlog进行消费时避免同步老版本的数据时可采用)</p></li><li><p>基于当前日志变更 (基于binlog/redolog解析出来的字段变更值进行同步，不做数据库反查，推荐使用)<br>b. 同步模式</p></li><li><p>行模式 (兼容otter3的处理方案，改变记录中的任何一个字段，触发整行记录的数据同步，在目标库执行merge sql)</p></li><li><p>列模式 (基于log中的具体变更字段，按需同步)<br>c. 特殊组合： (同样支持)</p></li><li><p>基于数据库反查+列模式</p></li><li><p>基于当前日志变更+行模式</p><h3 id="3-2-4-同步简要信息"><a href="#3-2-4-同步简要信息" class="headerlink" title="3.2.4 同步简要信息"></a>3.2.4 同步简要信息</h3><p><img src="https://upload-images.jianshu.io/upload_images/13935362-dec193e9dfcb910d?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"><br>说明：</p></li></ol><ul><li>延迟时间 = 数据库同步到目标库成功时间 - 数据库源库产生变更时间， 单位秒. (由对应node节点定时推送配置)</li><li>最后同步时间 = 数据库同步到目标库最近一次的成功时间 (当前同步关注的相关表，同步到目标库的最后一次成功时间)</li><li>最后位点时间 = 数据binlog消费最后一次更新位点的时间 (和同步时间区别：一个数据库可能存在别的表的变更，不会触发同步时间变更，但会触发位点时间变更)</li></ul><h3 id="3-2-5同步详细信息"><a href="#3-2-5同步详细信息" class="headerlink" title="3.2.5同步详细信息"></a>3.2.5同步详细信息</h3><p>目前主要分为几类:</p><ol><li>映射关系列表</li><li>延迟时间</li><li>同步进度</li><li>监控管理</li><li>日志记录</li></ol><p><strong>映射关系列表</strong><br><img src="https://upload-images.jianshu.io/upload_images/13935362-b5f419f05387facf?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></p><p>点击查看打开映射关系信息页面：<br><img src="https://upload-images.jianshu.io/upload_images/13935362-4b775185b6407541?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></p><p>说明：</p><ul><li>定义同步的源和目标的表信息 (注意:表明可以不同，可以定义数据库分库/分表)</li><li>Push权重 (对应的数字越大，同步会越后面得到同步，优先同步权重小的数据)</li><li>FileResolver (数据关联文件的解析类，目前支持动态源码推送,在目标jvm里动态编译生效，不再需要起停同步任务)</li><li>EventProcessor (业务自定义的数据处理类，比如可以定义不需要同步status=’ENABLE’的记录或者根据业务改变同步的字段信息 简单业务扩展，otter4新特性)</li><li>字段同步 (定义源和目标的字段映射，字段名和字段类型均可进行映射定义，类似于数据库视图定义功能 otter4新特性)</li><li>组合同步 (字段组的概念，字段组中的一个字段发生变更，会确保字段组中的3个字段一起同步到目标库 otter4新特性)</li><li>多个字段决定一个图片地址，变更文件字段中的任何一个字段，就会触发FileResolver类解析，从而可以确保基于字段同步模式，也可以保证FileResolver能够正常解析出文件 otter4重要的优化)</li></ul><p><strong>吞吐量</strong><br><img src="https://upload-images.jianshu.io/upload_images/13935362-34b39492f3300a56?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"><br>说明：</p><ul><li>数据记录统计 (insert/update/delete的变更总和，不区分具体的表，按表纬度的数据统计，可查看映射关系列表-&gt;每个映射关系右边的行为曲线链接)</li><li>文件记录统计</li></ul><p><strong>延迟时间</strong><br><img src="https://upload-images.jianshu.io/upload_images/13935362-278fccdd27856daf?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"><br>说明：</p><ul><li>延迟时间的统计 = 数据库同步到目标库成功时间 - 数据库源库产生变更时间， 单位秒. (由对应node节点定时推送配置)</li></ul><p><strong>同步进度</strong><br><img src="https://upload-images.jianshu.io/upload_images/13935362-cf420b44df594147?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"><br>说明：</p><ul><li>mainstem状态： 代表canal模块当前的运行节点(也即是binlog解析的运行节点，解析会相对耗jvm内存)</li><li>position状态： 当前同步成功的最后binlog位点信息 (包含链接的是数据库ip/port，对应binlog的位置，对应binlog的变更时间此时间即是计算延迟时间的源库变更时间)</li><li>同步进度： 每个同步批次会有一个唯一标识，可根据该唯一标示进行数据定位，可以查看每个批次的运行时间，找出性能瓶颈点</li></ul><p><strong>监控管理</strong><br><img src="https://upload-images.jianshu.io/upload_images/13935362-3a72945513bb1278.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="监控管理.png"></p><p>说明：</p><p>1.监控项目</p><ul><li>同步延迟，position超时(位点超过多少时间没有更新) ， 一般业务方关心这些即可</li><li>异常 (同步运行过程中出现的异常，比如oracle DBA关心oracle系统ORA-的异常信息，mysql DBA关心mysql数据库相关异常)</li><li>process超时(一个批次数据执行超过多少时间)，同步时间超时(数据超过多少时间没有同步成功过)</li></ul><p>2.阀值设置</p><p>1800@09:00-18:00 , 这例子是指定了早上9点到下午6点，报警阀值为1800.</p><p>3.发送对象</p><p>otterteam为otter团队的标识，阿里内部使用了dragoon系统监控报警通知，如果外部系统可实现自己的报警通知机制<br><strong>日志记录</strong><br><img src="https://upload-images.jianshu.io/upload_images/13935362-493d0067c2eea9d3?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></p><p>说明：</p><ol><li>日志标题即为对应的监控规则定义的名字，可根据监控规则检索对应的日志记录</li><li>日志内容即为发送报警的信息<br>注意： otter4采用主动推送报警的模式，可以保证报警的及时性以及日志完整性(相比于日志文件扫描机制来说)</li></ol><h3 id="3-2-6-配置管理"><a href="#3-2-6-配置管理" class="headerlink" title="3.2.6 配置管理"></a>3.2.6 配置管理</h3><p><strong>数据源</strong><br><img src="https://upload-images.jianshu.io/upload_images/13935362-849fdf2a7c5af559?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></p><p>说明：</p><ul><li>主要是数据库连接信息：定义字符编码，ip地址等 (类似napoli等存储也可以抽象为数据源进行配置)</li><li>切换数据库时，可根据ip检索同步数据库，找到需要切换的同步任务</li></ul><p><strong>数据表</strong><br><img src="https://upload-images.jianshu.io/upload_images/13935362-91eded13b8da0974?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"><br>说明：</p><ul><li>数据表是一种抽象概念，(针对数据库类型即为一个数据库表的定义)</li></ul><p><strong>canal配置</strong><br>说明：主要是管理canal链接到mysql/oracle获取日志的相关参数等，业务方可不重点关注</p><p><strong>机器管理</strong><br><img src="https://upload-images.jianshu.io/upload_images/13935362-5f81455059558a55?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></p><h1 id="映射规则配置"><a href="#映射规则配置" class="headerlink" title="映射规则配置"></a>映射规则配置</h1><h1 id="1-背景"><a href="#1-背景" class="headerlink" title="1.背景"></a>1.背景</h1><p>因为alibaba的特殊业务，比如：</p><ol><li>同步数据同时，需要同步数据关联的文件 (需要做数据join)</li><li>同步会员数据，敏感字段信息不能同步到美国站点. (需要做数据过滤)</li><li>两地机房的数据库可能为异构数据库，(需要做字段类型，名字等转化.)<br>为解决这些业务，otter引入了映射规则这一概念，用于描述这样的一种同步业务的关系，其粒度可以精确到一张表，或者是一整个库.</li></ol><h1 id="2-映射规则"><a href="#2-映射规则" class="headerlink" title="2.映射规则"></a>2.映射规则</h1><h2 id="2-1-表映射"><a href="#2-1-表映射" class="headerlink" title="2.1 表映射"></a>2.1 表映射</h2><p>otter中每个pipeline可以设置多个映射规则，每个映射规则描述一个数据库同步的内容，比如源表是哪张，同步到哪张目标表。<br><img src="https://upload-images.jianshu.io/upload_images/13935362-7e4e32172828c8cf?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></p><h3 id="2-1-1-权重的概念"><a href="#2-1-1-权重的概念" class="headerlink" title="2.1.1 权重的概念"></a>2.1.1 权重的概念</h3><p>可以先看下：Otter数据入库算法 ， 因为otter采用了pk hash的并行载入算法，会将原先binlog中的事务进行打散做并行处理提升同步性能。原先事务被拆散后，通过这个权重概念，来提供“业务上类事务功能”.</p><p>举个实际点的例子来看：</p><ul><li>比如有两张表，product(记录产品的属性信息)和product_detail(记录产品的详情信息)，product_detail上有个字段为product_id与product进行关联. 目前为1:1的关系</li><li>业务上插入数据可以通过事务，先插入product，然后插入product_detail，最后一起提交到数据库. 正常，页面上通过查询用户的product表的数据，发现有产品记录，然后通过product_id去查询product_detail表，查到后才显示产品页面</li><li>假如同步到目标库后，打散事务后，同步过程如果先插入了product表，后插入product_detail表，这时如果有用户访问该产品记录，可能就会遇到product_detail不存在的情况，从而导致页面出错.</li><li>所以，我们通过权重定义，比如将product_detail权重定义为5，将product定义为10。 otter会优先同步权重低的表数据，最终可以保证查询product有数据后，product_detail一定有数据，避免业务出错.<h2 id="2-2-视图映射"><a href="#2-2-视图映射" class="headerlink" title="2.2 视图映射"></a>2.2 视图映射</h2>如何进入视图编辑：<br><img src="https://upload-images.jianshu.io/upload_images/13935362-6c08a48f2a3cb44a?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"><br>点击下一步后，进入视图编辑页面：<br><img src="https://upload-images.jianshu.io/upload_images/13935362-eb836a5c4071bb4c?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></li></ul><p>说明：</p><ul><li>映射规则配置页面，可以选择视图模式为：include或exclude，代表正向匹配或者逆向排除.</li><li>视图配置页面，只支持存在的数据表(因为要获取数据表结构，所以.*等正则的数据表不支持配置该功能)</li><li>视图配置列表，左右选中列表会按照顺序进行对应，做映射时需按照顺序进行选择.<br>举个例子：</li></ul><p>如果要排除表字段A的同步，则只需要选择为exclude模式，然后视图编辑页面选择左右皆选择A字段即可，点击保存.</p><h2 id="2-3-字段组映射"><a href="#2-3-字段组映射" class="headerlink" title="2.3 字段组映射"></a>2.3 字段组映射</h2><p>首先解释一下，需要字段组同步的需求.</p><ol><li>文件同步. 一条记录对应的图片，可能会有一个或者多个字段，比如会有image_path,image_version来决定图片，所以我们可以定义这两个字段为一组，只要满足组内任意一个字段的变更，就会认为需要文件同步.</li><li>数据上的组同步，比如国家，省份，城市，可能在数据库为三个字段. 如果是双A同步，两地同时修改这些字段，但业务上可能在A地修改了国家为美国，在B地修改为省份为浙江，然后一同步，最终就会变成美国，浙江这样的情况. 这种情况可以通过group来解决，将国家，省份，城市做一个group，组内任何一个字段发生了变更，其余字段会做为整体一起变更.<br>再来看一下配置：(点击视图编辑页面的下一步，即可进入)<br><img src="https://upload-images.jianshu.io/upload_images/13935362-851b3c84874420ac?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></li></ol><p>说明：也可不配置视图，单独配置字段组，此时可选择的字段即为当前所有字段(映射规则按照同名映射).</p><h1 id="3-高级映射"><a href="#3-高级映射" class="headerlink" title="3.高级映射"></a>3.高级映射</h1><p>主要分为两类：</p><ol><li>文件同步</li><li>自定义数据同步<br>具体代码扩展方式和配置可参见： Otter扩展性</li></ol><p>配置方式：<br><img src="https://upload-images.jianshu.io/upload_images/13935362-1094307712c91f25?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></p><h2 id="3-1-文件同步"><a href="#3-1-文件同步" class="headerlink" title="3.1 文件同步"></a>3.1 文件同步</h2><p>首先解释一下文件同步的需求，阿里巴巴国际站业务，主要模式为对外贸易，卖家基本在国内，买家在国外. 所以，目前我们的机房部署为杭州和美国各一个，卖家访问杭州机房，买家访问美国机房。卖家在国内发布产品和图片，通过otter同步到美国，同步产品数据记录的同时，同样需要把图片同步过去，保证买家用户的访问体验. 所以，基于这个业务场景，衍生出了文件同步的需求.</p><p>所以，做文件同步的几个前提：</p><ol><li>异地同步 (需要部署为两个node，S/E和T/L分为两地. )</li><li>数据触发文件同步 (数据库记录做为类似文件索引信息，不支持单独同步文件)</li><li>本地文件同步 (需要同步的文件需要和node部署在一台机器上或者通过nfs mount，如果要同步 公司自带的分布式文件系统的数据，otter需要做额外扩展)</li></ol><p>文件同步准备工作：</p><ol><li>准备两台机器，分别部署上两个node</li><li>配置channel/pipeline同步，配置映射规则</li><li>编写FileResolver解析类，根据binlog中的变更数据，转化为文件的路径信息. 例子：TestFileResolver</li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">public class TestFileResolver extends AbstractFileResolver &#123;</span><br><span class="line">public FileInfo[] getFileInfo(Map&amp;lt;String, String&amp;gt; rowMap) &#123;</span><br><span class="line">    // 基本步骤：</span><br><span class="line">    // 1. 获取binlog中的变更字段，比如组成文件有多个字段组成version+path</span><br><span class="line">    // 2. 基于字段内容，构造一个文件路径，目前开源版本只支持本地文件的同步.(如果是网络文件，建议进行NFS mount到ndde机器).</span><br><span class="line">    // 3. 返回FileInfo数组，(目前不支持目录同步，如果是目录需要展开为多个FileInfo的子文件)，如果不需要同步，则返回null.</span><br><span class="line">    String path = rowMap.get(&quot;FIELD&quot;); //注意为大写</span><br><span class="line">    FileInfo fileInfo = null;</span><br><span class="line">    if (StringUtils.isNotEmpty(path)) &#123;</span><br><span class="line">        fileInfo = new FileInfo(path);</span><br><span class="line">        return new FileInfo[] &#123; fileInfo &#125;;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        return null;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h2 id="3-2-自定义数据同步"><a href="#3-2-自定义数据同步" class="headerlink" title="3.2 自定义数据同步"></a>3.2 自定义数据同步</h2><p>通过前面的字段视图映射，或许可以解决80%的需求，但总会有一小撮的特殊用户，希望可以自定义自己的同步数据内容，所以otter引入了自定义数据同步为EventProcessor，允许你任意改变整个同步过程中的数据内容.</p><p>可以支持的需求：</p><ol><li><p>根据字段内容，判断是否需要屏蔽本记录同步</p></li><li><p>动态增加/减少字段</p></li><li><p>动态修改字段内容</p></li><li><p>动态改变事件类型(Insert/Update/Delete)<br>几点注意：</p></li><li><p>EventProcessor主要是在E模块进行数据处理，也就是EventProcessor处理后的数据，会再次经过视图配置，字段组映射，文件同步，最后进入Transform处理.</p></li><li><p>EventProcessor修改数据中的schema/table name需要谨慎，因为会继续后续的E/T/L流程，所以需要保证修改后的name在映射规则列表里有配置，否则同步会出错.<br>一个例子：(比如我想将源库的每条binlog变更，记录到一个日志表binlog，映射规则配置为.*所有表的同步)</p></li></ol><p>代码：TestEventProcessor</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line">public class TestEventProcessor extends AbstractEventProcessor &#123;</span><br><span class="line">public boolean process(EventData eventData) &#123;</span><br><span class="line">    // 基本步骤：</span><br><span class="line">    // 1. 获取binlog中的变更字段</span><br><span class="line">    // 2. 根据业务逻辑进行判断，如果需要忽略本条数据同步，直接返回false，否则返回true</span><br><span class="line">    // 3. 根据业务逻辑进行逻辑转化，比如可以修改整个EventData数据.  </span><br><span class="line"></span><br><span class="line">    // 本文例子：源库的每条binlog变更，记录到一个日志表binlog</span><br><span class="line">    // create table test.binlog(</span><br><span class="line">    //        id bigint(20) auto_increment,</span><br><span class="line">    //        oschema varchar(256),</span><br><span class="line">    //        otable varchar(256),</span><br><span class="line">    //        gtime varchar(32)</span><br><span class="line">    //        ovalue text,</span><br><span class="line">    //        primary key(id);</span><br><span class="line">    //    )</span><br><span class="line">    // 在process处理中，可以修改EventData的任何数据，达到数据转换的效果, just have fun.</span><br><span class="line">    JSONObject col = new JSONObject();</span><br><span class="line">    JSONArray array = new JSONArray();</span><br><span class="line">    for (EventColumn column : eventData.getColumns()) &#123;</span><br><span class="line">        JSONObject obj = this.doColumn(column);</span><br><span class="line">        array.add(obj);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    for (EventColumn key : eventData.getKeys()) &#123;</span><br><span class="line">        JSONObject obj = this.doColumn(key);</span><br><span class="line">        array.add(obj);</span><br><span class="line">    &#125;</span><br><span class="line">    // 记录原始的表信息</span><br><span class="line">    col.put(&quot;schema&quot;, eventData.getSchemaName());</span><br><span class="line">    col.put(&quot;table&quot;, eventData.getTableName());</span><br><span class="line">    col.put(&quot;columns&quot;, array);</span><br><span class="line">    col.put(&quot;dml&quot;, eventData.getEventType());</span><br><span class="line">    col.put(&quot;exectime&quot;, eventData.getExecuteTime());</span><br><span class="line"></span><br><span class="line">    // 构造新的主键</span><br><span class="line">    EventColumn id = new EventColumn();</span><br><span class="line">    id.setColumnValue(eventData.getSchemaName());</span><br><span class="line">    id.setColumnType(Types.BIGINT);</span><br><span class="line">    id.setColumnName(&quot;id&quot;);</span><br><span class="line">    // 构造新的字段</span><br><span class="line">    EventColumn schema = new EventColumn();</span><br><span class="line">    schema.setColumnValue(eventData.getSchemaName());</span><br><span class="line">    schema.setColumnType(Types.VARCHAR);</span><br><span class="line">    schema.setColumnName(&quot;oschema&quot;);</span><br><span class="line"></span><br><span class="line">    EventColumn table = new EventColumn();</span><br><span class="line">    table.setColumnValue(eventData.getTableName());</span><br><span class="line">    table.setColumnType(Types.VARCHAR);</span><br><span class="line">    table.setColumnName(&quot;otable&quot;);</span><br><span class="line"></span><br><span class="line">    EventColumn ovalue = new EventColumn();</span><br><span class="line">    ovalue.setColumnValue(col.toJSONString());</span><br><span class="line">    ovalue.setColumnType(Types.VARCHAR);</span><br><span class="line">    ovalue.setColumnName(&quot;ovalue&quot;);</span><br><span class="line"></span><br><span class="line">    EventColumn gtime = new EventColumn();</span><br><span class="line">    gtime.setColumnValue(eventData.getExecuteTime() + &quot;&quot;);</span><br><span class="line">    gtime.setColumnType(Types.VARCHAR);</span><br><span class="line">    gtime.setColumnName(&quot;gtime&quot;);</span><br><span class="line"></span><br><span class="line">    // 替换为新的字段和主键信息</span><br><span class="line">    List&amp;lt;EventColumn&amp;gt; cols = new ArrayList&amp;lt;EventColumn&amp;gt;();</span><br><span class="line">    cols.add(schema);</span><br><span class="line">    cols.add(table);</span><br><span class="line">    cols.add(gtime);</span><br><span class="line">    cols.add(ovalue);</span><br><span class="line">    eventData.setColumns(cols);</span><br><span class="line"></span><br><span class="line">    List&amp;lt;EventColumn&amp;gt; keys = new ArrayList&amp;lt;EventColumn&amp;gt;();</span><br><span class="line">    keys.add(id);</span><br><span class="line">    eventData.setKeys(keys);</span><br><span class="line"></span><br><span class="line">    //修改数据meta信息</span><br><span class="line">    eventData.setEventType(EventType.INSERT);</span><br><span class="line">    eventData.setSchemaName(&quot;test&quot;);</span><br><span class="line">    eventData.setTableName(&quot;binlog&quot;);</span><br><span class="line">    return true;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">private JSONObject doColumn(EventColumn column) &#123;</span><br><span class="line">    JSONObject obj = new JSONObject();</span><br><span class="line">    obj.put(&quot;name&quot;, column.getColumnName());</span><br><span class="line">    obj.put(&quot;update&quot;, column.isUpdate());</span><br><span class="line">    obj.put(&quot;key&quot;, column.isKey());</span><br><span class="line">    if (column.getColumnType() != Types.BLOB &amp;amp;&amp;amp; column.getColumnType() != Types.CLOB) &#123;</span><br><span class="line">        obj.put(&quot;value&quot;, column.getColumnValue());</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        obj.put(&quot;value&quot;, &quot;&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">    return obj;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Adminguide&quot;&gt;&lt;a href=&quot;#Adminguide&quot; class=&quot;headerlink&quot; title=&quot;Adminguide&quot;&gt;&lt;/a&gt;Adminguide&lt;/h1&gt;&lt;h1 id=&quot;1-几点说明&quot;&gt;&lt;a href=&quot;#1-几点说明&quot; class=&quot;
      
    
    </summary>
    
      <category term="实用技术" scheme="http://ellenadams.github.io/categories/%E5%AE%9E%E7%94%A8%E6%8A%80%E6%9C%AF/"/>
    
      <category term="Otter" scheme="http://ellenadams.github.io/categories/%E5%AE%9E%E7%94%A8%E6%8A%80%E6%9C%AF/Otter/"/>
    
    
      <category term="Otter" scheme="http://ellenadams.github.io/tags/Otter/"/>
    
  </entry>
  
  <entry>
    <title>3.Otter快速上手</title>
    <link href="http://ellenadams.github.io/2019/07/27/3.Otter%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/"/>
    <id>http://ellenadams.github.io/2019/07/27/3.Otter快速上手/</id>
    <published>2019-07-27T04:52:18.767Z</published>
    <updated>2019-07-27T04:52:18.767Z</updated>
    
    <content type="html"><![CDATA[<h1 id="QuickStart"><a href="#QuickStart" class="headerlink" title="QuickStart"></a>QuickStart</h1><h1 id="1-几点说明"><a href="#1-几点说明" class="headerlink" title="1.几点说明"></a>1.几点说明</h1><p>otter依赖于canal提供数据库日志，针对mysql数据有一些要求，具体请查看： <a href="https://github.com/alibaba/canal/wiki/QuickStart" target="_blank" rel="noopener">https://github.com/alibaba/canal/wiki/QuickStart</a></p><p>有一点特别注意：<strong>目前canal支持mixed,row,statement多种日志协议的解析，但配合otter进行数据库同步，目前仅支持row协议的同步，使用时需要注意</strong>.</p><p><strong>环境准备</strong></p><ol><li><p>操作系统</p><p> a. otter为纯java编写，windows/linux均可支持</p><p> b. jdk建议使用1.6.25以上的版本，稳定可靠，目前阿里巴巴使用基本为此版本</p></li><li><p>整个otter同步由几部分组成，需要预先进行安装，后续会有专门的篇幅展开介绍</p></li></ol><ul><li>manager</li><li>node</li></ul><ol start="3"><li><p>otter node依赖于zookeeper进行分布式调度，需要安装一个zookeeper节点或者集群.</p><p> 重要：考虑异地机房的地域性，node机器会优先选择就近的zookeeper节点进行访问，比如国际站会在杭州和美国各部署node，针对美国的node会选择美国的zookeeper进行访问，提升读效率. ps. 不同机房的zookeeper集群组成一个物理大集群，只不过是根据地域不同划分为不同逻辑集群，所有地域的node机器对zookeeper进行写操作都会发到一个地域的zookeeper进行paoxs算法仲裁.</p><p> 所以，manager启动完成后，需要首先定义不同机房的zookeeper机器集群。</p><p> 比如：目前otter使用的zookeeper集群，在杭州会有3个机房，分别部署3+2+2台机器组成一个leader/follower集群，在美国一个机房部署2台机器，做为杭州机房zookeeper的observer(读镜像)，(observer模式特点：读请求在自己本地，写请求代理到leader/follower上投票处理，然后异步接收leader的写结果反馈. )</p></li></ol><p>observer配置文档： <a href="http://zookeeper.apache.org/doc/trunk/zookeeperObservers.html" target="_blank" rel="noopener">http://zookeeper.apache.org/doc/trunk/zookeeperObservers.html</a><br><img src="https://upload-images.jianshu.io/upload_images/13935362-dc8f832da8ed0416?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"><br>说明：添加了zookeeper集群后，会在添加node和canal时自动出现在可选列表里。 这也是添加node和canal的一个前提</p><h1 id="2-环境安装"><a href="#2-环境安装" class="headerlink" title="2.环境安装"></a>2.环境安装</h1><h2 id="2-1-manager安装"><a href="#2-1-manager安装" class="headerlink" title="2.1 manager安装"></a>2.1 manager安装</h2><p>Otter Manager QuickStart： Manager_Quickstart</p><h2 id="2-2-node安装"><a href="#2-2-node安装" class="headerlink" title="2.2 node安装"></a>2.2 node安装</h2><p>Otter Node QuickStart : Node_Quickstart</p><h2 id="2-3-网友分享"><a href="#2-3-网友分享" class="headerlink" title="2.3 网友分享"></a>2.3 网友分享</h2><p>网友安装otter过程记录，供未接触java/mvn开发的运维人员使用 ：<a href="http://blog.sina.com.cn/s/articlelist_1869333262_0_1.html" target="_blank" rel="noopener">http://blog.sina.com.cn/s/articlelist_1869333262_0_1.html</a></p><h1 id="3-操作演示"><a href="#3-操作演示" class="headerlink" title="3. 操作演示"></a>3. 操作演示</h1><p>演示视频（5分钟教你配置一个同步任务）：请点击图片或者这里<br><a href="http://www.tudou.com/programs/view/Q-qnCg7d-ew" target="_blank" rel="noopener"><img src="https://upload-images.jianshu.io/upload_images/13935362-058cc816bc34c19f.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="ScreenShot"></a><br>演示说明：</p><ol><li>搭建一个数据库同步任务，源数据库ip为：10.20.144.25，目标数据库ip为：10.20.144.29. 源数据库已开启binlog，并且binlog_format为ROW.</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like &apos;%binlog_format%&apos;;</span><br><span class="line">+---------------+-------+</span><br><span class="line">| Variable_name | Value |</span><br><span class="line">+---------------+-------+</span><br><span class="line">| binlog_format | ROW   |</span><br><span class="line">+---------------+-------+</span><br></pre></td></tr></table></figure><ol start="2"><li><p>数据同步精确到一张表进行测试，测试的表名为test.example，简单包含两个子段，测试过程中才创建.</p></li><li><p>配置完成后，手动在源库插入数据，然后快速在目标库进行查看数据，验证数据是否同步成功.</p></li></ol><hr><p>视频中的演示文本：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE  `test`.`example` (</span><br><span class="line">  `id` int(11)  NOT NULL AUTO_INCREMENT,</span><br><span class="line">  `name` varchar(32) COLLATE utf8_bin DEFAULT NULL ,</span><br><span class="line">   PRIMARY KEY (`ID`)</span><br><span class="line">) ENGINE=InnoDB DEFAULT CHARSET=utf8;</span><br><span class="line"></span><br><span class="line">insert into test.example(id,name) values(null,&apos;hello&apos;);</span><br><span class="line"></span><br><span class="line">-----</span><br><span class="line">Otter QuickStart 如何配置一个任务</span><br><span class="line">-----</span><br><span class="line">操作步骤：</span><br><span class="line">1.  添加数据库</span><br><span class="line">    a.  源库 jdbc:mysql://10.20.144.25:3306</span><br><span class="line">    b.  目标库 jdbc:mysql://10.20.144.29:3306</span><br><span class="line">2.  添加canal</span><br><span class="line">    a.  提供数据库ip信息 </span><br><span class="line">3.  添加同步表信息</span><br><span class="line">    a.  源数据表 test.example</span><br><span class="line">    b.  目标数据表 test.example</span><br><span class="line">4.  添加channel</span><br><span class="line">5.  添加pipeline</span><br><span class="line">    a.  选择node节点</span><br><span class="line">    b.  选择canal</span><br><span class="line">6.  添加同步映射规则</span><br><span class="line">    a.  定义源表和目标表的同步关系</span><br><span class="line">7.  启动</span><br><span class="line">8.  测试数据</span><br></pre></td></tr></table></figure><h1 id="Manager-Quickstart"><a href="#Manager-Quickstart" class="headerlink" title="Manager_Quickstart"></a>Manager_Quickstart</h1><p>KingZzz edited this page on 1 Feb · 9 revisions</p><h1 id="1-环境准备"><a href="#1-环境准备" class="headerlink" title="1.环境准备"></a>1.环境准备</h1><ol><li><p>otter manager依赖于mysql进行配置信息的存储，所以需要预先安装mysql，并初始化otter manager的系统表结构</p><p> a. 安装mysql，这里不展开，网上一搜一大把</p><p> b. 初始化otter manager系统表：</p></li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">下载：</span><br><span class="line">wget https://raw.github.com/alibaba/otter/master/manager/deployer/src/main/resources/sql/otter-manager-schema.sql </span><br><span class="line">载入：</span><br><span class="line">source otter-manager-schema.sql</span><br></pre></td></tr></table></figure><ol start="2"><li><p>整个otter架构依赖了zookeeper进行多节点调度，所以需要预先安装zookeeper，不需要初始化节点，otter程序启动后会自检.</p><p> a. manager需要在otter.properties中指定一个就近的zookeeper集群机器</p></li></ol><h1 id="2-启动步骤"><a href="#2-启动步骤" class="headerlink" title="2.启动步骤"></a>2.启动步骤</h1><ol><li>下载otter manager</li></ol><p>直接下载 ，可访问：<a href="https://github.com/alibaba/otter/releases" target="_blank" rel="noopener">https://github.com/alibaba/otter/releases</a> ，会列出所有历史的发布版本包下载方式，比如以x.y.z版本为例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://github.com/alibaba/otter/releases/download/otter-x.y.z/manager.deployer-x.y.z.tar.gz</span><br></pre></td></tr></table></figure><p>or<br>自己编译</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git clone git@github.com:alibaba/otter.git</span><br><span class="line">cd otter; </span><br><span class="line">mvn clean install -Dmaven.test.skip -Denv=release</span><br><span class="line">编译完成后，会在根目录下产生target/manager.deployer-$version.tar.gz</span><br></pre></td></tr></table></figure><ol start="2"><li>解压缩</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir /tmp/manager</span><br><span class="line">tar zxvf manager.deployer-$version.tar.gz  -C /tmp/manager</span><br></pre></td></tr></table></figure><ol start="3"><li><p>配置修改</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">## otter manager domain name #修改为正确访问ip，生成URL使用</span><br><span class="line">otter.domainName = 127.0.0.1    </span><br><span class="line">## otter manager http port</span><br><span class="line">otter.port = 8080</span><br><span class="line">## jetty web config xml</span><br><span class="line">otter.jetty = jetty.xml</span><br><span class="line"></span><br><span class="line">otter manager database config ，修改为正确数据库信息</span><br><span class="line"></span><br><span class="line">otter.database.driver.class.name = com.mysql.jdbc.Driver</span><br><span class="line">otter.database.driver.url = jdbc:mysql://127.0.01:3306/ottermanager</span><br><span class="line">otter.database.driver.username = root</span><br><span class="line">otter.database.driver.password = hello</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">otter communication port</span><br><span class="line"></span><br><span class="line">otter.communication.manager.port = 1099</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">otter communication pool size</span><br><span class="line"></span><br><span class="line">otter.communication.pool.size = 10</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">default zookeeper address，修改为正确的地址，手动选择一个地域就近的zookeeper集群列表</span><br><span class="line"></span><br><span class="line">otter.zookeeper.cluster.default = 127.0.0.1:2181</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">default zookeeper session timeout = 90s</span><br><span class="line"></span><br><span class="line">otter.zookeeper.sessionTimeout = 90000</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">otter arbitrate connect manager config</span><br><span class="line"></span><br><span class="line">otter.manager.address = $&#123;otter.domainName&#125;:$&#123;otter.communication.manager.port&#125;</span><br></pre></td></tr></table></figure></li><li><p>准备启动</p></li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh startup.sh</span><br></pre></td></tr></table></figure><ol start="5"><li>查看日志</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vi logs/manager.log</span><br><span class="line"></span><br><span class="line">2013-08-14 13:19:45.911 [] WARN  com.alibaba.otter.manager.deployer.JettyEmbedServer - ##Jetty Embed Server is startup!</span><br><span class="line">2013-08-14 13:19:45.911 [] WARN  com.alibaba.otter.manager.deployer.OtterManagerLauncher - ## the manager server is running now</span><br></pre></td></tr></table></figure><p>出现类似日志，代表启动成功</p><ol start="6"><li>验证</li></ol><p>访问： <a href="http://127.0.0.1:8080/，出现otter的页面，即代表启动成功" target="_blank" rel="noopener">http://127.0.0.1:8080/，出现otter的页面，即代表启动成功</a><br><img src="https://upload-images.jianshu.io/upload_images/13935362-ade89839980e5b1e?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"><br>访问：<a href="http://127.0.0.1:8080/login.htm，初始密码为：admin/admin，即可完成登录" target="_blank" rel="noopener">http://127.0.0.1:8080/login.htm，初始密码为：admin/admin，即可完成登录</a>. 目前：匿名用户只有只读查看的权限，登录为管理员才可以有操作权限</p><ol start="7"><li>关闭</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh stop.sh</span><br></pre></td></tr></table></figure><h1 id="Node-Quickstart"><a href="#Node-Quickstart" class="headerlink" title="Node_Quickstart"></a>Node_Quickstart</h1><h1 id="1-环境准备-1"><a href="#1-环境准备-1" class="headerlink" title="1.环境准备"></a>1.环境准备</h1><ol><li><p>otter node会受otter manager进行管理，所以需要预先安装otter manager，参见：Otter Manager Quickstart.</p></li><li><p>完成manager安装后，需要在manager页面为node定义配置信息，并生一个唯一id.</p><p> a. 首先访问manager页面的机器管理页面，点击添加机器按钮<br><img src="https://upload-images.jianshu.io/upload_images/13935362-8fd3983baa89f758?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></p></li></ol><p>几点说明：</p><ol><li><p>机器名称：可以随意定义，方便自己记忆即可</p></li><li><p>机器ip：对应node节点将要部署的机器ip，如果有多ip时，可选择其中一个ip进行暴露. (此ip是整个集群通讯的入口，实际情况千万别使用127.0.0.1，否则多个机器的node节点会无法识别)</p></li><li><p>机器端口：对应node节点将要部署时启动的数据通讯端口，建议值：2088</p></li><li><p>下载端口：对应node节点将要部署时启动的数据下载端口，建议值：9090</p></li><li><p>外部ip ：对应node节点将要部署的机器ip，存在的一个外部ip，允许通讯的时候走公网处理。</p></li><li><p>zookeeper集群：为提升通讯效率，不同机房的机器可选择就近的zookeeper集群.</p></li><li><p>node这种设计，是为解决单机部署多实例而设计的，允许单机多node指定不同的端口</p><p> b. 机器添加完成后，跳转到机器列表页面，获取对应的机器序号nid</p></li></ol><p>通过这两部操作，获取到了node节点对应的唯一标示，称之为node id，简称：nid. 记录该nid，后续启动nid时会使用</p><ol start="3"><li><p>node节点进行跨机房传输时，会使用到HTTP多线程传输技术，目前主要依赖了aria2c做为其下载客户端，后续会推出java版本.</p><p> a. aria2 官方首页： <a href="http://aria2.sourceforge.net/" target="_blank" rel="noopener">http://aria2.sourceforge.net/</a></p><p> b. 下载页面： <a href="http://sourceforge.net/projects/aria2/files/stable/" target="_blank" rel="noopener">http://sourceforge.net/projects/aria2/files/stable/</a></p></li></ol><p>当前测试过多个HTTP多线程下载客户端，比如wget,curl,axel,oget,proz,aria2c，测试结果aria2c下载效率最快，基本可以压满网卡.</p><p>注意：下载完成或者编译完成后，将对应的aria2c包加入到PATH路径即可.</p><h1 id="2-启动步骤-1"><a href="#2-启动步骤-1" class="headerlink" title="2.启动步骤"></a>2.启动步骤</h1><ol><li>下载otter node</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">直接下载 ，可访问：https://github.com/alibaba/otter/releases ，会列出所有历史的发布版本包下载方式，比如以x.y.z版本为例子：</span><br><span class="line"></span><br><span class="line">wget https://github.com/alibaba/otter/releases/download/otter-x.y.z/node.deployer-x.y.z.tar.gz</span><br><span class="line">or自己编译:</span><br><span class="line"></span><br><span class="line">git clone git@github.com:alibaba/otter.git  </span><br><span class="line">cd otter;   </span><br><span class="line">mvn clean install -Dmaven.test.skip -Denv=release  </span><br><span class="line">编译完成后，会在根目录下产生target/node.deployer-$version.tar.gz</span><br></pre></td></tr></table></figure><ol start="2"><li>解压缩</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir /tmp/node</span><br><span class="line">tar zxvf node.deployer-$version.tar.gz  -C /tmp/node</span><br></pre></td></tr></table></figure><ol start="3"><li>配置修改</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">a. nid配置 (将环境准备中添加机器后获取到的序号，保存到conf目录下的nid文件，比如我添加的机器对应序号为1)</span><br><span class="line"></span><br><span class="line">echo 1 &gt; conf/nid</span><br><span class="line">    b. otter.properties配置修改</span><br><span class="line"></span><br><span class="line"># otter node root dir</span><br><span class="line">otter.nodeHome = $&#123;user.dir&#125;/../node </span><br><span class="line">## otter node dir</span><br><span class="line">otter.htdocs.dir = $&#123;otter.nodeHome&#125;/htdocs</span><br><span class="line">otter.download.dir = $&#123;otter.nodeHome&#125;/download</span><br><span class="line">otter.extend.dir= $&#123;otter.nodeHome&#125;/extend</span><br><span class="line"></span><br><span class="line">default zookeeper sesstion timeout = 90s</span><br><span class="line"></span><br><span class="line">otter.zookeeper.sessionTimeout = 90000</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">otter communication pool size</span><br><span class="line"></span><br><span class="line">otter.communication.pool.size = 10</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">otter arbitrate &amp; node connect manager config ， 修改为正确的manager服务地址</span><br><span class="line"></span><br><span class="line">otter.manager.address = 127.0.0.1:1099</span><br></pre></td></tr></table></figure><ol start="4"><li>准备启动</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh startup.sh</span><br></pre></td></tr></table></figure><ol start="5"><li>查看日志</li></ol><p>如果manager页面的ip配置不正确，会出现类似错误：</p><p>打开日志： vi logs/node/node.log</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Exception in thread &quot;main&quot; java.lang.IllegalArgumentException: node[1] ip[127.0.0.1] port[2088] , but your host ip[10.12.48.215] is not matched!</span><br><span class="line">        at com.alibaba.otter.node.etl.OtterController.checkNidVaild(OtterController.java:245)</span><br><span class="line">        at com.alibaba.otter.node.etl.OtterController.initNid(OtterController.java:230)</span><br><span class="line">        at com.alibaba.otter.node.etl.OtterController.start(OtterController.java:73)</span><br><span class="line">        at com.alibaba.otter.node.deployer.OtterLauncher.main(OtterLauncher.java:25)</span><br></pre></td></tr></table></figure><p>此时修改ip为对应的host ip后，再次启动即可。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vi logs/node/node.log</span><br><span class="line">2013-08-14 15:42:16.886 [main] INFO  com.alibaba.otter.node.deployer.OtterLauncher - INFO ## the otter server is running now ......</span><br><span class="line">看到如下日志，代表node启动完成.</span><br></pre></td></tr></table></figure><ol start="6"><li>验证</li></ol><p>访问： <a href="http://127.0.0.1:8080/node_list.htm，查看对应的节点状态，如果变为了已启动，代表已经正常启动。(ps，如果是未启动，会是一个红色高亮)" target="_blank" rel="noopener">http://127.0.0.1:8080/node_list.htm，查看对应的节点状态，如果变为了已启动，代表已经正常启动。(ps，如果是未启动，会是一个红色高亮)</a><br><img src="https://upload-images.jianshu.io/upload_images/13935362-9baf873bb0bc55ba?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></p><ol start="7"><li>关闭</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh stop.sh</span><br></pre></td></tr></table></figure><p>关闭后，可查看下manager页面，检查下节点状态.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;QuickStart&quot;&gt;&lt;a href=&quot;#QuickStart&quot; class=&quot;headerlink&quot; title=&quot;QuickStart&quot;&gt;&lt;/a&gt;QuickStart&lt;/h1&gt;&lt;h1 id=&quot;1-几点说明&quot;&gt;&lt;a href=&quot;#1-几点说明&quot; class=&quot;
      
    
    </summary>
    
      <category term="实用技术" scheme="http://ellenadams.github.io/categories/%E5%AE%9E%E7%94%A8%E6%8A%80%E6%9C%AF/"/>
    
      <category term="Otter" scheme="http://ellenadams.github.io/categories/%E5%AE%9E%E7%94%A8%E6%8A%80%E6%9C%AF/Otter/"/>
    
    
      <category term="Otter" scheme="http://ellenadams.github.io/tags/Otter/"/>
    
  </entry>
  
  <entry>
    <title>2.Otter原理介绍</title>
    <link href="http://ellenadams.github.io/2019/07/27/2.Otter%E5%8E%9F%E7%90%86%E4%BB%8B%E7%BB%8D/"/>
    <id>http://ellenadams.github.io/2019/07/27/2.Otter原理介绍/</id>
    <published>2019-07-27T04:51:29.271Z</published>
    <updated>2019-07-27T04:51:29.271Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><h1 id="项目介绍"><a href="#项目介绍" class="headerlink" title="项目介绍"></a>项目介绍</h1><p>名称：otter [‘ɒtə(r)]</p><p>译意： 水獭，数据搬运工</p><p>语言： 纯java开发</p><p>定位： 基于数据库增量日志解析，准实时同步到本机房或异地机房的mysql/oracle数据库.</p><h1 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h1><p><img src="https://upload-images.jianshu.io/upload_images/13935362-5f7f4aac1e64bab9?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"><br>原理描述：</p><ol><li><p>基于Canal开源产品，获取数据库增量日志数据。 什么是Canal：<a href="https://github.com/alibaba/canal" target="_blank" rel="noopener">https://github.com/alibaba/canal</a></p></li><li><p>典型管理系统架构，manager(web管理)+node(工作节点)</p><p> a. manager运行时推送同步配置到node节点</p><p> b. node节点将同步状态反馈到manager上</p></li><li><p>基于zookeeper，解决分布式状态调度的，允许多node节点之间协同工作.</p></li></ol><h1 id="otter能解决什么？"><a href="#otter能解决什么？" class="headerlink" title="otter能解决什么？"></a>otter能解决什么？</h1><ol><li><p>异构库同步</p><p> a. mysql -&gt; mysql/oracle. (目前开源版本只支持mysql增量，目标库可以是mysql或者oracle，取决于canal的功能)</p></li><li><p>单机房同步 (数据库之间RTT &lt; 1ms)</p><p> a. 数据库版本升级</p><p> b. 数据表迁移</p><p> c. 异步二级索引</p></li><li><p>异地机房同步 (比如阿里巴巴国际站就是杭州和美国机房的数据库同步，RTT &gt; 200ms，亮点)</p><p> a. 机房容灾</p></li><li><p>双向同步</p><p> a. 避免回环算法 (通用的解决方案，支持大部分关系型数据库)</p><p> b. 数据一致性算法 (保证双A机房模式下，数据保证最终一致性，亮点)</p></li><li><p>文件同步</p><p> a. 站点镜像 (进行数据复制的同时，复制关联的图片，比如复制产品数据，同时复制产品图片).</p></li></ol><h2 id="单机房复制示意图："><a href="#单机房复制示意图：" class="headerlink" title="单机房复制示意图："></a>单机房复制示意图：</h2><p><img src="https://upload-images.jianshu.io/upload_images/13935362-e082262ad74ab738.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="屏幕快照 2019-06-03 下午1.29.50.png"></p><p>说明：</p><p>   a. 数据on-Fly，尽可能不落地，更快的进行数据同步. (开启node loadBalancer算法，如果Node节点S+ETL落在不同的Node上，数据会有个网络传输过程)</p><p>   b. node节点可以有failover / loadBalancer.</p><h2 id="异地机房复制示意图："><a href="#异地机房复制示意图：" class="headerlink" title="异地机房复制示意图："></a>异地机房复制示意图：</h2><p><img src="https://upload-images.jianshu.io/upload_images/13935362-b8a7afee87e2a766?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></p><p>说明：</p><p>   a. 数据涉及网络传输，S/E/T/L几个阶段会分散在2个或者更多Node节点上，多个Node之间通过zookeeper进行协同工作 (一般是Select和Extract在一个机房的Node，Transform/Load落在另一个机房的Node)</p><p>   b. node节点可以有failover / loadBalancer. (每个机房的Node节点，都可以是集群，一台或者多台机器)</p><h2 id="初步性能指标："><a href="#初步性能指标：" class="headerlink" title="初步性能指标："></a>初步性能指标：</h2><ol><li><p>单机房同步</p><p>a. 100tps ， 延迟100ms</p><p>b. 5000tps, 延迟1s</p></li><li><p>中美异地机房同步</p><p>a. 100tps ， 延迟2s</p><p>b. 5000tps ，延迟10s</p></li></ol><p>ps. 性能指标取决于目标数据库性能，数据大小等多个因素，单机房100b大小，极限tps可以1w+</p><h1 id="相关名词解释"><a href="#相关名词解释" class="headerlink" title="相关名词解释"></a>相关名词解释</h1><h2 id="otter核心model关系图"><a href="#otter核心model关系图" class="headerlink" title="otter核心model关系图"></a>otter核心model关系图</h2><p><img src="https://upload-images.jianshu.io/upload_images/13935362-2dc50b4e13720caf?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></p><h2 id="名词解释"><a href="#名词解释" class="headerlink" title="名词解释"></a>名词解释</h2><ul><li>Pipeline：从源端到目标端的整个过程描述，主要由一些同步映射过程组成</li><li>Channel：同步通道，单向同步中一个Pipeline组成，在双向同步中有两个Pipeline组成</li><li>DataMediaPair：根据业务表定义映射关系，比如源表和目标表，字段映射，字段组等</li><li>DataMedia : 抽象的数据介质概念，可以理解为数据表/mq队列定义</li><li>DataMediaSource : 抽象的数据介质源信息，补充描述DateMedia</li><li>ColumnPair : 定义字段映射关系</li><li>ColumnGroup : 定义字段映射组</li><li>Node : 处理同步过程的工作节点，对应一个jvm</li></ul><hr><h2 id="otter的S-E-T-L-stage阶段模型"><a href="#otter的S-E-T-L-stage阶段模型" class="headerlink" title="otter的S/E/T/L stage阶段模型"></a>otter的S/E/T/L stage阶段模型</h2><p><img src="https://upload-images.jianshu.io/upload_images/13935362-123c5cb896c0e478?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></p><p>说明：为了更好的支持系统的扩展性和灵活性，将整个同步流程抽象为Select/Extract/Transform/Load，这么4个阶段.<br>Select阶段: 为解决数据来源的差异性，比如接入canal获取增量数据，也可以接入其他系统获取其他数据等。</p><p>Extract/Transform/Load 阶段：类似于数据仓库的ETL模型，具体可为数据join，数据转化，数据Load的</p><h1 id="Otter调度模型"><a href="#Otter调度模型" class="headerlink" title="Otter调度模型"></a>Otter调度模型</h1><h1 id="1-背景"><a href="#1-背景" class="headerlink" title="1.背景"></a>1.背景</h1><p>在介绍调度模型之前，首先了解一下otter系统要解决的异地机房的网络环境.</p><ol><li>中美网络延迟 (平均200ms)</li><li>中美传输速度 (2~6MB/s)<br>网络因素是一个很重要的问题，</li></ol><ul><li>比如中美网络延迟RTT，平均为200ms，这直接会影响整个系统的架构设计。</li></ul><p>试想一下，发送一条binlog一次RTT 200ms，那是否意味着单线程1秒钟只能发送5条。不过tcp在解决这类问题时，有自己的一套优化算法，叫做滑动窗口，它发送数据可能一次性发了10条，然后一起等返回结果，这样可以提升传输效率，但始终无法满足1秒传输1w+记录的需求。这也就决定了，需要对发送的binlog做批处理，一次性发送尽可能多的数据，然后一起等结果.</p><ul><li>比如中美单socket的带宽只有2～6MB，这直接会影响整个系统的架构设计。</li></ul><p>试想一下，假定一binlog平均1kb，那6MB最多只有6000条数据，也就意味着最大的同步tps只有6000? 而且很多业务的mysql都是共享，也就是6000个binlog对象中，可能只有三分之一或者四分之一是某个业务的，这肯定是无法满足要求的。所以，基于带宽的问题，决定otter架构必须是双节点部署，在杭州一个节点，美国一个节点，杭州这边对数据做加速同步处理，然后快速传递到美国.</p><p>基于这两个因素，决定了： batch处理 + 双节点部署的架构.</p><h1 id="2-调度模型"><a href="#2-调度模型" class="headerlink" title="2.调度模型"></a>2.调度模型</h1><p><img src="https://upload-images.jianshu.io/upload_images/13935362-63cf674bb8e4e975?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></p><p>在正式介绍otter调度模型之前，我们首先得了解TCP/IP协议在解决此类”差网络”环境的一些处理方案，从中借鉴相应的方案.</p><h2 id="2-1-Nagle算法"><a href="#2-1-Nagle算法" class="headerlink" title="2.1 Nagle算法"></a>2.1 Nagle算法</h2><p>通过Canal解决Nagle算法，Canal之前是做为otter的一个子项目，为解决otter的数据增量获取的机制，并为otter项目的特点而量身打造了几个feature.</p><p>Canal的处理：</p><p>   a. 构建RingBuffer (可以基于内存控制模式/数量控制模式)</p><p>   b. 允许客户端指定batchSize获取</p><pre><code>i. 内存大小ii. 记录数</code></pre><p>   c. 指定定batchSize + timeout获取</p><pre><code>i. timeout = -1 ,即时获取，有多少取多少ii. timeout = 0，阻塞至满足batchSize条件iii. timeout &gt; 0，阻塞指定的时间或者满足batchSize.</code></pre><p>建议值：batchSize=4000(约4M) , timeout=500，内存控制模式</p><h2 id="2-2-滑动窗口"><a href="#2-2-滑动窗口" class="headerlink" title="2.2 滑动窗口"></a>2.2 滑动窗口</h2><p><img src="https://upload-images.jianshu.io/upload_images/13935362-621b63b4fd311e68?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></p><p>说明：</p><ol><li>otter通过select模块串行获取canal的批数据，注意是串行获取，每批次获取到的数据，就会有一个全局标识，otter里称之为processId.</li><li>select模块获取到数据后，将其传递给后续的ETL模型. 这里E和T模块会是一个并行处理</li><li>将数据最后传递到Load时，会根据每批数据对应的processId，按照顺序进行串行加载。 ( 比如有一个processId=2的数据先到了Load模块，但会阻塞等processId=1的数据Load完成后才会被执行)</li><li>简单一点说，Select/Load模块会是一个串行机制来保证binlog处理的顺序性，Extract/Transform会是一个并行，加速传输效率.</li></ol><h3 id="2-2-1-并行度"><a href="#2-2-1-并行度" class="headerlink" title="2.2.1 并行度"></a>2.2.1 并行度</h3><p>类似于tcp滑动窗口大小，比如整个滑动窗口设置了并行度为5时，只有等第一个processId Load完成后，第6个Select才会去获取数据。</p><h3 id="2-2-2-数据可靠性"><a href="#2-2-2-数据可靠性" class="headerlink" title="2.2.2 数据可靠性"></a>2.2.2 数据可靠性</h3><ul><li>如何保证数据不丢：2pc. (get/ack)</li><li>如何处理重传协议：get/ack/rollback</li><li>如何支持并行化：多get cursor+ack curosr (可以参看Canal的异步ACK模型)</li></ul><h3 id="2-2-3-编程模型抽象-SEDA模型"><a href="#2-2-3-编程模型抽象-SEDA模型" class="headerlink" title="2.2.3 编程模型抽象(SEDA模型)"></a>2.2.3 编程模型抽象(SEDA模型)</h3><p><img src="https://upload-images.jianshu.io/upload_images/13935362-059f30657d8d1b98?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></p><p>说明： 将并行化调度的串行/并行处理，进行隐藏，抽象了await/single的接口，整个调度称之为仲裁器。(有了这层抽象，不同的仲裁器实现可以解决同机房，异地机房的同步需求)</p><p>模型接口：</p><ul><li><p>await模拟object获取锁操作</p></li><li><p>notify被唤醒后提交任务到thread pools</p></li><li><p>single模拟object释放锁操作，触发下一个stage<br>这里使用了SEDA模型的优势：</p></li><li><p>共享thread pool，解决流控机制</p></li><li><p>划分多stage，提升资源利用率</p></li><li><p>统一编程模型，支持同机房，跨机房不同的调度算法</p><h3 id="仲裁器算法"><a href="#仲裁器算法" class="headerlink" title="仲裁器算法"></a>仲裁器算法</h3><p>主要包括： 令牌生成(processId) + 事件通知.</p></li></ul><p>令牌生成：</p><ul><li><p>基于AtomicLong.inc()机制，(纯内存机制，解决同机房，单节点同步需求，不需要多节点交互)</p></li><li><p>基于zookeeper的自增id机制，(解决异地机房，多节点协作同步需求)<br>事件通知： (简单原理： 每个stage都会有个block queue，接收上一个stage的single信号通知，当前stage会阻塞在该block queue上，直到有信号通知)</p></li><li><p>block queue + put/take方法，(纯内存机制)</p></li><li><p>block queue + rpc + put/take方法 (两个stage对应的node不同，需要rpc调用，需要依赖负载均衡算法解决node节点的选择问题)</p></li><li><p>block queue + zookeeper watcher ()<br>负载均衡算法：</p></li><li><p>Stick : 类似于session stick技术，一旦第一次选择了node，下一次选择会继续使用该node. (有一个好处，资源上下文缓存命中率高)</p></li><li><p>Random : 随机算法</p></li><li><p>RoundRbin ： 轮询算法<br>注意点：每个node节点，都会在zookeeper中生成Ephemeral节点，每个node都会缓存住当前存活的node列表，node节点消失，通过zookeeper watcher机制刷新每个node机器的内存。然后针对每次负载均衡选择时只针对当前存活的节点，保证调度的可靠性。</p></li></ul><h3 id="2-2-4-调度算法成本估算"><a href="#2-2-4-调度算法成本估算" class="headerlink" title="2.2.4 调度算法成本估算"></a>2.2.4 调度算法成本估算</h3><p>中美网络RTT = 200ms , zookeeper一次写入=10ms</p><p>调度成本估算：</p><pre><code>a. zookeeper + zookeeper watch (完全分布式)   10 * 4 + 200 * 2 + 200 = 640msb. zookeeper + rpc (sticky分布式，尽可能选择同节点)10 + 100 + 200 = 310msc. memory + memory (内存调度，单机房)   0msd. memory + rpc (跨机房调度，最优实现，待完成??)   0 + 100 + 100 = 200ms</code></pre><h3 id="2-2-5-数据传输"><a href="#2-2-5-数据传输" class="headerlink" title="2.2.5 数据传输"></a>2.2.5 数据传输</h3><p>有了一层SEDA调度模型的抽象，S/E/T/L模块之间互不感知，那几个模块之间的数据传递，需要有一个机制来处理，这里抽象了一个pipe(管道)的概念.</p><p>原理：</p><p>stage | pipe | stage</p><p>基于pipe实现：</p><ul><li>in memory (两个stage经过仲裁器调度算法选择为同一个node时，直接使用内存传输)</li><li>rpc call (&lt;1MB)</li><li>file(gzip) + http多线程下载<br>在pipe中，通过对数据进行TTL控制，解决TCP协议中的丢包问题控制.<h1 id="Otter数据入库算法"><a href="#Otter数据入库算法" class="headerlink" title="Otter数据入库算法"></a>Otter数据入库算法</h1>agapple edited this page on 17 Aug 2013 · 1 revision<h1 id="1-核心算法介绍"><a href="#1-核心算法介绍" class="headerlink" title="1.核心算法介绍"></a>1.核心算法介绍</h1>实际测试中，otter的同步速度相比于mysql的复制，约有5倍左右的性能提升，这取决于其同步算法的实现. 抛弃了强一致性，得到了性能提升<h2 id="1-1-数据合并"><a href="#1-1-数据合并" class="headerlink" title="1.1 数据合并"></a>1.1 数据合并</h2></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1. insert + insert -&gt; insert (数据迁移+数据增量场景)</span><br><span class="line">2. insert + update -&gt; insert  (update字段合并到insert)</span><br><span class="line">3. insert + delete -&gt; delete </span><br><span class="line">4. update + insert -&gt; insert (数据迁移+数据增量场景)</span><br><span class="line">5. update + update -&gt; update</span><br><span class="line">6. update + delete -&gt; delete</span><br><span class="line">7. delete + insert -&gt; insert </span><br><span class="line">8. delete + update -&gt; update (数据迁移+数据增量场景)</span><br><span class="line">9. delete + delete -&gt; delete</span><br></pre></td></tr></table></figure><p>说明.</p><ol><li><p>insert/行记录update 执行merge sql，解决重复数据执行</p></li><li><p>合并算法执行后，单pk主键只有一条记录，减少并行load算法的复杂性(比如batch合并，并行/串行等处理)</p></li></ol><h2 id="1-2-数据入库算法"><a href="#1-2-数据入库算法" class="headerlink" title="1.2 数据入库算法"></a>1.2 数据入库算法</h2><p>   入库算法采取了按pk hash并行载入+batch合并的优化</p><p>   a. 打散原始数据库事务，预处理数据，合并insert/update/delete数据(参见合并算法)，然后按照table + pk进行并行(相同table的数据，先执行delete,后执行insert/update，串行保证，解决唯一性约束数据变更问题)，相同table的sql会进行batch合并处理</p><p>   b. 提供table权重定义，根据权重定义不同支持”业务上类事务功能”，并行中同时有串行权重控制.</p><p>   业务类事务描述：比如用户的一次交易付款的流程，先产生一笔交易记录，然后修改订单状态为已付款. 用户对这事件的感知，是通过订单状态的已付款，然后进行查询交易记录。</p><p>   所以，可以对同步进行一次编排： 先同步完交易记录，再同步订单状态。 (给同步表定义权重，权重越高的表相对重要，放在后面同步，最后达到的效果可以保证业务事务可见性的功能，快的等慢的. )</p><h2 id="2-初步性能指标："><a href="#2-初步性能指标：" class="headerlink" title="2.初步性能指标："></a>2.初步性能指标：</h2><ol><li><p>单机房同步</p><p>a. 100tps ， 延迟100ms</p><p>b. 5000tps, 延迟1s</p></li><li><p>中美异地机房同步</p><p>a. 100tps ， 延迟2s</p><p>b. 5000tps ，延迟10s</p></li></ol><p>ps. 性能指标取决于目标数据库性能，数据大小等多个因素，单机房100b大小，极限tps可以1w+</p><h1 id="Otter双向回环控制"><a href="#Otter双向回环控制" class="headerlink" title="Otter双向回环控制"></a>Otter双向回环控制</h1><h1 id="1-基本需求"><a href="#1-基本需求" class="headerlink" title="1.基本需求"></a>1.基本需求</h1><p>支持mysql/oracle的异构数据库的双向回环，早期有变态需求：杭州是mysql，美国是oracle，需要做双向同步。<br>需要支持级联同步，比如A&lt;-&gt;B-&gt;C，A同步到B的数据，不能从B回到A，但需要同步到C</p><h1 id="2-实现思路"><a href="#2-实现思路" class="headerlink" title="2.实现思路"></a>2.实现思路</h1><p>利用事务机制，在事务头和尾中插入otter同步标识<br>解析时识别同步标识，判断是否需要屏蔽同步<br>几点注意：</p><p>基于标准SQL实现<br>可以支持mysql/oracle等异构数据库的双向同步<br>事务完整解析&amp;完整可见性<br>事务被拆开同步，会出现部分回环同步，数据不一致. 比如一个事务被拆分为了3截，中间一截因为没有事务头和尾的标识，如果发生同步了，就会导致数据不一致.</p><h1 id="3-实现示意图"><a href="#3-实现示意图" class="headerlink" title="3.实现示意图"></a>3.实现示意图</h1><p><img src="https://upload-images.jianshu.io/upload_images/13935362-82eb56c20f964024?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></p><h1 id="Otter数据一致性"><a href="#Otter数据一致性" class="headerlink" title="Otter数据一致性"></a>Otter数据一致性</h1><h1 id="1-技术选型分析"><a href="#1-技术选型分析" class="headerlink" title="1.技术选型分析"></a>1.技术选型分析</h1><p>需要处理一致性的业务场景：</p><ul><li>多地修改 (双A机房)</li><li>同一记录，同时变更</li><li>同一记录定义：具体到某一张表，某一条pk，某一字段</li><li>同时变更定义：A地写入的数据在B地还未可见的一段时间范围</li></ul><p>基本思路</p><ul><li>事前控制：比如paoxs协议，在多地数据写入各自数据存储之前，就已经决定好最后保留哪条记录</li><li>事后处理：指A/B两地修改的数据，已经保存到数据库之后，通过数据同步后保证两数据的一致性</li></ul><h2 id="1-1-事前控制"><a href="#1-1-事前控制" class="headerlink" title="1.1 事前控制"></a>1.1 事前控制</h2><p>paxos协议，相信大家研究的人也比较多，但是它有一些局限性，就拿zookeeper来说，它使用了paxos的一个变种，但基本原理还是相似的。</p><p>我们拿zookeeper的几种部署模式来看：</p><ol><li>先看： A地部署leader/follower集群，B地部署observer.</li></ol><p>此时A地收到数据后，需要的网络操作基本为同机房的leader/follower的paxos协议，耗时基本可控</p><p>此时B地收到数据后，需要的网络操作为：</p><ul><li>B地接收到请求，转发给A地，一次机房网络</li><li>A地接收到请求，由leader转发给follower进行投票决策，同机房网络</li><li>A地leader将投票的结构，反馈给B地，一次机房网络.<br>这样一来，也就是说，事务时间 = 一次异地机房RTT + 同机房paxos算法耗时. 比如中美网络延迟200ms，那事务时间基本就是200ms+ 。 但此时，B地机房基本是一个只读镜像，读数据也有延迟，其系统写扩展性全在A机房，某一天当A机房不够用时，A机房进行拆分，就会遇到下一个问题。</li></ul><ol start="2"><li>再看：A地和B地组成leader/follower</li></ol><p>此时A地收到数据后，需要的网络操作为：(假如A不是leader，B是leader)</p><ul><li>首先需要发送数据到B，一次机房网络</li><li>B收到A的提议数据后，发起一个投票到A，一次机房网络</li><li>A收到提议后，返回一个投票结果到B，一次机房网络</li><li>B收到大部分投票结果，做出决定之后，将结果反馈给A，一次网络交互.</li></ul><p>这种理想无冲突的情况，总共会有2次RTT，如果优化A发起的提议自己默认投票，不返回给A进行投票，可以优化为1次RTT. 针对中美网络延迟200ms，那事务时间基本是200ms+. 如果A地和B地同时写入，那事务时间可能会翻倍。</p><p>总结：如果你能接受事务时间的影响(比如你A地和B地的网络延迟只有10ms)，那是可以考虑选择paxos协议. 但目前otter所要解决的需求为中美200ms的RTT，暂时无法接收paxos协议来解决一致性问题.</p><h2 id="1-2-事后处理"><a href="#1-2-事后处理" class="headerlink" title="1.2 事后处理"></a>1.2 事后处理</h2><p>针对事后处理，不管哪种方案，一定会是一个最终一致性，因为在你做处理前，A地和B地的数据内容已经不一致了，你不论选择任何一个版本，对另一边来说都是一个数据版本丢失，最终一致性。</p><p>针对数据最终一致性处理，goldengate文档中提到了几种case :</p><ul><li>trusted source. 信任站点，数据出现冲突时，永远以某一边为准覆盖另一边</li><li>timestamp，基于数据的修改时间戳，修改时间新的覆盖旧的数据</li><li>数据类型merge， 比如针对库存信息，A地库存减一，B地库存减二，两边同步之后A地和B地的数据应该是减三，合并两者减一和减二的操作</li></ul><p>针对trusted source/timestamp模型，一定需要建立一个冲突数据kv表，(比如trusted source场景，如果B地修改了记录，而A地没修改此记录，那B地可以覆盖A地，即使A地是trusted source) ，对应冲突数据KV表的插入和删除，如果插入和删除不及时，就会有各种各样的误判，导致数据不一致。</p><p>举个插入不及时的case: 比如A地和B地进行双向同步，同时修改了同一记录，但A地的binlog解析器因为异常挂起了，导致构建冲突数据KV表数据延迟了，而此时B地的数据就会认为无冲突，直接覆盖了A，即使A地是trusted source，然后A地数据解析恢复后，同步到B地时，因为A是trusted source，就会覆盖B地的数据，最后就是A和B两地各为两边之前的版本，导致数据不一致。</p><p>因为goldengate外部文档针对双A机房同步，数据一致性处理描述的比较少，我只能推测到这，基本结论是风险太大，所以otter需要有一种完全可靠的数据一致性方案，这也是本文讨论的重点。</p><h2 id="1-3-单向回环补救-基于trusted-source的改进版"><a href="#1-3-单向回环补救-基于trusted-source的改进版" class="headerlink" title="1.3 单向回环补救 (基于trusted source的改进版)"></a>1.3 单向回环补救 (基于trusted source的改进版)</h2><p><img src="https://upload-images.jianshu.io/upload_images/13935362-a7f1800c2a616f17?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"><br>思路：最终一致性</p><p>适用场景： A地和B地数据不对等，比如A地为主，写入量比较高，B地有少量的数据写入</p><p>单向回环流程：(比如图中以HZ为trusted source站点)</p><ul><li><p>us-&gt;hz同步的数据，会再次进入hz-&gt;us队列，形成一次单向回环</p></li><li><p>hz-&gt;us同步的数据，不会进入us-&gt;hz队列(回环终止，保证不进入死循环)<br>存在的问题：存在同步延迟时，会出现版本丢失高/数据交替性变化</p></li><li><p>比如US同一条记录变更了10个版本，而且很快同步到了HZ，而HZ因为同步数据大，同步延迟，后续单向回环中将10个版本又在US进行了一次重放，导致出现数据交替</p></li><li><p>比如HZ同一条记录变更了10个版本，而且很快同步到了US，而US因为同步延迟，将一个比较早的版本同步到了HZ，后续通过单向回环，将此记录重放到了US，导致之前HZ到US的10个版本丢失.<br>解决方案：</p></li><li><p>反查数据库同步 (以数据库最新版本同步，解决交替性，比如设置一致性反查数据库延迟阀值为60秒，即当同步过程中发现数据延迟超过了60秒，就会基于PK反查一次数据库，拿到当前最新值进行同步，减少交替性的问题)</p></li><li><p>字段同步 (降低冲突概率)</p></li><li><p>同步效率 (同步越快越好，降低双写导致版本丢失概率，不需要构建冲突数据KV表)</p></li><li><p>同步全局控制 (比如HZ-&gt;US和US-&gt;HZ一定要一起启动，一起关闭，保证不会出现一边数据一直覆盖另一边，造成比较多的版本丢失)<br>同步全局控制方案：(分布式Permit)</p></li></ul><p><img src="https://upload-images.jianshu.io/upload_images/13935362-5124aa42a424bff0?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"><br>注意：A,B,C三点状态都正常才允许进行同步(解决数据单向覆盖)。 任何一边的canal不正常工作，都应该停掉整个双向同步，及时性越高越好。</p><h2 id="1-4-时间交集补救"><a href="#1-4-时间交集补救" class="headerlink" title="1.4 时间交集补救"></a>1.4 时间交集补救</h2><p><img src="https://upload-images.jianshu.io/upload_images/13935362-615f8a815d7f87ca?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"><br>算法描述：</p><ol><li>首先定义两个时间概念</li></ol><ul><li>数据变更时间A ：代表业务数据在A地数据库中产生的时间，即图中的时间A</li><li>数据同步时间B：代表数据变更载入到B地数据库的时间，即图中的时间B</li></ul><ol start="2"><li><p>针对每条或者一批数据都记录变更时间A和同步时间B，同时保留历史同步过的数据记录</p></li><li><p>图中纵轴为时间轴，Aa代表从数据库A同步到数据库B的一个同步过程，Ba代表从数据库B到同步到的数据库A的一个同步过程,每个同步过程在纵轴上会有两个点，分别代表变更时间A和同步时间B.</p></li><li><p>根据同一时间的定义，在两边数据库的各自同步过程中，以数据库A为例，在数据库B的同步过程找到与Aa有时间交集的批次，比如这里就是Aa 与 (Ba , Bb , Bc)有时间交集</p></li><li><p>针对步骤４中的批次，根据同一数据的定义，在交集的每个批次中，比如首先拿Aa和Ba的历史同步数据记录，根据同一数据定义进行查找，然后再是Aa和Bb，依次类推。</p></li><li><p>针对步骤５中找到的同一数据，最后确定为需要进行单向回环的一致性算法的数据。</p></li></ol><p>此方案相比于单向回环方案：减少单向回环同步的数据量，解决A和B地数据对等的case，不过目前开源版本暂未实现。</p><h1 id="Otter高可用性"><a href="#Otter高可用性" class="headerlink" title="Otter高可用性"></a>Otter高可用性</h1><h1 id="1-基本需求-1"><a href="#1-基本需求-1" class="headerlink" title="1.基本需求"></a>1.基本需求</h1><ol><li>网络不可靠，异地机房尤为明显.</li><li>manager/node的jvm不可靠，需要考虑异常crash情况</li><li>node的jvm不可靠，需要考虑异常crash的情况</li><li>数据库不可靠，需要考虑数据库切换，比如binlog获取和数据载入时，都需要考虑数据库HA机制</li><li>系统发布时，排除正常的jvm关闭和启动</li></ol><h1 id="2-实现思路-1"><a href="#2-实现思路-1" class="headerlink" title="2.实现思路"></a>2.实现思路</h1><h2 id="2-1-考虑node和manager独立部署"><a href="#2-1-考虑node和manager独立部署" class="headerlink" title="2.1 考虑node和manager独立部署"></a>2.1 考虑node和manager独立部署</h2><p>manager对于node来说可以是一个optional的环境，只有在第一次启动任务时需要，node一旦启动了同步任务后，无论manager是否可用，不能影响正常同步。</p><p>需要考虑的点：</p><ul><li>node对于配置需要有本地cache</li><li>node推送统计信息到manager需要有容错处理，需要考虑manager failover(一台manager挂了，需要链接到另一台).<br>目前otter内部，manager部署2台，manager主要集中在杭州机房，node部署70+，node分布在各个机房。</li></ul><h2 id="2-2-建议异常流程处理机制"><a href="#2-2-建议异常流程处理机制" class="headerlink" title="2.2 建议异常流程处理机制"></a>2.2 建议异常流程处理机制</h2><p><img src="https://upload-images.jianshu.io/upload_images/13935362-668a90f61e85836c?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></p><p>otter调度系统在设计的时候，会有个假定，认为90%的情况都是正常工作的，所以一旦出现异常，处理的代价相对比较高，会使用分布式锁机制。</p><p>仲裁器设计了三种异常机制指令：</p><ul><li><p>WARNING : 只发送报警信息，不做任何S/E/T/L调度干预</p></li><li><p>ROLLBACK : 尝试获取分布式锁，避免并发修改，其次修改分布式Permit为false，停止后续的所有S/E/T/L调度，然后删除所有当前process调度信息，通过zookeeper watcher通知所有相关node，清理对应process的上下文，pipe的数据存储会通过TTL来进行清理，不需要ROLLBACK干预。完成后，释放锁操作</p></li><li><p>RESTART ： 前面几个步骤和ROLLBACK基本类似，唯一不同点在于，在释放锁之前会尝试修改分布式Permit为true，重新开启同步，然后释放锁.<br>罗列了一下不同异常对应的处理机制：</p></li><li><p>两个节点通讯时网络异常，节点发起ROLLBACK</p></li><li><p>节点执行S/E/T/L模块，比如写数据库出现网络异常，节点发起ROLLBACK</p></li><li><p>节点发生了CRASH，由manager进行监听，manager发现后发起RESTART</p></li></ul><h2 id="2-3-node节点监控原理"><a href="#2-3-node节点监控原理" class="headerlink" title="2.3 node节点监控原理"></a>2.3 node节点监控原理</h2><ol><li>和hadoop/hbase原理基本一致，利用zookeeper.每个node在启动完成后，都会在zookeeper中创建一个Ephemerals节点(此节点特点，当node节点发生crash之后，与zookeeper建立的sesstion因为没有心跳，超过一定时间后就会出现SesstionExpired，然后zookeeper会删除该节点)</li><li>manager监听整个node节点列表的变化，任何一个node节点的消失，都会收到zookeeper watcher通知，与内存中上一个版本进行比较，判断出当前消失的node节点</li><li>针对该消失的node节点，会有一段保护期(因为可能正常的发布，会关闭node，同样会触发该watcher)，如果该node在保护期内重新启动了，则不做任何处理。默认保护期为90秒</li><li>如果保护期内node节点未正常启动，说明node是异常crash，通过查询配置，找到使用了该node的所有同步任务，对每个同步任务发起一个RESTART指令，让所有同步任务重新做一次负载均衡选择，避免挂死在老的node上，一直死等其结果返回。</li></ol><h2 id="2-4-数据库切换"><a href="#2-4-数据库切换" class="headerlink" title="2.4 数据库切换"></a>2.4 数据库切换</h2><p>数据库异常问题多种多样，比如数据库hang住，数据库不可用，数据库不可写等等。 在阿里巴巴内部一般会有DBA控制数据库的切换问题。</p><p>比如会有一套管理系统，配置当前mysql主备的关系，发现主机不可用时，他们会通过该系统切备机变为主机，然后推送该配置到所有节点，然后各个客户端收到主备切换消息，更改自己的数据库链接，完成数据库切换。</p><p>因为内部系统无法直接开源，在otter开源版本中，也自带了一个简单版的数据库主备推送的机制，通过页面上的切换按钮，就可以通知到所有的otter节点，切换数据库链接，包括canal的binlog解析和otter数据库loader等。</p><p>otter内部配置中称之为主备配置(media配置)，为一对主备IP，定义一个groupKey。然后在各个地方使用该groupKey。</p><ul><li>比如jdbc url使用group后为：jdbc:mysql://groupKey=xxxx</li><li>canal中可以选择HA机制为media，然后填入对应的groupKey即可<br>发现需要做数据库切换了，可以直接点击切换按钮，目前otter的实现为定时轮询非推送，一般需要1分钟左右才会正式生效，或者发生一次RESTART指令。同样，主备切换可以暴露为服务，方便大家接入各自的数据库管理平台，这也是otter抽象这么一层主备切换配置的原因.</li></ul><h1 id="Otter扩展性"><a href="#Otter扩展性" class="headerlink" title="Otter扩展性"></a>Otter扩展性</h1><h1 id="1-扩展性定义"><a href="#1-扩展性定义" class="headerlink" title="1.扩展性定义"></a>1.扩展性定义</h1><p>按照实现不同，可分为两类：</p><ol><li>数据处理自定义，比如Extract , Transform的数据处理. 目前Select/Load不支持数据自定义处理</li><li>组件功能性扩展，比如支持oracle日志获取，支持hbase数据输出等.</li></ol><h2 id="1-1-数据处理自定义"><a href="#1-1-数据处理自定义" class="headerlink" title="1.1 数据处理自定义"></a>1.1 数据处理自定义</h2><p>Extract模块：</p><ul><li>EventProcessor : 自定义数据处理，可以改变一条变更数据的任意内容</li><li>FileResolver : 解决数据和文件的关联关系<br>目前两者都只支持java语言编写，但都支持运行时动态编译&amp;lib包载入的功能。</li></ul><ol><li>通过Otter Manager直接发布source文件代码，然后推送到node节点上即时生效，不需要重启任何java进程，有点动态语言的味道</li><li>可以将class文件放置到extend目录或者打成jar包，放置在node启动classpath中，也可以通过Otter Manager指定类名的方式进行加载，这样允许业务完全自定义。(但有个缺点，如果使用了一些外部包加入到node classpath中，比如远程接口调用，目前EventProcessor的调用是串行处理，针对串行进行远程调用执行，效率会比较差. )<br><img src="https://upload-images.jianshu.io/upload_images/13935362-f6ab20058d06a963?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"><br>EventProcessor接口示例：</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 业务自定义处理过程</span><br><span class="line"> * </span><br><span class="line"> * @author jianghang 2012-6-25 下午02:26:36</span><br><span class="line"> * @version 4.1.0</span><br><span class="line"> */</span><br><span class="line">public interface EventProcessor &#123;</span><br><span class="line">/**</span><br><span class="line"> * 自定义处理单条EventData对象</span><br><span class="line"> * </span><br><span class="line"> * @return &#123;@link EventData&#125; 返回值=null，需要忽略该条数据</span><br><span class="line"> */</span><br><span class="line">public EventData process(EventData eventData);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="1-2-扩展代码开发"><a href="#1-2-扩展代码开发" class="headerlink" title="1.2 扩展代码开发"></a>1.2 扩展代码开发</h2><h3 id="1-2-1-自定义维护"><a href="#1-2-1-自定义维护" class="headerlink" title="1.2.1 自定义维护"></a>1.2.1 自定义维护</h3><p>依赖配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">&lt;groupId&gt;com.alibaba.otter&lt;/groupId&gt;</span><br><span class="line">&lt;artifactId&gt;shared.etl&lt;/artifactId&gt;</span><br><span class="line">&lt;version&gt;x.y.z&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">&lt;groupId&gt;com.alibaba.otter&lt;/groupId&gt;</span><br><span class="line">&lt;artifactId&gt;node.extend&lt;/artifactId&gt;</span><br><span class="line">&lt;version&gt;x.y.z&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p>a. 创建mvn标准工程</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mvn archetype:create -DgroupId=com.alibaba.otter -DartifactId=node.code</span><br></pre></td></tr></table></figure><p>b. 修改pom.xml，添加依赖<br>c. mvn eclipse:eclipse导入工程</p><p>d. 代码开发完成后，使用的有两种选择：1. manager上选择source，直接粘帖源码 . 2. 将该代码打成jar包，放到node工程的lib目录下，在manager上选择clazz后，写上对应的类名即可</p><h3 id="1-2-2-基于otter-extend工程维护"><a href="#1-2-2-基于otter-extend工程维护" class="headerlink" title="1.2.2 基于otter.extend工程维护"></a>1.2.2 基于otter.extend工程维护</h3><p>a. 下载otter源码包， <a href="https://github.com/alibaba/otter" target="_blank" rel="noopener">https://github.com/alibaba/otter</a></p><p>b. 导入工程.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mvn clean eclipse:eclipse install -Dmaven.test.skip</span><br></pre></td></tr></table></figure><p>c. 代码开发完成后，使用的有两种选择：1. manager上选择source，直接粘帖源码 . 2. 整个otter编译打包，发布后，在manager上选择clazz后，写上对应的类名即可</p><h2 id="1-3-扩展示例代码："><a href="#1-3-扩展示例代码：" class="headerlink" title="1.3 扩展示例代码："></a>1.3 扩展示例代码：</h2><p>EventProcessor扩展：<a href="https://github.com/alibaba/otter/blob/master/node/extend/src/main/java/com/alibaba/otter/node/extend/processor/TestEventProcessor.java" target="_blank" rel="noopener">https://github.com/alibaba/otter/blob/master/node/extend/src/main/java/com/alibaba/otter/node/extend/processor/TestEventProcessor.java</a></p><p>FileResolver扩展：<a href="https://github.com/alibaba/otter/blob/master/node/extend/src/main/java/com/alibaba/otter/node/extend/fileresolver/TestFileResolver.java" target="_blank" rel="noopener">https://github.com/alibaba/otter/blob/master/node/extend/src/main/java/com/alibaba/otter/node/extend/fileresolver/TestFileResolver.java</a></p><h2 id="1-4-组件功能性扩展"><a href="#1-4-组件功能性扩展" class="headerlink" title="1.4 组件功能性扩展"></a>1.4 组件功能性扩展</h2><p>目前这块扩展性机制不够，设计时只预留了接口，但新增一个功能实现，需要通过硬编码的方式去进行，下载otter的源码，增加功能支持，修改spring配置，同时修改web页面，方便使用。</p><p>基于manager的灵活扩展性的实现，暂没有想到很好的办法，如果你有好的思路和实现方式，也可以告知我们，谢谢。</p><p>比如举增加hbase load实现为例，需要扩展的内容：</p><ul><li>增加hbase数据源的抽象</li><li>增加hbase表的抽象，比如column，columnFamily</li><li>增加hbase transform的实现</li><li>增加hbase loader的实现</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h1&gt;&lt;h1 id=&quot;项目介绍&quot;&gt;&lt;a href=&quot;#项目介绍&quot; cla
      
    
    </summary>
    
      <category term="实用技术" scheme="http://ellenadams.github.io/categories/%E5%AE%9E%E7%94%A8%E6%8A%80%E6%9C%AF/"/>
    
      <category term="Otter" scheme="http://ellenadams.github.io/categories/%E5%AE%9E%E7%94%A8%E6%8A%80%E6%9C%AF/Otter/"/>
    
    
      <category term="Otter" scheme="http://ellenadams.github.io/tags/Otter/"/>
    
  </entry>
  
  <entry>
    <title>1.Otter初步介绍</title>
    <link href="http://ellenadams.github.io/2019/07/27/1.Otter%E5%88%9D%E6%AD%A5%E4%BB%8B%E7%BB%8D/"/>
    <id>http://ellenadams.github.io/2019/07/27/1.Otter初步介绍/</id>
    <published>2019-07-27T04:50:13.987Z</published>
    <updated>2019-07-27T04:50:13.987Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Otter初步介绍"><a href="#Otter初步介绍" class="headerlink" title="Otter初步介绍"></a>Otter初步介绍</h1><h1 id="项目背景"><a href="#项目背景" class="headerlink" title="项目背景"></a>项目背景</h1><p>   阿里巴巴B2B公司，因为业务的特性，卖家主要集中在国内，买家主要集中在国外，所以衍生出了杭州和美国异地机房的需求，同时为了提升用户体验，整个机房的架构为双A，两边均可写，由此诞生了otter这样一个产品。</p><p>   otter第一版本可追溯到04~05年，此次外部开源的版本为第4版，开发时间从2011年7月份一直持续到现在，目前阿里巴巴B2B内部的本地/异地机房的同步需求基本全上了otter。</p><p><strong>目前同步规模：</strong></p><p>同步数据量6亿<br>文件同步1.5TB(2000w张图片)<br>涉及200+个数据库实例之间的同步<br>80+台机器的集群规模<br>项目介绍<br>名称：otter [‘ɒtə(r)]</p><p>译意： 水獭，数据搬运工</p><p>语言： 纯java开发</p><p>定位： 基于数据库增量日志解析，准实时同步到本机房或异地机房的mysql/oracle数据库. 一个分布式数据库同步系统</p><h1 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h1><p><img src="https://upload-images.jianshu.io/upload_images/13935362-cdeb0cfb11c6f5ab?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></p><p>原理描述：</p><ol><li><p>基于Canal开源产品，获取数据库增量日志数据。 什么是Canal, 请点击</p></li><li><p>典型管理系统架构，manager(web管理)+node(工作节点)</p><p> a. manager运行时推送同步配置到node节点</p><p> b. node节点将同步状态反馈到manager上</p></li><li><p>基于zookeeper，解决分布式状态调度的，允许多node节点之间协同工作.</p></li></ol><p><strong>什么是canal?</strong></p><p>otter之前开源的一个子项目，开源链接地址++：<a href="http://github.com/alibaba/canal++" target="_blank" rel="noopener">http://github.com/alibaba/canal++</a></p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>See the page for Introduction: ++<a href="https://github.com/alibaba/otter/wiki/Introduction++" target="_blank" rel="noopener">https://github.com/alibaba/otter/wiki/Introduction++</a></p><h2 id="QuickStart"><a href="#QuickStart" class="headerlink" title="QuickStart"></a>QuickStart</h2><p>See the page for quick start: ++<a href="https://github.com/alibaba/otter/wiki/QuickStart++" target="_blank" rel="noopener">https://github.com/alibaba/otter/wiki/QuickStart++</a></p><h2 id="AdminGuide"><a href="#AdminGuide" class="headerlink" title="AdminGuide"></a>AdminGuide</h2><p>See the page for admin deploy guide :++<a href="https://github.com/alibaba/otter/wiki/Adminguide++" target="_blank" rel="noopener">https://github.com/alibaba/otter/wiki/Adminguide++</a></p><h1 id="相关文档"><a href="#相关文档" class="headerlink" title="相关文档"></a>相关文档</h1><p>See the page for 文档: ++<a href="https://github.com/alibaba/otter/wiki/%E7%9B%B8%E5%85%B3PPT%26amp%3BPDF++" target="_blank" rel="noopener">https://github.com/alibaba/otter/wiki/%E7%9B%B8%E5%85%B3PPT%26amp%3BPDF++</a></p><h1 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h1><p>See the page for FAQ: ++<a href="https://github.com/alibaba/otter/wiki/Faq++" target="_blank" rel="noopener">https://github.com/alibaba/otter/wiki/Faq++</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Otter初步介绍&quot;&gt;&lt;a href=&quot;#Otter初步介绍&quot; class=&quot;headerlink&quot; title=&quot;Otter初步介绍&quot;&gt;&lt;/a&gt;Otter初步介绍&lt;/h1&gt;&lt;h1 id=&quot;项目背景&quot;&gt;&lt;a href=&quot;#项目背景&quot; class=&quot;headerli
      
    
    </summary>
    
      <category term="实用技术" scheme="http://ellenadams.github.io/categories/%E5%AE%9E%E7%94%A8%E6%8A%80%E6%9C%AF/"/>
    
      <category term="Otter" scheme="http://ellenadams.github.io/categories/%E5%AE%9E%E7%94%A8%E6%8A%80%E6%9C%AF/Otter/"/>
    
    
      <category term="Otter" scheme="http://ellenadams.github.io/tags/Otter/"/>
    
  </entry>
  
  <entry>
    <title>远在故乡的家</title>
    <link href="http://ellenadams.github.io/2019/07/27/%E8%BF%9C%E5%9C%A8%E6%95%85%E4%B9%A1%E7%9A%84%E5%AE%B6/"/>
    <id>http://ellenadams.github.io/2019/07/27/远在故乡的家/</id>
    <published>2019-07-27T04:10:09.828Z</published>
    <updated>2019-07-27T04:10:09.828Z</updated>
    
    <content type="html"><![CDATA[<h1 id="远在故乡的家"><a href="#远在故乡的家" class="headerlink" title="远在故乡的家"></a>远在故乡的家</h1><p>&emsp;&emsp;多少次归途中，多少次梦途里。家，远在远方，而近在心间。就像你，我从未远离。</p><p>&emsp;&emsp;从懵懵懂懂到魑魅魍魉，我们在书写着自己的日子。有时皓月当空的夜里，睡前用热毛巾擦脸抑或是洗头时猛然回头，看看这周遭，是否我曾熟悉的家里。我只需要一杯陕青或是一碗饸饹，便会想起那舒适的气息。</p><p>&emsp;&emsp;我们穿梭于车站和人流间，晃已隔世。未曾经历，不曾言说。日子，一天一天的划过，转眼，花红叶绿，在炎热也清凉的初夏，经历着相聚相守到别离分开……时过境迁，已奔波两年多，未尝疯狂的去爱，去做自我的决定。可能，工作让我们成长，正是对物的淡然和对情的不执著。</p><p>&emsp;&emsp;会渴望奔走乡间和小城，去到彩云之南，抵达大洋彼岸……这会是每个90后的幻想，在我们憧憬着那些虚幻的同时，回首向来萧瑟处，我们的家乡才是心灵最终归途的地点。她在衰老，也在凋敝，和我们初见的景象全然不一……从学校到社会，或许他人问你最多的第一句是“在哪工作啊？”第二句则转为“啥时候结婚啊”……貌似我们就是工厂的速成品，标准件，从学校出来就要经历这些一般，任然，我觉得还是要遵循自己的内心，并非我们离经叛道，在压抑着从初中到高中的六年里，你们错过了多少儿媳妇？大学一毕业的威逼利诱，真的全然不符自然规律。</p><p>&emsp;&emsp;“青青子衿，悠悠我心”。漫步高山草甸的我从未想过，风沙过后，他会是何般景象……正如我们的家和故乡，一点一点剥离我们对她的认识，变得生冷而又少了一丝乡间的色彩。苟活于世，我们的尴尬是不服输的“精神”和不得不去面对现实的“勇气”，我们对自己和自己接触的人事有着严苛的要求，当然，也苛求着母鸡变凤凰的“传说”。但背道而驰得飞快的我们的理想，在现实面前是如此不堪一击，能做得，唯有以不变应万变，因为我们，没有资本！！！</p><p>&emsp;&emsp;所幸，我们不会摔得很惨。我们的认知和社会在逐步接轨，也在改变着自己和自己对于这个世界的认识。听说，每个人终将变成也一定会成为自己所厌恶的人，是的，我们读书少，对于这复杂的环境要去适应，而我们曾经所厌恶的，正是这难以适应的环境。</p><p>&emsp;&emsp;我们在彼岸，家在心头，都很现实，也很无奈，大家都在变，包括我，也包括你，还有你我之外的大多数“向上者”。</p><p>&emsp;&emsp;我们，或多或少有一些坚持不为他人所懂，正是这份坚持，我们失去了朋友，亲人，恋情和挚爱……有多少不舍和无奈透露其中，是人都想找一份，事少钱多离家近的“体面”工作。但这从对立面考虑又何尝不是一种损失呢？家是庇护我们的港湾，是让我们能够着力去拼搏的后援，是爱也是亲人，这点，我始终坚信！但我们需要成长，需要经历，以一种中和的态度去看待，去体验，我们不会再是那个初出茅庐的孩童，我们也要去承担，去扛起这一份责任和义务！<br>&emsp;&emsp;如履薄冰也好，如坐针毡也罢，是你自己选择得，无论如何，都要去尽力做好，只有经历过，才知道其中的喜怒哀乐和缘由事故。<br>&emsp;&emsp;我们的家在远方，其实，远方并不远，就在我们心间，盼望着每一次隔夜的归途，也盼望着能够亲眼看到企盼已久得亲友，或许我们许久不见，也或者我们忙得连电话都打不上一通，但请你记住，我下次见到你的时候，愿你还是当初的模样！<br>&emsp;&emsp;无故爱你，故乡！也爱你们，那久经别离，在家乡的人儿们！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;远在故乡的家&quot;&gt;&lt;a href=&quot;#远在故乡的家&quot; class=&quot;headerlink&quot; title=&quot;远在故乡的家&quot;&gt;&lt;/a&gt;远在故乡的家&lt;/h1&gt;&lt;p&gt;&amp;emsp;&amp;emsp;多少次归途中，多少次梦途里。家，远在远方，而近在心间。就像你，我从未远离。&lt;/p&gt;

      
    
    </summary>
    
      <category term="生活感触" scheme="http://ellenadams.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E8%A7%A6/"/>
    
      <category term="感受" scheme="http://ellenadams.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E8%A7%A6/%E6%84%9F%E5%8F%97/"/>
    
    
      <category term="个人" scheme="http://ellenadams.github.io/tags/%E4%B8%AA%E4%BA%BA/"/>
    
  </entry>
  
  <entry>
    <title>旅途无尽是沧桑</title>
    <link href="http://ellenadams.github.io/2019/07/27/%E6%97%85%E9%80%94%E6%97%A0%E5%B0%BD%E6%98%AF%E6%B2%A7%E6%A1%91/"/>
    <id>http://ellenadams.github.io/2019/07/27/旅途无尽是沧桑/</id>
    <published>2019-07-27T04:05:32.330Z</published>
    <updated>2019-07-27T04:05:32.330Z</updated>
    
    <content type="html"><![CDATA[<h1 id="旅途无尽是沧桑"><a href="#旅途无尽是沧桑" class="headerlink" title="旅途无尽是沧桑"></a>旅途无尽是沧桑</h1><p>&emsp;&emsp;在静静坐了28个小时大巴车后，我到达了目的地，有着神山神湖的边疆圣地。这是是沙漠戈壁荒芜中埋藏的一点绿意。途中，几经辗转难眠，因为不停的检查站和难以蜷缩的座位。想着，远离了家乡，会否有一点精神上的自由，全然，不是这样。</p><p>&emsp;&emsp;从上了这片高原，再也就失去了那种闲适和放松的感觉，唯有途中的景致可以稍微缓解一下工作长久带来的那些病症。所以，再美的景色也需要有人去欣赏和把味。</p><p>&emsp;&emsp;听到手机没电，怀着一颗敬畏的心奔走在大河和深渊之间，跋涉过山，趟过了河流，在生与死的边界，才知道真情的弥足珍贵。这些天，慢慢觉察出自己的变化，已经不再是那么阳光的大男孩了，变得那样世故现实，不在去憧憬和梦幻那一路走来的快乐和种种滋味，而只是在工作的泥潭中任自己沦落。</p><p>&emsp;&emsp;好久没有那种接到电话喜悦的心情，每每听到铃声响起，面对而来的是无尽的烦躁和抑郁。所幸，在别人看来如此“美好”的工作下，我还怀着对未来的目标和畅游天下的梦。能够在最年轻的日子里做自己喜欢的事情真的算得上是一种巨大的挑战。微微山峰，潺潺河流，有如此静谧的时光，能够 一同作伴，胜过一个人的忧肠。</p><p>&emsp;&emsp;在普兰县的高山草场看到无忧无虑的牧民和他们的羊群，虽寒冷异常，但帐篷下，小溪边，洋溢的是他们发自内心的笑靥。多么渴望离开这喧嚣，逃亡，逃往一个谁也不认识的境地，骑马牧羊，我们身上背负得太多，所以压抑自己的性格和爱好，而去浪费在一些日复一日重复的工作上面，没有什么实质可言，所以，找段时间去问问自己，究竟想要什么，为了什么，追求什么。这并不是说我们在逃避，所说万事皆如此，而我独爱旅行读书的话，那么就背上行囊走在满眼迷香的大道上。</p><p>&emsp;&emsp;可能，经历是最好的过往，我们从中体会，在此成长。勇往直前，心无所畏。旅途，或许是想通某件事最好的途径。我们都欣欣然走在路上，哭过。笑过，痛过，也伤过……抹平一切伤痕，继续前行，在旅行的路上，永远没有停止。不要停下，对一切美好事物的追寻，相信，纯真和爱。</p><p>&emsp;&emsp;只要适时觉醒，那么一切也都不算晚，给自己一个交代，一个来自心灵的交代，大千世界，路还很长，珍惜的东西还有很多，旅途，继续进行着，我们的人生，自己说了算！Don’t   stop   try,keep    going!</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;旅途无尽是沧桑&quot;&gt;&lt;a href=&quot;#旅途无尽是沧桑&quot; class=&quot;headerlink&quot; title=&quot;旅途无尽是沧桑&quot;&gt;&lt;/a&gt;旅途无尽是沧桑&lt;/h1&gt;&lt;p&gt;&amp;emsp;&amp;emsp;在静静坐了28个小时大巴车后，我到达了目的地，有着神山神湖的边疆圣地。这是是
      
    
    </summary>
    
      <category term="生活感触" scheme="http://ellenadams.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E8%A7%A6/"/>
    
      <category term="感受" scheme="http://ellenadams.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E8%A7%A6/%E6%84%9F%E5%8F%97/"/>
    
    
      <category term="个人" scheme="http://ellenadams.github.io/tags/%E4%B8%AA%E4%BA%BA/"/>
    
  </entry>
  
  <entry>
    <title>flink on yarn 启动源码分析</title>
    <link href="http://ellenadams.github.io/2019/07/27/flinkyarn/"/>
    <id>http://ellenadams.github.io/2019/07/27/flinkyarn/</id>
    <published>2019-07-27T02:07:14.156Z</published>
    <updated>2019-07-27T02:07:14.157Z</updated>
    
    <content type="html"><![CDATA[<h1 id="flink-on-yarn-启动问题"><a href="#flink-on-yarn-启动问题" class="headerlink" title="flink on yarn 启动问题"></a>flink on yarn 启动问题</h1><p>&emsp;&emsp;有两个月没发文了，这次在沉寂了两个月后带来的是我们在日常启动flink时大都会遇到的一个问题，不过也困扰了我断断续续有两天时间，后来在拨云见日之后发现豁然开朗的本质，其实，我们的解决问题时，有时候还是只浮于表面，而没有看到深藏冰面以下的那一角，所以继续努力是少不了的，那么切开问题，我们来从现象入手吧！</p><h1 id="1-flink启动现象"><a href="#1-flink启动现象" class="headerlink" title="1.flink启动现象"></a>1.flink启动现象</h1><p>&emsp;&emsp;我们还在用flink on yarn，所以问题是在yarn上启动flink任务后，运行的vcores和containers还有taskManager数以及slot数和我们设置的大相径庭，在程序运行一会之后便又会回归正常，那么，究竟是什么原因产生的这种现象呢，下来我们先具体看下实际的案例。<br><img src="https://upload-images.jianshu.io/upload_images/13935362-e3e228bb58566a1c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="flink on yarn 0.png"></p><p><img src="https://upload-images.jianshu.io/upload_images/13935362-5a39d3467551c116.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="flink on yarn 1.png"></p><p><img src="https://upload-images.jianshu.io/upload_images/13935362-97fa061e27c9941f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="flink on yarn 2.png"></p><p><img src="https://upload-images.jianshu.io/upload_images/13935362-fd90b065232deca6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="flink on yarn 3.png"></p><p><img src="https://upload-images.jianshu.io/upload_images/13935362-97fa061e27c9941f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="flink on yarn 4.png"></p><p><img src="https://upload-images.jianshu.io/upload_images/13935362-ec3168214a336550.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="flink on yarn 5.png"></p><p><img src="https://upload-images.jianshu.io/upload_images/13935362-8d294f8bf11bd67b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="flink shell.png"></p><h2 id="1-1-问题介绍"><a href="#1-1-问题介绍" class="headerlink" title="1.1 问题介绍"></a>1.1 问题介绍</h2><p>&emsp;&emsp;实际任务中，我们设置的container为2个，每个container上的slot为2个，共计<strong>4个slot</strong>。而在yarn队列上实际运行时，我们的子队列最大5个container，9个vcore（内存暂没发现问题，此处我们不做介绍），而我们子队列上有其他任务运行时和只有我们当前任务运行时两种情况下，我们都进行了测试，下来，我们分情况介绍一下。</p><h3 id="1-1-1-有其他任务"><a href="#1-1-1-有其他任务" class="headerlink" title="1.1.1 有其他任务"></a>1.1.1 有其他任务</h3><p>&emsp;&emsp;我们的4个任务都会占用3container和接近5个vcore,共计12container，19vcore（<em>这个估算我是觉得没看懂</em>），具体的队列情况，我们要去yarn队列这块分析下：</p><ul><li>总的资源为96vcores；</li><li>非root队列分配36vcores；</li><li>实时队列分配10vcores；</li><li>我们此时这个队列分配9个vcores；</li><li>说明实际占用的实时队列下的小队列资源已满。</li></ul><p>&emsp;&emsp;此时，我们通过yarnUI可以看出，我们的任务占用资源不多不少，正好3个container，5个vcores，没有多啊，我们先放下疑虑，看看只有该任务运行时的情况。</p><h3 id="1-1-2-只有一个任务"><a href="#1-1-2-只有一个任务" class="headerlink" title="1.1.2 只有一个任务"></a>1.1.2 只有一个任务</h3><p>&emsp;&emsp;在只有当前任务运行时，那就很顺畅了，我们通过不停地F5可以发现，container、vcore从：<br>(1,1) -&gt; (2,3) -&gt; (3,5) -&gt; (4,7) -&gt; (5,9) -&gt; (4,7) -&gt; (3,5)， 这个变化很线性，实际上最大我们的任务占用了5个container和9个vcore，其中除过jobManager<br>和Appmaster占用的1个container1个vcore之外，等于我们有4个container，8个vcore，正常来说，这里面只有2个container，4个vcore是我们需要用的，<strong>多余的2个container，4个Vcores后来又被释放了</strong>，这是现象，至于这个问题的本质是什么，可能我这会能想到的有几种可能：</p><ol><li>我们的yarn队列上其他的资源被我们这个任务全部占用甚至超额占用；</li><li>flink的jobManager在分配taskManager时，按照一定的机制来分配多余的资源。</li></ol><p>具体是什么原因呢，我们要通过下面第二章的源码走读来找到原因，下来，先审视一下我们的启动程序。</p><h2 id="1-2-flink启动程序"><a href="#1-2-flink启动程序" class="headerlink" title="1.2 flink启动程序"></a>1.2 flink启动程序</h2><p>启动程序如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">/streaming/flink-1.6.0/bin/flink run  -s hdfs://hdfs/user/96490559/savepoint-fa82  -C </span><br><span class="line">file:/mnt/streaming/live/jars/mysql-connector-java-5.1.40.jar -n -m yarn-cluster -c com.scheduler  </span><br><span class="line">-yn 2 -ys 2 -p 4 -ytm 1024 -yqu KSC_27CF -ynm test_qa --yarnship /streaming/live/jars </span><br><span class="line">-d /streaming/live/streaming-dist-flink.jar</span><br></pre></td></tr></table></figure><h1 id="2-源码分析"><a href="#2-源码分析" class="headerlink" title="2.源码分析"></a>2.源码分析</h1><p>首先，我们通过flink on yarn的客户端来看一下taskmanager及slot的设置：</p><h2 id="2-1-设置相关参数"><a href="#2-1-设置相关参数" class="headerlink" title="2.1 设置相关参数"></a>2.1 设置相关参数</h2><h3 id="FlinkyarnSessionCli"><a href="#FlinkyarnSessionCli" class="headerlink" title="FlinkyarnSessionCli"></a>FlinkyarnSessionCli</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">private ClusterSpecification createClusterSpecification(Configuration configuration, CommandLine cmd) &#123;</span><br><span class="line">if (cmd.hasOption(container.getOpt())) &#123; // number of containers is required option!</span><br><span class="line">LOG.info(&quot;The argument &#123;&#125; is deprecated in will be ignored.&quot;, container.getOpt());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// TODO: The number of task manager should be deprecated soon</span><br><span class="line">final int numberTaskManagers;</span><br><span class="line"></span><br><span class="line">if (cmd.hasOption(container.getOpt())) &#123;</span><br><span class="line">//通过cmd命令行中设置的container数来设置taskmananger数</span><br><span class="line">numberTaskManagers = Integer.valueOf(cmd.getOptionValue(container.getOpt()));</span><br><span class="line">&#125; else &#123;</span><br><span class="line">numberTaskManagers = 1;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// JobManager Memory</span><br><span class="line">final int jobManagerMemoryMB = ConfigurationUtils.getJobManagerHeapMemory(configuration).getMebiBytes();</span><br><span class="line"></span><br><span class="line">// Task Managers memory</span><br><span class="line">final int taskManagerMemoryMB = ConfigurationUtils.getTaskManagerHeapMemory(configuration).getMebiBytes();</span><br><span class="line">        //按照我们每个taskmanager设置的vcore数设置slot数</span><br><span class="line">int slotsPerTaskManager = configuration.getInteger(TaskManagerOptions.NUM_TASK_SLOTS);</span><br><span class="line"></span><br><span class="line">return new ClusterSpecification.ClusterSpecificationBuilder()</span><br><span class="line">.setMasterMemoryMB(jobManagerMemoryMB)</span><br><span class="line">.setTaskManagerMemoryMB(taskManagerMemoryMB)</span><br><span class="line">.setNumberTaskManagers(numberTaskManagers)</span><br><span class="line">.setSlotsPerTaskManager(slotsPerTaskManager)</span><br><span class="line">.createClusterSpecification();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其次，我们从yarn集群的这个描述类来看具体资源获取这块的一些内容，包含Vcores和memory，这里我们需要关注的点是Vcores以及container的获取及设置。</p><h3 id="AbstractYarnClusterDescriptor"><a href="#AbstractYarnClusterDescriptor" class="headerlink" title="AbstractYarnClusterDescriptor"></a>AbstractYarnClusterDescriptor</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">public ApplicationReport startAppMaster(</span><br><span class="line">Configuration configuration,</span><br><span class="line">String applicationName,</span><br><span class="line">String yarnClusterEntrypoint,</span><br><span class="line">JobGraph jobGraph,</span><br><span class="line">YarnClient yarnClient,</span><br><span class="line">YarnClientApplication yarnApplication,</span><br><span class="line">ClusterSpecification clusterSpecification) throws Exception &#123;</span><br><span class="line"></span><br><span class="line">//获取可用的最大核数</span><br><span class="line">final int numYarnMaxVcores;</span><br><span class="line">try &#123;</span><br><span class="line">numYarnMaxVcores = yarnClient.getNodeReports(NodeState.RUNNING)</span><br><span class="line">.stream()</span><br><span class="line">.mapToInt(report -&gt; report.getCapability().getVirtualCores())</span><br><span class="line">.max()</span><br><span class="line">.orElse(0);</span><br><span class="line">&#125; catch (Exception e) &#123;</span><br><span class="line">throw new YarnDeploymentException(&quot;Couldn&apos;t get cluster description, please check on the YarnConfiguration&quot;, e);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int configuredVcores = flinkConfiguration.getInteger(YarnConfigOptions.VCORES, clusterSpecification.getSlotsPerTaskManager());</span><br><span class="line">// 配置的核数应小于可用核数</span><br><span class="line">if (configuredVcores &gt; numYarnMaxVcores) &#123;</span><br><span class="line">throw new IllegalConfigurationException(</span><br><span class="line">String.format(&quot;The number of requested virtual cores per node %d&quot; +</span><br><span class="line">&quot; exceeds the maximum number of virtual cores %d available in the Yarn Cluster.&quot; +</span><br><span class="line">&quot; Please note that the number of virtual cores is set to the number of task slots by default&quot; +</span><br><span class="line">&quot; unless configured in the Flink config with &apos;%s.&apos;&quot;,</span><br><span class="line">configuredVcores, numYarnMaxVcores, YarnConfigOptions.VCORES.key()));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">ApplicationReport report = startAppMaster(</span><br><span class="line">flinkConfiguration,</span><br><span class="line">applicationName,</span><br><span class="line">yarnClusterEntrypoint,</span><br><span class="line">jobGraph,</span><br><span class="line">yarnClient,</span><br><span class="line">yarnApplication,</span><br><span class="line">validClusterSpecification);</span><br><span class="line"></span><br><span class="line">// Create application via yarnClient</span><br><span class="line">final YarnClientApplication yarnApplication = yarnClient.createApplication();</span><br><span class="line">final GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse();</span><br><span class="line">Resource maxRes = appResponse.getMaximumResourceCapability();</span><br><span class="line"></span><br><span class="line">final int yarnMinAllocationMB = yarnConfiguration.getInt(YarnConfiguration.RM_SCHEDULER_MINIMUM_ALLOCATION_MB, 0);</span><br><span class="line"></span><br><span class="line">freeClusterMem = getCurrentFreeClusterResources(yarnClient);</span><br><span class="line"></span><br><span class="line">final ClusterSpecification validClusterSpecification;</span><br><span class="line">try &#123;</span><br><span class="line">validClusterSpecification = validateClusterResources(</span><br><span class="line">clusterSpecification,</span><br><span class="line">yarnMinAllocationMB,</span><br><span class="line">maxRes,</span><br><span class="line">freeClusterMem);</span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    // 设置Flink on YARN的相关配置</span><br><span class="line">appMasterEnv.put(YarnConfigKeys.ENV_TM_COUNT, String.valueOf(clusterSpecification.getNumberTaskManagers()));//设置taskmanager数</span><br><span class="line">appMasterEnv.put(YarnConfigKeys.ENV_TM_MEMORY, String.valueOf(clusterSpecification.getTaskManagerMemoryMB()));</span><br><span class="line">appMasterEnv.put(YarnConfigKeys.FLINK_JAR_PATH, remotePathJar.toString());</span><br><span class="line">appMasterEnv.put(YarnConfigKeys.ENV_APP_ID, appId.toString());</span><br><span class="line">appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_HOME_DIR, homeDir.toString());</span><br><span class="line">appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_SHIP_FILES, envShipFileList.toString());</span><br><span class="line">appMasterEnv.put(YarnConfigKeys.ENV_SLOTS, String.valueOf(clusterSpecification.getSlotsPerTaskManager()));//设置每个taskmanager上的slot数</span><br><span class="line">appMasterEnv.put(YarnConfigKeys.ENV_DETACHED, String.valueOf(detached));</span><br><span class="line">appMasterEnv.put(YarnConfigKeys.ENV_ZOOKEEPER_NAMESPACE, getZookeeperNamespace());</span><br><span class="line">appMasterEnv.put(YarnConfigKeys.FLINK_YARN_FILES, yarnFilesDir.toUri().toString());</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">public ApplicationReport startAppMaster(</span><br><span class="line">Configuration configuration,</span><br><span class="line">String applicationName,</span><br><span class="line">String yarnClusterEntrypoint,</span><br><span class="line">JobGraph jobGraph,</span><br><span class="line">YarnClient yarnClient,</span><br><span class="line">YarnClientApplication yarnApplication,</span><br><span class="line">ClusterSpecification clusterSpecification) throws Exception &#123;</span><br><span class="line"></span><br><span class="line">// ------------------ Initialize the file systems -------------------------</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">// initialize file system</span><br><span class="line">// Copy the application master jar to the filesystem</span><br><span class="line">// Create a local resource to point to the destination jar path</span><br><span class="line">// hard coded check for the GoogleHDFS client because its not overriding the getScheme() method.</span><br><span class="line"></span><br><span class="line">......</span><br><span class="line"></span><br><span class="line">// Setup jar for ApplicationMaster</span><br><span class="line">Path remotePathJar = setupSingleLocalResource(</span><br><span class="line">&quot;flink.jar&quot;,</span><br><span class="line">fs,</span><br><span class="line">appId,</span><br><span class="line">flinkJarPath,</span><br><span class="line">localResources,</span><br><span class="line">homeDir,</span><br><span class="line">&quot;&quot;);</span><br><span class="line"></span><br><span class="line">// 为TaskManager设置相关参数，是针对总的slot和每个TaskManager上的slot数来设置</span><br><span class="line">configuration.setInteger(</span><br><span class="line"></span><br><span class="line">TaskManagerOptions.NUM_TASK_SLOTS,</span><br><span class="line">clusterSpecification.getSlotsPerTaskManager()</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">configuration.setString(</span><br><span class="line">TaskManagerOptions.TASK_MANAGER_HEAP_MEMORY,</span><br><span class="line">clusterSpecification.getTaskManagerMemoryMB() + &quot;m&quot;);</span><br><span class="line"></span><br><span class="line">......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="TaskManagerOptions"><a href="#TaskManagerOptions" class="headerlink" title="TaskManagerOptions"></a>TaskManagerOptions</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">@Documentation.CommonOption(position = Documentation.CommonOption.POSITION_PARALLELISM_SLOTS)</span><br><span class="line">// 此处的slot数为我们operator中的并行度数，是每个TaskManager上可运行slot的数，默认值1，我们的Vcores设置为每个TaskManager为2，所以该值也为2</span><br><span class="line">public static final ConfigOption&lt;Integer&gt; NUM_TASK_SLOTS =</span><br><span class="line">key(&quot;taskmanager.numberOfTaskSlots&quot;)</span><br><span class="line">.defaultValue(1)</span><br><span class="line">.withDescription(&quot;The number of parallel operator or user function instances that a single TaskManager can&quot; +</span><br><span class="line">&quot; run. If this value is larger than 1, a single TaskManager takes multiple instances of a function or&quot; +</span><br><span class="line">&quot; operator. That way, the TaskManager can utilize multiple CPU cores, but at the same time, the&quot; +</span><br><span class="line">&quot; available memory is divided between the different operator or function instances. This value&quot; +</span><br><span class="line">&quot; is typically proportional to the number of physical CPU cores that the TaskManager&apos;s machine has&quot; +</span><br><span class="line">&quot; (e.g., equal to the number of cores, or half the number of cores).&quot;);</span><br><span class="line"></span><br><span class="line">   //设置taskManager的堆内存大小，默认为1G</span><br><span class="line">/**</span><br><span class="line"> * JVM heap size for the TaskManagers with memory size.</span><br><span class="line"> */</span><br><span class="line">@Documentation.CommonOption(position = Documentation.CommonOption.POSITION_MEMORY)</span><br><span class="line">public static final ConfigOption&lt;String&gt; TASK_MANAGER_HEAP_MEMORY =</span><br><span class="line">key(&quot;taskmanager.heap.size&quot;)</span><br><span class="line">.defaultValue(&quot;1024m&quot;)</span><br><span class="line">.withDescription(&quot;JVM heap size for the TaskManagers, which are the parallel workers of&quot; +</span><br><span class="line">&quot; the system. On YARN setups, this value is automatically configured to the size of the TaskManager&apos;s&quot; +</span><br><span class="line">&quot; YARN container, minus a certain tolerance value.&quot;);</span><br></pre></td></tr></table></figure><p>在我们flink的job运行中，jobmanager负责执行单个flink作业图，它里面针对单个graph有相关的资源申请和释放的相关方法，下来我们具体看一下。</p><h3 id="JobMaster"><a href="#JobMaster" class="headerlink" title="JobMaster"></a>JobMaster</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// 初始化4个taskManager,这里是？？？</span><br><span class="line">this.registeredTaskManagers = new HashMap&lt;&gt;(4);</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">//申请taskManager资源</span><br><span class="line">@Override</span><br><span class="line">public CompletableFuture&lt;Collection&lt;SlotOffer&gt;&gt; offerSlots(</span><br><span class="line">final ResourceID taskManagerId,</span><br><span class="line">final Collection&lt;SlotOffer&gt; slots,</span><br><span class="line">final Time timeout) &#123;</span><br><span class="line"></span><br><span class="line">Tuple2&lt;TaskManagerLocation, TaskExecutorGateway&gt; taskManager = registeredTaskManagers.get(taskManagerId);</span><br><span class="line"></span><br><span class="line">if (taskManager == null) &#123;</span><br><span class="line">return FutureUtils.completedExceptionally(new Exception(&quot;Unknown TaskManager &quot; + taskManagerId));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">final TaskManagerLocation taskManagerLocation = taskManager.f0;</span><br><span class="line">final TaskExecutorGateway taskExecutorGateway = taskManager.f1;</span><br><span class="line"></span><br><span class="line">final RpcTaskManagerGateway rpcTaskManagerGateway = new RpcTaskManagerGateway(taskExecutorGateway, getFencingToken());</span><br><span class="line"></span><br><span class="line">return slotPoolGateway.offerSlots(</span><br><span class="line">taskManagerLocation,</span><br><span class="line">rpcTaskManagerGateway,</span><br><span class="line">slots);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">public CompletableFuture&lt;SerializedInputSplit&gt; requestNextInputSplit(</span><br><span class="line">final JobVertexID vertexID,</span><br><span class="line">final ExecutionAttemptID executionAttempt) &#123;</span><br><span class="line"></span><br><span class="line">       //获取执行图的执行单元</span><br><span class="line">final Execution execution = executionGraph.getRegisteredExecutions().get(executionAttempt);</span><br><span class="line">if (execution == null) &#123;</span><br><span class="line">......</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">final ExecutionJobVertex vertex = executionGraph.getJobVertex(vertexID);</span><br><span class="line">if (vertex == null) &#123;</span><br><span class="line">......</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">final InputSplitAssigner splitAssigner = vertex.getSplitAssigner();</span><br><span class="line">if (splitAssigner == null) &#123;</span><br><span class="line">......</span><br><span class="line">&#125;</span><br><span class="line">       //通过执行单元来获取slot和taskId</span><br><span class="line">final LogicalSlot slot = execution.getAssignedResource();</span><br><span class="line">final int taskId = execution.getVertex().getParallelSubtaskIndex();</span><br><span class="line">final String host = slot != null ? slot.getTaskManagerLocation().getHostname() : null;</span><br><span class="line">final InputSplit nextInputSplit = splitAssigner.getNextInputSplit(host, taskId);</span><br><span class="line"></span><br><span class="line">try &#123;</span><br><span class="line">    //将切分好的输入序列化成对象</span><br><span class="line">final byte[] serializedInputSplit = InstantiationUtil.serializeObject(nextInputSplit);</span><br><span class="line">return CompletableFuture.completedFuture(new SerializedInputSplit(serializedInputSplit));</span><br><span class="line">&#125; catch (Exception ex) &#123;</span><br><span class="line">......</span><br><span class="line">return FutureUtils.completedExceptionally(reason);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="FlinkresourceManager"><a href="#FlinkresourceManager" class="headerlink" title="FlinkresourceManager"></a>FlinkresourceManager</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">   // 此方法使资源框架主框架同步，重新检查可用的和挂起的worker容器集，并在需要时分配容器。</span><br><span class="line">   //这个方法不会自动释放worker，因为对于这个资源管理器，哪个worker可以被释放是不可见的。</span><br><span class="line">   //相反，JobManager必须显式地释放单个worker</span><br><span class="line">private void checkWorkersPool() &#123;</span><br><span class="line">int numWorkersPending = getNumWorkerRequestsPending();</span><br><span class="line">int numWorkersPendingRegistration = getNumWorkersPendingRegistration();</span><br><span class="line"></span><br><span class="line">// sanity checks</span><br><span class="line">Preconditions.checkState(numWorkersPending &gt;= 0,</span><br><span class="line">&quot;Number of pending workers should never be below 0.&quot;);</span><br><span class="line">Preconditions.checkState(numWorkersPendingRegistration &gt;= 0,</span><br><span class="line">&quot;Number of pending workers pending registration should never be below 0.&quot;);</span><br><span class="line"></span><br><span class="line">// see how many workers we want, and whether we have enough</span><br><span class="line">int allAvailableAndPending = startedWorkers.size() +</span><br><span class="line">numWorkersPending + numWorkersPendingRegistration;</span><br><span class="line">       //resourcemanager设置taskmanager数 --&gt;&gt; 池子大小 —（开始的+挂起的+已注册的）</span><br><span class="line">int missing = designatedPoolSize - allAvailableAndPending;</span><br><span class="line"></span><br><span class="line">if (missing &gt; 0) &#123;</span><br><span class="line">requestNewWorkers(missing);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="YarnFlinkresourceManager"><a href="#YarnFlinkresourceManager" class="headerlink" title="YarnFlinkresourceManager"></a>YarnFlinkresourceManager</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">protected void requestNewWorkers(int numWorkers) &#123;</span><br><span class="line">final long mem = taskManagerParameters.taskManagerTotalMemoryMB();</span><br><span class="line">final int containerMemorySizeMB;</span><br><span class="line"></span><br><span class="line">if (mem &lt;= Integer.MAX_VALUE) &#123;</span><br><span class="line">containerMemorySizeMB = (int) mem;</span><br><span class="line">&#125; else &#123;</span><br><span class="line">containerMemorySizeMB = Integer.MAX_VALUE;</span><br><span class="line">LOG.error(&quot;Decreasing container size from &#123;&#125; MB to &#123;&#125; MB (integer value overflow)&quot;,</span><br><span class="line">mem, containerMemorySizeMB);</span><br><span class="line">&#125;</span><br><span class="line">       //遍历taskmanager，然后资源管理客户端 添加资源请求申请</span><br><span class="line">for (int i = 0; i &lt; numWorkers; i++) &#123;</span><br><span class="line">numPendingContainerRequests++;</span><br><span class="line">LOG.info(&quot;Requesting new TaskManager container with &#123;&#125; megabytes memory. Pending requests: &#123;&#125;&quot;,</span><br><span class="line">containerMemorySizeMB, numPendingContainerRequests);</span><br><span class="line"></span><br><span class="line">// Priority for worker containers - priorities are intra-application</span><br><span class="line">Priority priority = Priority.newInstance(0);</span><br><span class="line"></span><br><span class="line">// Resource requirements for worker containers</span><br><span class="line">int taskManagerSlots = taskManagerParameters.numSlots();</span><br><span class="line">int vcores = config.getInteger(YarnConfigOptions.VCORES, Math.max(taskManagerSlots, 1));</span><br><span class="line">Resource capability = Resource.newInstance(containerMemorySizeMB, vcores);</span><br><span class="line"></span><br><span class="line">resourceManagerClient.addContainerRequest(</span><br><span class="line">new AMRMClient.ContainerRequest(capability, null, null, priority));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// make sure we transmit the request fast and receive fast news of granted allocations</span><br><span class="line">resourceManagerClient.setHeartbeatInterval(FAST_YARN_HEARTBEAT_INTERVAL_MS);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">// ------------------------------------------------------------------------</span><br><span class="line">//  </span><br><span class="line">// ------------------------------------------------------------------------</span><br><span class="line">private void containersAllocated(List&lt;Container&gt; containers) &#123;</span><br><span class="line">    //得到我们需要的和已注册的TaskManager</span><br><span class="line">final int numRequired = getDesignatedWorkerPoolSize();</span><br><span class="line">final int numRegistered = getNumberOfStartedTaskManagers();</span><br><span class="line"></span><br><span class="line">for (Container container : containers) &#123;</span><br><span class="line">numPendingContainerRequests = Math.max(0, numPendingContainerRequests - 1);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">// 判断是否返回container，是否启动TaskManager</span><br><span class="line">if (numRegistered + containersInLaunch.size() &lt; numRequired) &#123;</span><br><span class="line"></span><br><span class="line">// 启动TaskManager</span><br><span class="line">final YarnContainerInLaunch containerInLaunch = new YarnContainerInLaunch(container);</span><br><span class="line">final ResourceID resourceID = containerInLaunch.getResourceID();</span><br><span class="line">containersInLaunch.put(resourceID, containerInLaunch);</span><br><span class="line">               ......</span><br><span class="line">               </span><br><span class="line">try &#123;</span><br><span class="line">// 设置一个特殊的环境变量来唯一标识container</span><br><span class="line">taskManagerLaunchContext.getEnvironment()</span><br><span class="line">.put(ENV_FLINK_CONTAINER_ID, resourceID.getResourceIdString());</span><br><span class="line">nodeManagerClient.startContainer(container, taskManagerLaunchContext);</span><br><span class="line">&#125;</span><br><span class="line">catch (Throwable t) &#123;</span><br><span class="line">// failed to launch the container</span><br><span class="line">containersInLaunch.remove(resourceID);</span><br><span class="line"></span><br><span class="line">// return container, a new one will be requested eventually</span><br><span class="line">......</span><br><span class="line">containersBeingReturned.put(container.getId(), container);</span><br><span class="line">resourceManagerClient.releaseAssignedContainer(container.getId());</span><br><span class="line">&#125;</span><br><span class="line">&#125; else &#123;</span><br><span class="line">// 返回过多的container并释放资源</span><br><span class="line">containersBeingReturned.put(container.getId(), container);</span><br><span class="line">resourceManagerClient.releaseAssignedContainer(container.getId());</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">updateProgress();</span><br><span class="line"></span><br><span class="line">// 如果我们不等待其他容器，我们可以使用常规的心跳</span><br><span class="line">if (numPendingContainerRequests &lt;= 0) &#123;</span><br><span class="line">resourceManagerClient.setHeartbeatInterval(yarnHeartbeatIntervalMillis);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 确保我们再次检查worker或容器的状态至少一次，以防一些容器不能正常工作</span><br><span class="line">triggerCheckWorkers();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="2-2-释放多余资源"><a href="#2-2-释放多余资源" class="headerlink" title="2.2 释放多余资源"></a>2.2 释放多余资源</h2><h3 id="JobMaster-1"><a href="#JobMaster-1" class="headerlink" title="JobMaster"></a>JobMaster</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">//释放空余的资源</span><br><span class="line">private CompletableFuture&lt;Acknowledge&gt; releaseEmptyTaskManager(ResourceID resourceId) &#123;</span><br><span class="line">return disconnectTaskManager(resourceId, new FlinkException(String.format(&quot;No more slots registered at JobMaster %s.&quot;, resourceId)));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">public CompletableFuture&lt;Acknowledge&gt; disconnectTaskManager(final ResourceID resourceID, final Exception cause) &#123;</span><br><span class="line">log.debug(&quot;Disconnect TaskExecutor &#123;&#125; because: &#123;&#125;&quot;, resourceID, cause.getMessage());</span><br><span class="line"></span><br><span class="line">taskManagerHeartbeatManager.unmonitorTarget(resourceID);</span><br><span class="line">//1.slotPool先按照id释放多余的slot资源</span><br><span class="line">CompletableFuture&lt;Acknowledge&gt; releaseFuture = slotPoolGateway.releaseTaskManager(resourceID, cause);</span><br><span class="line">       //2.已注册的TaskManager再去取消多余的taskManager</span><br><span class="line">Tuple2&lt;TaskManagerLocation, TaskExecutorGateway&gt; taskManagerConnection = registeredTaskManagers.remove(resourceID);</span><br><span class="line"></span><br><span class="line">if (taskManagerConnection != null) &#123;</span><br><span class="line">taskManagerConnection.f1.disconnectJobManager(jobGraph.getJobID(), cause);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">return releaseFuture;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="SlotPool"><a href="#SlotPool" class="headerlink" title="SlotPool"></a>SlotPool</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">public CompletableFuture&lt;Acknowledge&gt; releaseTaskManager(final ResourceID resourceId, final Exception cause) &#123;</span><br><span class="line">if (registeredTaskManagers.remove(resourceId)) &#123;</span><br><span class="line">releaseTaskManagerInternal(resourceId, cause);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">return CompletableFuture.completedFuture(Acknowledge.get());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">private void releaseTaskManagerInternal(final ResourceID resourceId, final Exception cause) &#123;</span><br><span class="line">final Set&lt;AllocatedSlot&gt; removedSlots = new HashSet&lt;&gt;(allocatedSlots.removeSlotsForTaskManager(resourceId));</span><br><span class="line"></span><br><span class="line">        //具体如何去释放</span><br><span class="line">        //1.先触发指定负载的释放（如果有效载荷可以释放，然后从slot中取出）</span><br><span class="line">for (AllocatedSlot allocatedSlot : removedSlots) &#123;</span><br><span class="line">allocatedSlot.releasePayload(cause);</span><br><span class="line">&#125;</span><br><span class="line">        //2.将需要移除的TaskManager上的slot添加到对应的类中</span><br><span class="line">removedSlots.addAll(availableSlots.removeAllForTaskManager(resourceId));</span><br><span class="line">        //3.移除slot</span><br><span class="line">for (AllocatedSlot removedSlot : removedSlots) &#123;</span><br><span class="line">TaskManagerGateway taskManagerGateway = removedSlot.getTaskManagerGateway();</span><br><span class="line">taskManagerGateway.freeSlot(removedSlot.getAllocationId(), cause, rpcTimeout);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="RpcTaskManagerGateway"><a href="#RpcTaskManagerGateway" class="headerlink" title="RpcTaskManagerGateway"></a>RpcTaskManagerGateway</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">public CompletableFuture&lt;Acknowledge&gt; freeSlot(AllocationID allocationId, Throwable cause, Time timeout) &#123;</span><br><span class="line">    //移除slot</span><br><span class="line">return taskExecutorGateway.freeSlot(</span><br><span class="line">allocationId,</span><br><span class="line">cause,</span><br><span class="line">timeout);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="TaskExecutor"><a href="#TaskExecutor" class="headerlink" title="TaskExecutor"></a>TaskExecutor</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">public CompletableFuture&lt;Acknowledge&gt; freeSlot(AllocationID allocationId, Throwable cause, Time timeout) &#123;</span><br><span class="line">    //取消空闲的taskManager</span><br><span class="line">freeSlotInternal(allocationId, cause);</span><br><span class="line"></span><br><span class="line">return CompletableFuture.completedFuture(Acknowledge.get());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">private void freeSlotInternal(AllocationID allocationId, Throwable cause) &#123;</span><br><span class="line">checkNotNull(allocationId);</span><br><span class="line"></span><br><span class="line">log.debug(&quot;Free slot with allocation id &#123;&#125; because: &#123;&#125;&quot;, allocationId, cause.getMessage());</span><br><span class="line"></span><br><span class="line">try &#123;</span><br><span class="line">final JobID jobId = taskSlotTable.getOwningJob(allocationId);</span><br><span class="line"></span><br><span class="line">final int slotIndex = taskSlotTable.freeSlot(allocationId, cause);</span><br><span class="line"></span><br><span class="line">if (slotIndex != -1) &#123;</span><br><span class="line"></span><br><span class="line">if (isConnectedToResourceManager()) &#123;</span><br><span class="line">// the slot was freed. Tell the RM about it</span><br><span class="line">ResourceManagerGateway resourceManagerGateway = establishedResourceManagerConnection.getResourceManagerGateway();</span><br><span class="line"></span><br><span class="line">resourceManagerGateway.notifySlotAvailable(</span><br><span class="line">establishedResourceManagerConnection.getTaskExecutorRegistrationId(),</span><br><span class="line">new SlotID(getResourceID(), slotIndex),</span><br><span class="line">allocationId);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">if (jobId != null) &#123;</span><br><span class="line">// check whether we still have allocated slots for the same job</span><br><span class="line">if (taskSlotTable.getAllocationIdsPerJob(jobId).isEmpty()) &#123;</span><br><span class="line"></span><br><span class="line">try &#123;</span><br><span class="line">    //通过jobLeader服务移除job</span><br><span class="line">jobLeaderService.removeJob(jobId);</span><br><span class="line">&#125; catch (Exception e) &#123;</span><br><span class="line">log.info(&quot;Could not remove job &#123;&#125; from JobLeaderService.&quot;, jobId, e);</span><br><span class="line">&#125;</span><br><span class="line">                        //关闭与jobManager的连接</span><br><span class="line">closeJobManagerConnection(</span><br><span class="line">jobId,</span><br><span class="line">new FlinkException(&quot;TaskExecutor &quot; + getAddress() +</span><br><span class="line">&quot; has no more allocated slots for job &quot; + jobId + &apos;.&apos;));</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125; catch (SlotNotFoundException e) &#123;</span><br><span class="line">log.debug(&quot;Could not free slot for allocation id &#123;&#125;.&quot;, allocationId, e);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">localStateStoresManager.releaseLocalStateForAllocationId(allocationId);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;启动时候会根据提交作业最后生成的ExecutionGraph的并发度（也就是作业可运行的最大并行度，即可用资源数）来向resourceManager申请slot，<br>然后resourceManager就会启动container <yn> slot<ys>  memory &lt;-ytm&gt;，最后ExecutionGraph切分的（map1,map2,map3…）在各个slot部署启动，多余的没用到的container就会被关闭。</ys></yn></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;flink-on-yarn-启动问题&quot;&gt;&lt;a href=&quot;#flink-on-yarn-启动问题&quot; class=&quot;headerlink&quot; title=&quot;flink on yarn 启动问题&quot;&gt;&lt;/a&gt;flink on yarn 启动问题&lt;/h1&gt;&lt;p&gt;&amp;emsp;
      
    
    </summary>
    
      <category term="实用技术" scheme="http://ellenadams.github.io/categories/%E5%AE%9E%E7%94%A8%E6%8A%80%E6%9C%AF/"/>
    
      <category term="Flink" scheme="http://ellenadams.github.io/categories/%E5%AE%9E%E7%94%A8%E6%8A%80%E6%9C%AF/Flink/"/>
    
    
      <category term="flink" scheme="http://ellenadams.github.io/tags/flink/"/>
    
      <category term="yarn" scheme="http://ellenadams.github.io/tags/yarn/"/>
    
  </entry>
  
  <entry>
    <title>Flink UDF 自动注册实践</title>
    <link href="http://ellenadams.github.io/2019/07/27/flinkUDFRegister/"/>
    <id>http://ellenadams.github.io/2019/07/27/flinkUDFRegister/</id>
    <published>2019-07-27T02:06:15.150Z</published>
    <updated>2019-07-27T02:06:15.150Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>日前，在更新UDF函数这块的一些功能时，发现一些较为细小但大家都会遇到的问题，作为趟过的坑发出来，希望大家能够避免。</p></blockquote><h1 id="1-注册UDF函数"><a href="#1-注册UDF函数" class="headerlink" title="1.注册UDF函数"></a>1.注册UDF函数</h1><h2 id="1-1-注册相关方法"><a href="#1-1-注册相关方法" class="headerlink" title="1.1 注册相关方法"></a>1.1 注册相关方法</h2><ul><li>&nbsp; &nbsp;此处，我们使用的udf函数为标量函数，它继承的是ScalarFunction，该类在我们的使用中，发现它继承自UserDefinedFunction这个类，该处的udf函数由用户自己定义，而函数的注册此处我们自己实现;</li><li>&nbsp; &nbsp;函数注册时，使用flink的tableEnv上下文对象注册该函数，此处注册时使用的方法是TableEnvironment类里面的重载方法registerFunction，这个函数不涉及参数和泛型的问题，具体方法如下：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line">    * Registers a [[ScalarFunction]] under a unique name. Replaces already existing</span><br><span class="line">    * user-defined functions under this name.</span><br><span class="line">    */</span><br><span class="line">  def registerFunction(name: String, function: ScalarFunction): Unit = &#123;</span><br><span class="line">    // check if class could be instantiated</span><br><span class="line">    checkForInstantiation(function.getClass)</span><br><span class="line"></span><br><span class="line">    // register in Table API</span><br><span class="line"></span><br><span class="line">    functionCatalog.registerFunction(name, function.getClass)</span><br><span class="line"></span><br><span class="line">    // register in SQL API</span><br><span class="line">    functionCatalog.registerSqlFunction(</span><br><span class="line">      createScalarSqlFunction(name, name, function, typeFactory)</span><br><span class="line">    )</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></li></ul><p>&nbsp; &nbsp;通过上面得方法，发现在检查完类的实例化之后，便是对该类进行注册使用，分别针对Table API和SQL API两种不同形式去进行注册。</p><p>&nbsp; &nbsp;下面是我们注册的小案例：</p><ul><li><p>日常模式</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tableEnv.registerFunction(&quot;hashCode&quot;,new HashCode())</span><br><span class="line">myTable.select(&quot;item,item.hashCode(),hashCode(item)&quot;)</span><br><span class="line">val hcTest = tableEnv.sqlQuery(&quot;select item,hashCode(item) from myTable&quot;)</span><br></pre></td></tr></table></figure></li><li><p>假日模式</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tableEnv.registerFunction(m(&quot;name&quot;).toString, ReflectHelper.newInstanceByClsName[ScalarFunction]</span><br><span class="line">(m(&quot;className&quot;).toString,this.getClass.getClassLoader))</span><br></pre></td></tr></table></figure></li></ul><h2 id="1-2-函数示例"><a href="#1-2-函数示例" class="headerlink" title="1.2 函数示例"></a>1.2 函数示例</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line">  * Created by LX on 2018/11/15. </span><br><span class="line">  */</span><br><span class="line">class HashCode extends ScalarFunction &#123;</span><br><span class="line"></span><br><span class="line">  var hashcode_factor = 12</span><br><span class="line"></span><br><span class="line">  override def open(context: FunctionContext): Unit = &#123;</span><br><span class="line">    // access &quot;hashcode_factor&quot; parameter</span><br><span class="line">    // &quot;12&quot; would be the default value if parameter does not exist</span><br><span class="line">    hashcode_factor = context.getJobParameter(&quot;hashcode_factor&quot;, &quot;12&quot;).toInt</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  def eval(s: String): Int = &#123;</span><br><span class="line">    s.hashCode()+hashcode_factor</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="2-注册UDTF函数"><a href="#2-注册UDTF函数" class="headerlink" title="2.注册UDTF函数"></a>2.注册UDTF函数</h1><h2 id="2-1-注册相关方法"><a href="#2-1-注册相关方法" class="headerlink" title="2.1 注册相关方法"></a>2.1 注册相关方法</h2><ul><li>在UDTF和UDAF中，我们发现，注册使用的具体函数是包含有一定的格式限制，比如此时我们需要注册的UDTF函数，Split类继承自TableFunction[(String,Int)]，那么我们的函数注册中，在java程序编译时会去检查该泛型，后续实际运行时，解析我们的UDTF函数时，对泛型内的类型进行序列化和反序列化时会和我们规定的泛型进行对比，如果此时我们的数据schema或者说我们的数据本身格式不匹配抑或是我们给出了数据的泛型，编译过了擦除掉之后，在实际运行中却发现并没有该字段信息，那么同样也会出错，所以此时，我们更加要去注意产生该问题的根源，那么根源究竟是什么呢，话不多说，接着看代码。</li><li>我们需要注册函数的registerFunction方法，来自于StreamTableEnvironment中的registerFunction方法，此处的类请大家和之前区别一下，注意，此处这个类在后续我们使用UDAF时也会使用，那么原因在于这两个函数加入了泛型的约束，所以兜兜转转，会有中间的一个检查判断过程，接着，同样是在TableEnvironment这个类中的registerTableFunctionInternal方法，下来，我会分别给出两个方法，请看代码。</li></ul><p><strong>StreamTableEnvironment</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line">    * Registers a [[TableFunction]] under a unique name in the TableEnvironment&apos;s catalog.</span><br><span class="line">    * Registered functions can be referenced in SQL queries.</span><br><span class="line">    *</span><br><span class="line">    * @param name The name under which the function is registered.</span><br><span class="line">    * @param tf The TableFunction to register</span><br><span class="line">    */</span><br><span class="line">  def registerFunction[T: TypeInformation](name: String, tf: TableFunction[T]): Unit = &#123;</span><br><span class="line">    registerTableFunctionInternal(name, tf)</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p><strong>TableEnvironment</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line">   * Registers a [[TableFunction]] under a unique name. Replaces already existing</span><br><span class="line">   * user-defined functions under this name.</span><br><span class="line">   */</span><br><span class="line"> private[flink] def registerTableFunctionInternal[T: TypeInformation](</span><br><span class="line">   name: String, function: TableFunction[T]): Unit = &#123;</span><br><span class="line">   // check if class not Scala object</span><br><span class="line">   checkNotSingleton(function.getClass)</span><br><span class="line">   // check if class could be instantiated</span><br><span class="line">   checkForInstantiation(function.getClass)</span><br><span class="line"></span><br><span class="line">   val typeInfo: TypeInformation[_] = if (function.getResultType != null) &#123;</span><br><span class="line">     function.getResultType</span><br><span class="line">   &#125; else &#123;</span><br><span class="line">     implicitly[TypeInformation[T]]</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   // register in Table API</span><br><span class="line">   functionCatalog.registerFunction(name, function.getClass)</span><br><span class="line"></span><br><span class="line">   // register in SQL API</span><br><span class="line">   val sqlFunction = createTableSqlFunction(name, name, function, typeInfo, typeFactory)</span><br><span class="line">   functionCatalog.registerSqlFunction(sqlFunction)</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>&nbsp; &nbsp;看到了吧，这个T类型规范了我们注册的这个函数的类型，这个在自定义注册时一定要小心；注意我们返回类型是否和我们注册时规定的泛型一致，要让注册能过编译，也要让函数能顺利运行。</p><h2 id="2-2-函数示例"><a href="#2-2-函数示例" class="headerlink" title="2.2 函数示例"></a>2.2 函数示例</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line">  * Created by lx on 2018/11/15. </span><br><span class="line">  */</span><br><span class="line">class Split(separator: String) extends TableFunction[(String, Int)] &#123;</span><br><span class="line"></span><br><span class="line">  def eval(str: String): Unit = &#123;</span><br><span class="line">    str.split(separator).foreach(x =&gt; collect(x, x.length))</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>&nbsp; &nbsp;这个里面的返回即是(String, Int)，因为我们注册时，已经获取了该类的泛型，所以此时，只需要我们在注册前引入隐式转换即可。</p><h2 id="2-3-注册部分"><a href="#2-3-注册部分" class="headerlink" title="2.3 注册部分"></a>2.3 注册部分</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">//register table schema: [a: String]</span><br><span class="line">   tableEnv.registerDataStream(&quot;mySplit&quot;, textFiles,&apos;a)</span><br><span class="line">   val mySplit: Table = tableEnv.sqlQuery(&quot;select * from mySplit&quot;)</span><br><span class="line">   mySplit.printSchema()</span><br><span class="line"></span><br><span class="line">   //register udtf</span><br><span class="line">   val split = new Split(&quot;,&quot;)</span><br><span class="line">   val dslTable =mySplit.join(split(&apos;a) as (&apos;word,&apos;length)).select(&apos;a,&apos;word,&apos;length)</span><br><span class="line">   val dslLeftTable = mySplit.leftOuterJoin(split(&apos;a) as  (&apos;word,&apos;length)).select(&apos;a,&apos;word,&apos;length)</span><br><span class="line"></span><br><span class="line">   tableEnv.registerFunction(&quot;split&quot;,split)</span><br><span class="line">   val sqlJoin =  tableEnv.sqlQuery(&quot;select a,item,counts from mySplit,LATERAL TABLE(split(a)) as T(item,counts)&quot;)</span><br><span class="line">   val sqlLeftJoin =tableEnv.sqlQuery(&quot;select a, item, counts from mySplit </span><br><span class="line">   LEFT JOIN LATERAL TABLE(split(a)) as T(item, counts) ON TRUE&quot;)</span><br></pre></td></tr></table></figure><h1 id="3-注册UDAF函数"><a href="#3-注册UDAF函数" class="headerlink" title="3.注册UDAF函数"></a>3.注册UDAF函数</h1><h2 id="3-1-注册函数"><a href="#3-1-注册函数" class="headerlink" title="3.1 注册函数"></a>3.1 注册函数</h2><blockquote><p>看了上面两种，其实无非是，UDF函数直接注册就可以，UDTF在注册时需要我们规范下类的泛型，而UDAF则不止是这些，不过，take it easy放轻松，趟过的坑马上列出来给你看，哈哈，这里提前说，多了一个返回的类，而此处这个类你们就可要小心啦<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&amp;nbsp; &amp;nbsp;此时，我们的具体思路是，要先给出一个类，比如有几个成员变量作为后续AggregateFunction的一个辅助类，然后UDAF函数中用到了它还有它其中的成员变量，下来，改变下思路，先看注册的函数吧：</span><br><span class="line">- WeightedAvgAccum</span><br><span class="line">```</span><br><span class="line">/**</span><br><span class="line">  * Created by lx on 2018/11/15.</span><br><span class="line">  */</span><br><span class="line">import java.lang.&#123;Long =&gt; JLong, Integer =&gt; JInteger&#125;</span><br><span class="line">import org.apache.flink.api.java.tuple.&#123;Tuple2 =&gt; JTuple2&#125;</span><br><span class="line"></span><br><span class="line">class WeightedAvgAccum extends JTuple2[JLong, JInteger]  &#123;</span><br><span class="line">  var   sum = 0L</span><br><span class="line">  var   count =0</span><br><span class="line">&#125;</span><br><span class="line">```</span><br><span class="line">- WeightedAvg</span><br><span class="line">```</span><br><span class="line">/**</span><br><span class="line"> * Weighted Average user-defined aggregate function.</span><br><span class="line"> */</span><br><span class="line">class WeightedAvg extends AggregateFunction[JLong, CountAccumulator] &#123;</span><br><span class="line"></span><br><span class="line">  override def createAccumulator(): WeightedAvgAccum = &#123;</span><br><span class="line">    new WeightedAvgAccum</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  override def getValue(acc: WeightedAvgAccum): JLong = &#123;</span><br><span class="line">    if (acc.count == 0) &#123;</span><br><span class="line">        null</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        acc.sum / acc.count</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  def accumulate(acc: WeightedAvgAccum, iValue: JLong, iWeight: JInteger): Unit = &#123;</span><br><span class="line">    acc.sum += iValue * iWeight</span><br><span class="line">    acc.count += iWeight</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  def retract(acc: WeightedAvgAccum, iValue: JLong, iWeight: JInteger): Unit = &#123;</span><br><span class="line">    acc.sum -= iValue * iWeight</span><br><span class="line">    acc.count -= iWeight</span><br><span class="line">  &#125;</span><br><span class="line">    </span><br><span class="line">  def merge(acc: WeightedAvgAccum, it: java.lang.Iterable[WeightedAvgAccum]): Unit = &#123;</span><br><span class="line">    val iter = it.iterator()</span><br><span class="line">    while (iter.hasNext) &#123;</span><br><span class="line">      val a = iter.next()</span><br><span class="line">      acc.count += a.count</span><br><span class="line">      acc.sum += a.sum</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  def resetAccumulator(acc: WeightedAvgAccum): Unit = &#123;</span><br><span class="line">    acc.count = 0</span><br><span class="line">    acc.sum = 0L</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  override def getAccumulatorType: TypeInformation[WeightedAvgAccum] = &#123;</span><br><span class="line">    new TupleTypeInfo(classOf[WeightedAvgAccum], Types.LONG, Types.INT)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  override def getResultType: TypeInformation[JLong] = Types.LONG</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">```</span><br><span class="line">## 3.2 注册方法及问题详解</span><br><span class="line">&amp;nbsp; &amp;nbsp;大家伙受累看完这两个类，没什么问题的话我们接着往下讲，官网例子，如下包换，在我们使用flink注册时，没什么问题啊，那么你凭什么说要注意呢？此处我们的前提是用户上传到我们的系统，我们通过反射来拿到该类的实例然后再去注册，那么，问题就来了，如果平时使用没有任何问题，而我们自动让flink识别注册时，flink却做不到，原因为何，请先看看，平时使用和我们自动注册时的一些区别；</span><br><span class="line">- 日常玩法：</span><br><span class="line">```</span><br><span class="line">    tableEnv.registerFunction(&quot;wAvg&quot;,new WeightedAvg())</span><br><span class="line">    val  weightAvgTable = tableEnv.sqlQuery(&quot;select item,wAvg(points,counts) AS avgPoints FROM myTable GROUP BY item&quot;)</span><br><span class="line">```</span><br><span class="line">- 假日玩法：</span><br><span class="line">```</span><br><span class="line"></span><br><span class="line">    implicit  val infoTypes = TypeInformation.of(classOf[Object])</span><br><span class="line">    tableEnv.registerFunction[Object,Object](m(&quot;name&quot;).toString, </span><br><span class="line">    ReflectHelper.newInstanceByClsName(m(&quot;className&quot;).toString,this.getClass.getClassLoader,sm.dac))</span><br><span class="line"></span><br><span class="line">```</span><br><span class="line">&amp;nbsp; &amp;nbsp;亲爱的们，看到问题了吗？其实原因就是我们的程序不是你，它无法推断具体的类的类型，这个需要是我们给出一定的范围或者说我们规范这个流程，即便是这样，引入了对object的隐式转换，过得了编译，但是运行时还会报错，不信，你看：</span><br><span class="line">```</span><br><span class="line">2018-11-22 19:49:40,872 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        </span><br><span class="line">- groupBy: (item), window: (TumblingGroupWindow(&apos;w$, &apos;proctime, 5000.millis)), </span><br><span class="line">select: (item, udafWeightAvg(counts, points) AS c) -&gt; select: (c, item) -&gt; job_1542187919994 -&gt; Sink: Print to Std. Out (2/2) </span><br><span class="line">(3a9098c7ddb0a115349f6d89aba606ff) switched from RUNNING to FAILED.</span><br><span class="line">org.apache.flink.types.NullFieldException: Field 0 is null, but expected to hold a value.</span><br><span class="line">at org.apache.flink.api.java.typeutils.runtime.TupleSerializer.serialize(TupleSerializer.java:127)</span><br><span class="line">at org.apache.flink.api.java.typeutils.runtime.TupleSerializer.serialize(TupleSerializer.java:30)</span><br><span class="line">at org.apache.flink.api.java.typeutils.runtime.RowSerializer.serialize(RowSerializer.java:160)</span><br><span class="line">at org.apache.flink.api.java.typeutils.runtime.RowSerializer.serialize(RowSerializer.java:46)</span><br><span class="line">at org.apache.flink.contrib.streaming.state.AbstractRocksDBState.getValueBytes(AbstractRocksDBState.java:171)</span><br><span class="line">at org.apache.flink.contrib.streaming.state.AbstractRocksDBAppendingState.updateInternal</span><br><span class="line">    (AbstractRocksDBAppendingState.java:80)</span><br><span class="line">at org.apache.flink.contrib.streaming.state.RocksDBAggregatingState.add(RocksDBAggregatingState.java:105)</span><br><span class="line">at org.apache.flink.streaming.runtime.operators.windowing.WindowOperator.processElement(WindowOperator.java:391)</span><br><span class="line">at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:202)</span><br><span class="line">at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:105)</span><br><span class="line">at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:300)</span><br><span class="line">at org.apache.flink.runtime.taskmanager.Task.run(Task.java:711)</span><br><span class="line">at java.lang.Thread.run(Thread.java:745)</span><br><span class="line">Caused by: java.lang.NullPointerException</span><br><span class="line">at org.apache.flink.api.common.typeutils.base.LongSerializer.serialize(LongSerializer.java:63)</span><br><span class="line">at org.apache.flink.api.common.typeutils.base.LongSerializer.serialize(LongSerializer.java:27)</span><br><span class="line">at org.apache.flink.api.java.typeutils.runtime.TupleSerializer.serialize(TupleSerializer.java:125)</span><br><span class="line">... 12 more</span><br><span class="line">2018-11-22 19:49:40,873 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        </span><br><span class="line"> - Job csv_test csv_test_udaf_acc (ec1e56648123905f7ffd85ba884e89ca) switched from state RUNNING to FAILING.</span><br><span class="line">org.apache.flink.types.NullFieldException: Field 0 is null, but expected to hold a value.</span><br><span class="line">```</span><br><span class="line">&amp;nbsp; &amp;nbsp;报错很显然，flink大群里大佬翻译告诉我说这是tuple里面第一位的数据为空，序列化long为空导致，而我傻傻的找了大半天，发现我的程序没问题啊，那这到底问题出在哪呢？其实有时候，并不是我们的错，只是我们太高看了别人，经过苦苦寻找，才找到原来官网的例子中有猫腻。</span><br><span class="line">&amp;nbsp; &amp;nbsp;下来，同样的，看一下StreamTableEnvironment和TableEnvironment这两个类中的注册方法。</span><br><span class="line"></span><br><span class="line">**StreamTableEnvironment**</span><br><span class="line">```</span><br><span class="line">/**</span><br><span class="line">    * Registers an [[AggregateFunction]] under a unique name in the TableEnvironment&apos;s catalog.</span><br><span class="line">    * Registered functions can be referenced in Table API and SQL queries.</span><br><span class="line">    *</span><br><span class="line">    * @param name The name under which the function is registered.</span><br><span class="line">    * @param f The AggregateFunction to register.</span><br><span class="line">    * @tparam T The type of the output value.</span><br><span class="line">    * @tparam ACC The type of aggregate accumulator.</span><br><span class="line">    */</span><br><span class="line">  def registerFunction[T: TypeInformation, ACC: TypeInformation](</span><br><span class="line">      name: String,</span><br><span class="line">      f: AggregateFunction[T, ACC])</span><br><span class="line">  : Unit = &#123;</span><br><span class="line">    registerAggregateFunctionInternal[T, ACC](name, f)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">```</span><br><span class="line">**TableEnvironment**</span><br><span class="line">```</span><br><span class="line">/**</span><br><span class="line">    * Registers an [[AggregateFunction]] under a unique name. Replaces already existing</span><br><span class="line">    * user-defined functions under this name.</span><br><span class="line">    */</span><br><span class="line">  private[flink] def registerAggregateFunctionInternal[T: TypeInformation, ACC: TypeInformation](</span><br><span class="line">      name: String, function: AggregateFunction[T, ACC]): Unit = &#123;</span><br><span class="line">    // check if class not Scala object</span><br><span class="line">    checkNotSingleton(function.getClass)</span><br><span class="line">    // check if class could be instantiated</span><br><span class="line">    checkForInstantiation(function.getClass)</span><br><span class="line"></span><br><span class="line">    val resultTypeInfo: TypeInformation[_] = getResultTypeOfAggregateFunction(</span><br><span class="line">      function,</span><br><span class="line">      implicitly[TypeInformation[T]])</span><br><span class="line"></span><br><span class="line">    val accTypeInfo: TypeInformation[_] = getAccumulatorTypeOfAggregateFunction(</span><br><span class="line">      function,</span><br><span class="line">      implicitly[TypeInformation[ACC]])</span><br><span class="line"></span><br><span class="line">    // register in Table API</span><br><span class="line">    functionCatalog.registerFunction(name, function.getClass)</span><br><span class="line"></span><br><span class="line">    // register in SQL API</span><br><span class="line">    val sqlFunctions = createAggregateSqlFunction(</span><br><span class="line">      name,</span><br><span class="line">      name,</span><br><span class="line">      function,</span><br><span class="line">      resultTypeInfo,</span><br><span class="line">      accTypeInfo,</span><br><span class="line">      typeFactory)</span><br><span class="line"></span><br><span class="line">    functionCatalog.registerSqlFunction(sqlFunctions)</span><br><span class="line">  &#125;</span><br><span class="line">```</span><br><span class="line">具体呢如下：</span><br><span class="line">- 一是，我们此处规范的是一个[Object,Object]的泛型，对于Accum类里的Jlong，JInteger没法起到限定，进而在解析时无法找到对应的类型，这个反应在TableEnvironment里面的T和ACC，T对应上了，而ACC却没有；</span><br><span class="line">- 二是，我们的Avg类里面，返回的却是一个 new TupleTypeInfo(classOf[WeightedAvgAccum], Types.LONG, Types.INT)和Types.LONG，那么不难发现，这个tuple里三个元素，我们其实只需要把第一个解析了，而另外两个都是套在它里面的，所以Object只有一个，而WeightedAvgAccum里却有三个，完全不对应，所以我们需要更改这两个类，改完后具体代码如下：</span><br><span class="line">- WeightedAvgAccum</span><br><span class="line">```</span><br><span class="line">/**</span><br><span class="line">  * Created by lx on 2018/11/22.</span><br><span class="line">  */</span><br><span class="line">class WeightedAvgAccum &#123;</span><br><span class="line">  var   sum = 1L</span><br><span class="line">  var   count = 2</span><br><span class="line">&#125;</span><br><span class="line">```</span><br><span class="line">- WeightedAvg</span><br><span class="line">```</span><br><span class="line">import org.apache.flink.api.common.typeinfo.TypeInformation</span><br><span class="line">import org.apache.flink.api.java.typeutils.TupleTypeInfo</span><br><span class="line">import org.apache.flink.table.api.Types</span><br><span class="line">import org.apache.flink.table.functions.&#123;AggregateFunction, UserDefinedFunction, utils&#125;</span><br><span class="line">import java.lang.&#123;Integer =&gt; JInteger, Long =&gt; JLong&#125;</span><br><span class="line">import org.apache.flink.table.functions.utils.UserDefinedFunctionUtils</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line">  * Created by lx on 2018/11/14.</span><br><span class="line">  */</span><br><span class="line">class WeightedAvg extends  AggregateFunction[JLong, WeightedAvgAccum]&#123;</span><br><span class="line"></span><br><span class="line">  override def createAccumulator(): WeightedAvgAccum = &#123;</span><br><span class="line">    new WeightedAvgAccum</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  override def getValue(acc: WeightedAvgAccum): JLong = &#123;</span><br><span class="line">    if (acc.count == 0) &#123;</span><br><span class="line">      null</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">      acc.sum / acc.count</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  def accumulate(acc: WeightedAvgAccum, iValue: JLong, iWeight: JInteger): Unit = &#123;</span><br><span class="line">    acc.sum += iValue * iWeight</span><br><span class="line">    acc.count += iWeight</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  def retract(acc: WeightedAvgAccum, iValue: JLong, iWeight: JInteger): Unit = &#123;</span><br><span class="line">    acc.sum -= iValue * iWeight</span><br><span class="line">    acc.count -= iWeight</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  def merge(acc: WeightedAvgAccum, it: java.lang.Iterable[WeightedAvgAccum]): Unit = &#123;</span><br><span class="line">    val iter = it.iterator()</span><br><span class="line">    while (iter.hasNext) &#123;</span><br><span class="line">      val a = iter.next()</span><br><span class="line">      acc.count += a.count</span><br><span class="line">      acc.sum += a.sum</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  def resetAccumulator(acc: WeightedAvgAccum): Unit = &#123;</span><br><span class="line">    acc.count = 0</span><br><span class="line">    acc.sum = 0L</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  override def getAccumulatorType: TypeInformation[WeightedAvgAccum] = TypeInformation.of(classOf[WeightedAvgAccum])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  override def getResultType: TypeInformation[JLong] = Types.LONG</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">```</span><br><span class="line">&gt; 那么具体运行如何呢，具体如下：</span><br><span class="line"></span><br><span class="line">![flink_running——picture](https://upload-images.jianshu.io/upload_images/13935362-f4e77ff8b1ca240f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)</span><br><span class="line"></span><br><span class="line"># 4.问题总结</span><br><span class="line">&amp;nbsp; &amp;nbsp;巴拉巴拉说了这么多，可能对于大神来说并不是什么新鲜问题，但是我相信初次接触的小白来讲还是或多或少有一些帮助的，所以希望后续在码代码的过程中要多方面去思考，也希望还是要加强对底层知识的深度认识，也能够更快的触类旁通，好啦，今天就到这啦，我是林夕，后面持续为大家带来我自己的一些见解和认知，撒由那拉</span><br></pre></td></tr></table></figure></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;日前，在更新UDF函数这块的一些功能时，发现一些较为细小但大家都会遇到的问题，作为趟过的坑发出来，希望大家能够避免。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;1-注册UDF函数&quot;&gt;&lt;a href=&quot;#1-注册UDF函数&quot; class=&quot;
      
    
    </summary>
    
      <category term="实用技术" scheme="http://ellenadams.github.io/categories/%E5%AE%9E%E7%94%A8%E6%8A%80%E6%9C%AF/"/>
    
      <category term="Flink" scheme="http://ellenadams.github.io/categories/%E5%AE%9E%E7%94%A8%E6%8A%80%E6%9C%AF/Flink/"/>
    
    
      <category term="flink" scheme="http://ellenadams.github.io/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink UDF</title>
    <link href="http://ellenadams.github.io/2019/07/27/flinkUDF/"/>
    <id>http://ellenadams.github.io/2019/07/27/flinkUDF/</id>
    <published>2019-07-27T02:05:11.631Z</published>
    <updated>2019-07-27T02:05:11.631Z</updated>
    
    <content type="html"><![CDATA[<p>本文会主要讲三种udf：</p><ul><li><p>ScalarFunction</p></li><li><p>TableFunction</p></li><li><p>AggregateFunction</p></li></ul><p>&nbsp; &nbsp; 用户自定义函数是非常重要的一个特征，因为他极大地扩展了查询的表达能力。本文除了介绍这三种udf之外，最后会介绍一个redis作为交互数据源的udf案例。</p><blockquote><p><strong>注册用户自定义函数</strong></p></blockquote><p>&nbsp; &nbsp;在大多数场景下，用户自定义函数在使用之前是必须要注册的。对于Scala的Table API，udf是不需要注册的。</p><p>&nbsp; &nbsp;调用TableEnvironment的registerFunction()方法来实现注册。Udf注册成功之后，会被插入TableEnvironment的function catalog，这样table API和sql就能解析他了。</p><h1 id="1-Scalar-Functions-标量函数"><a href="#1-Scalar-Functions-标量函数" class="headerlink" title="1.Scalar Functions 标量函数"></a>1.Scalar Functions 标量函数</h1><p>&nbsp; &nbsp;标量函数，是指返回一个值的函数。标量函数是实现将0，1，或者多个标量值转化为一个新值。</p><p>&nbsp; &nbsp;实现一个标量函数需要继承ScalarFunction，并且实现一个或者多个evaluation方法。标量函数的行为就是通过evaluation方法来实现的。evaluation方法必须定义为public，命名为eval。evaluation方法的输入参数类型和返回值类型决定着标量函数的输入参数类型和返回值类型。evaluation方法也可以被重载实现多个eval。同时evaluation方法支持变参数，例如：eval(String… strs)。</p><p>下面给出一个标量函数的例子。例子实现的是一个hashcode方法。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">public class HashCode extends ScalarFunction &#123;</span><br><span class="line">private int factor = 12;</span><br><span class="line">public HashCode(int factor) &#123;</span><br><span class="line">    this.factor = factor;</span><br><span class="line">&#125;</span><br><span class="line">public int eval(String s) &#123;</span><br><span class="line">   return s.hashCode() * factor;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">BatchTableEnvironment tableEnv = TableEnvironment.getTableEnvironment(env);</span><br><span class="line">// register the function</span><br><span class="line">tableEnv.registerFunction(&quot;hashCode&quot;, new HashCode(10));</span><br><span class="line">// use the function in Java Table API</span><br><span class="line">myTable.select(&quot;string, string.hashCode(), hashCode(string)&quot;);</span><br><span class="line">// use the function in SQL API</span><br><span class="line"></span><br><span class="line">tableEnv.sqlQuery(&quot;SELECT string, HASHCODE(string) FROM MyTable&quot;);</span><br></pre></td></tr></table></figure><p>&nbsp; &nbsp;默认情况下evaluation方法的返回值类型是由flink类型抽取工具决定。对于基础类型及简单的POJOS是足够的，但是更复杂的类型，自定义类型，组合类型，会报错。这种情况下，返回值类型的TypeInformation，需要手动指定，方法是重载ScalarFunction#getResultType()。</p><p>&nbsp; &nbsp;下面给一个例子，通过复写ScalarFunction#getResultType()，将long型的返回值在代码生成的时候翻译成Types.TIMESTAMP。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">public static class TimestampModifier extends ScalarFunction &#123;</span><br><span class="line">public long eval(long t) &#123;</span><br><span class="line">  return t % 1000;</span><br><span class="line">&#125;</span><br><span class="line">public TypeInformation&lt;?&gt; getResultType(signature: Class&lt;?&gt;[]) &#123;</span><br><span class="line">  return Types.TIMESTAMP;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="2-Table-Functions-表函数"><a href="#2-Table-Functions-表函数" class="headerlink" title="2.Table Functions 表函数"></a>2.Table Functions 表函数</h1><p>&nbsp; &nbsp;与标量函数相似之处是输入可以0，1，或者多个参数，但是不同之处可以输出任意数目的行数。返回的行也可以包含一个或者多个列。</p><p>&nbsp; &nbsp;为了自定义表函数，需要继承TableFunction，实现一个或者多个evaluation方法。表函数的行为定义在这些evaluation方法内部，函数名为eval并且必须是public。TableFunction可以重载多个eval方法。Evaluation方法的输入参数类型，决定着表函数的输入类型。Evaluation方法也支持变参，例如：eval(String… strs)。返回表的类型取决于TableFunction的基本类型。Evaluation方法使用collect(T)发射输出rows。</p><p>&nbsp; &nbsp;在Table API中，表函数在scala语言中使用方法如下：.join(Expression) 或者 .leftOuterJoin(Expression)，在java语言中使用方法如下：.join(String) 或者.leftOuterJoin(String)。</p><ul><li>Join操作算子会使用表函数(操作算子右边的表)产生的所有行进行(cross) join 外部表(操作算子左边的表)的每一行。</li></ul><ul><li>leftOuterJoin操作算子会使用表函数(操作算子右边的表)产生的所有行进行(cross) join 外部表(操作算子左边的表)的每一行，并且在表函数返回一个空表的情况下会保留所有的outer rows。</li></ul><p>在sql语法中稍微有点区别：</p><ul><li>cross join用法是LATERAL TABLE(<tablefunction>)。</tablefunction></li><li>LEFT JOIN用法是在join条件中加入ON TRUE。</li></ul><p>下面的例子讲的是如何使用表值函数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">// The generic type &quot;Tuple2&lt;String, Integer&gt;&quot; determines the schema of the returned table as (String, Integer).</span><br><span class="line"></span><br><span class="line">public class Split extends TableFunction&lt;Tuple2&lt;String, Integer&gt;&gt; &#123;</span><br><span class="line"></span><br><span class="line">  private String separator = &quot; &quot;;</span><br><span class="line">  public Split(String separator) &#123;</span><br><span class="line">      this.separator = separator;</span><br><span class="line">  &#125;</span><br><span class="line">  public void eval(String str) &#123;</span><br><span class="line">      for (String s : str.split(separator)) &#123;</span><br><span class="line">          // use collect(...) to emit a row</span><br><span class="line">          collect(new Tuple2&lt;String, Integer&gt;(s, s.length()));</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">BatchTableEnvironment tableEnv = TableEnvironment.getTableEnvironment(env);</span><br><span class="line">Table myTable = ...         // table schema: [a: String]</span><br><span class="line">// Register the function.</span><br><span class="line">tableEnv.registerFunction(&quot;split&quot;, new Split(&quot;#&quot;));</span><br><span class="line">// Use the table function in the Java Table API. &quot;as&quot; specifies the field names of the table.</span><br><span class="line">myTable.join(&quot;split(a) as (word, length)&quot;).select(&quot;a, word, length&quot;);</span><br><span class="line"></span><br><span class="line">myTable.leftOuterJoin(&quot;split(a) as (word, length)&quot;).select(&quot;a, word, length&quot;);</span><br><span class="line"></span><br><span class="line">// Use the table function in SQL with LATERAL and TABLE keywords.</span><br><span class="line">// CROSS JOIN a table function (equivalent to &quot;join&quot; in Table API).</span><br><span class="line">tableEnv.sqlQuery(&quot;SELECT a, word, length FROM MyTable, LATERAL TABLE(split(a)) as T(word, length)&quot;);</span><br><span class="line">// LEFT JOIN a table function (equivalent to &quot;leftOuterJoin&quot; in Table API).</span><br><span class="line">tableEnv.sqlQuery(&quot;SELECT a, word, length FROM MyTable LEFT JOIN LATERAL TABLE(split(a)) as T(word, length) ON TRUE&quot;);</span><br></pre></td></tr></table></figure><p>&nbsp; &nbsp;需要注意的是PROJO类型不需要一个确定的字段顺序。意味着你不能使用as修改表函数返回的pojo的字段的名字。</p><p>&nbsp; &nbsp;默认情况下TableFunction返回值类型是由flink类型抽取工具决定。对于基础类型及简单的POJOS是足够的，但是更复杂的类型，自定义类型，组合类型，会报错。这种情况下，返回值类型的TypeInformation，需要手动指定，方法是重载TableFunction#getResultType()。</p><p>下面的例子，我们通过复写TableFunction#getResultType()方法使得表返回类型是RowTypeInfo(String, Integer)。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">public class CustomTypeSplit extends TableFunction&lt;Row&gt; &#123;</span><br><span class="line">  public void eval(String str) &#123;</span><br><span class="line">      for (String s : str.split(&quot; &quot;)) &#123;</span><br><span class="line">          Row row = new Row(2);</span><br><span class="line">          row.setField(0, s);</span><br><span class="line">          row.setField(1, s.length);</span><br><span class="line">          collect(row);</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  @Override</span><br><span class="line">  public TypeInformation&lt;Row&gt; getResultType() &#123;</span><br><span class="line">      return Types.ROW(Types.STRING(), Types.INT());</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="3-Aggregation-Functions-聚合函数"><a href="#3-Aggregation-Functions-聚合函数" class="headerlink" title="3.Aggregation Functions 聚合函数"></a>3.Aggregation Functions 聚合函数</h1><p>&nbsp; &nbsp;用户自定义聚合函数聚合一张表(一行或者多行，一行有一个或者多个属性)为一个标量的值。<br>[图片上传失败…(image-f5e972-1542542047386)]<br>上图中是讲的一张饮料的表这个表有是那个字段五行数据，现在要做的是求出所有饮料的最高价。</p><p>&nbsp; &nbsp;聚合函数需要继承AggregateFunction。聚合函数工作方式如下：</p><ul><li><p>首先，需要一个accumulator，这个是保存聚合中间结果的数据结构。调用AggregateFunction函数的createAccumulator()方法来创建一个空accumulator.</p></li><li><p>随后，每个输入行都会调用accumulate()方法来更新accumulator。一旦所有的行被处理了，getValue()方法就会被调用，计算和返回最终的结果。</p></li></ul><p>对于每个AggregateFunction，下面三个方法都是比不可少的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">createAccumulator()</span><br><span class="line"></span><br><span class="line">accumulate()</span><br><span class="line"></span><br><span class="line">getValue()</span><br></pre></td></tr></table></figure><p>&nbsp; &nbsp;flink的类型抽取机制不能识别复杂的数据类型，比如，数据类型不是基础类型或者简单的pojos类型。所以，类似于ScalarFunction 和TableFunction，AggregateFunction提供了方法去指定返回结果类型的TypeInformation，用的是AggregateFunction#getResultType()。Accumulator类型用的是AggregateFunction#getAccumulatorType()。</p><p>&nbsp; &nbsp;除了上面的方法，还有一些可选的方法。有些方法是让系统更加高效的执行查询，另外的一些在特定的场景下是必须的。例如，merge()方法在会话组窗口（session group window）上下文中是必须的。当一行数据是被视为跟两个回话窗口相关的时候，两个会话窗口的accumulators需要被join。</p><p>AggregateFunction的下面几个方法，根据使用场景的不同需要被实现：</p><ul><li>retract()：在bounded OVER窗口的聚合方法中是需要实现的。</li><li>merge()：在很多batch 聚合和会话窗口聚合是必须的。</li><li>resetAccumulator(): 在大多数batch聚合是必须的。</li></ul><blockquote><p>AggregateFunction的所有方法都是需要被声明为public，而不是static。定义聚合函数需要实现org.apache.flink.table.functions.AggregateFunction同时需要实现一个或者多个accumulate方法。该方法可以被重载为不同的数据类型，并且支持变参。</p></blockquote><p>&nbsp; &nbsp;为了计算加权平均值，累加器需要存储已累积的所有数据的加权和及计数。在栗子中定义一个WeightedAvgAccum类作为accumulator。尽管，retract(), merge(), 和resetAccumulator()方法在很多聚合类型是不需要的，这里也给出了栗子。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line">* Accumulator for WeightedAvg.</span><br><span class="line">*/</span><br><span class="line">public static class WeightedAvgAccum &#123;</span><br><span class="line">  public long sum = 0;</span><br><span class="line">  public int count = 0;</span><br><span class="line">&#125;</span><br><span class="line">/**</span><br><span class="line">* Weighted Average user-defined aggregate function.</span><br><span class="line">*/</span><br><span class="line">public static class WeightedAvg extends AggregateFunction&lt;Long, WeightedAvgAccum&gt; &#123;</span><br><span class="line">  @Override</span><br><span class="line">  public WeightedAvgAccum createAccumulator() &#123;</span><br><span class="line">    return new WeightedAvgAccum();</span><br><span class="line">  &#125;</span><br><span class="line">  @Override</span><br><span class="line">  public Long getValue(WeightedAvgAccum acc) &#123;</span><br><span class="line">      if (acc.count == 0) &#123;</span><br><span class="line">          return null;</span><br><span class="line">      &#125; else &#123;</span><br><span class="line">          return acc.sum / acc.count;</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  public void accumulate(WeightedAvgAccum acc, long iValue, int iWeight) &#123;</span><br><span class="line">      acc.sum += iValue * iWeight;</span><br><span class="line">      acc.count += iWeight;</span><br><span class="line">  &#125;</span><br><span class="line">  public void retract(WeightedAvgAccum acc, long iValue, int iWeight) &#123;</span><br><span class="line">      acc.sum -= iValue * iWeight;</span><br><span class="line">      acc.count -= iWeight;</span><br><span class="line">  &#125;</span><br><span class="line">  public void merge(WeightedAvgAccum acc, Iterable&lt;WeightedAvgAccum&gt; it) &#123;</span><br><span class="line">      Iterator&lt;WeightedAvgAccum&gt; iter = it.iterator();</span><br><span class="line">      while (iter.hasNext()) &#123;</span><br><span class="line">          WeightedAvgAccum a = iter.next();</span><br><span class="line">          acc.count += a.count;</span><br><span class="line">          acc.sum += a.sum;</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  public void resetAccumulator(WeightedAvgAccum acc) &#123;</span><br><span class="line">      acc.count = 0;</span><br><span class="line">      acc.sum = 0L;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">// register function</span><br><span class="line">StreamTableEnvironment tEnv = ...</span><br><span class="line">tEnv.registerFunction(&quot;wAvg&quot;, new WeightedAvg());</span><br><span class="line">// use function</span><br><span class="line"></span><br><span class="line">tEnv.sqlQuery(&quot;SELECT user, wAvg(points, level) AS avgPoints FROM userScores GROUP BY user&quot;);</span><br></pre></td></tr></table></figure><h1 id="4-udf的最佳实践经验"><a href="#4-udf的最佳实践经验" class="headerlink" title="4.udf的最佳实践经验"></a>4.udf的最佳实践经验</h1><h2 id="4-1-Table-API和SQL"><a href="#4-1-Table-API和SQL" class="headerlink" title="4.1 Table API和SQL"></a>4.1 Table API和SQL</h2><p>&nbsp; &nbsp;代码生成器内部会尽可能多的尝试使用原生值。用户定义的函数可能通过对象创建、强制转换(casting)和拆装箱((un)boxing)引入大量开销。因此，强烈推荐参数和返回值的类型定义为原生类型而不是他们包装类型(boxing class)。Types.DATE 和Types.TIME可以用int代替。Types.TIMESTAMP可以用long代替。</p><p>&nbsp; &nbsp;建议用户自定义函数使用java编写而不是scala编写，因为scala的类型可能会有不被flink类型抽取器兼容。</p><h2 id="4-2-用Runtime集成UDFs"><a href="#4-2-用Runtime集成UDFs" class="headerlink" title="4.2 用Runtime集成UDFs"></a>4.2 用Runtime集成UDFs</h2><p>&nbsp; &nbsp;有时候udf需要获取全局runtime信息或者在进行实际工作之前做一些设置和清除工作，比如，打开数据库链接和关闭数据库链接。Udf提供了open()和close()方法，可以被复写，功能类似Dataset和DataStream API的RichFunction方法。</p><p>&nbsp; &nbsp;Open()方法是在evaluation方法调用前调用一次。Close()是在evaluation方法最后一次调用后调用。Open()方法提共一个FunctionContext，FunctionContext包含了udf执行环境的上下文，比如，metric group，分布式缓存文件，全局的job参数。</p><p>&nbsp; &nbsp;通过调用FunctionContext的相关方法，可以获取到相关的信息：</p><ul><li>getMetricGroup()并行子任务的指标组;</li><li>getCachedFile(name)分布式缓存文件的本地副本;</li><li>getJobParameter(name, defaultValue)给定key全局job参数;</li></ul><p>&nbsp; &nbsp;给出的例子就是通过FunctionContext在一个标量函数中获取全局job的参数。主要是实现获取redis的配置，然后简历redis链接，实现redis的交互的过程。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.flink.table.functions.FunctionContext;</span><br><span class="line">import org.apache.flink.table.functions.ScalarFunction;</span><br><span class="line">import redis.clients.jedis.Jedis;</span><br><span class="line">public class HashCode extends ScalarFunction &#123;</span><br><span class="line">  private int factor = 12;</span><br><span class="line">  Jedis jedis = null;</span><br><span class="line">  public HashCode() &#123;</span><br><span class="line">      super();</span><br><span class="line">  &#125;</span><br><span class="line">  @Override</span><br><span class="line">  public void open(FunctionContext context) throws Exception &#123;</span><br><span class="line">      super.open(context);</span><br><span class="line">      String redisHost = context.getJobParameter(&quot;redis.host&quot;,&quot;localhost&quot;);</span><br><span class="line">      int redisPort = Integer.valueOf(context.getJobParameter(&quot;redis.port&quot;,&quot;6379&quot;));</span><br><span class="line">      jedis = new Jedis(redisHost,redisPort);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  @Override</span><br><span class="line">  public void close() throws Exception &#123;</span><br><span class="line">      super.close();</span><br><span class="line">      jedis.close();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  public HashCode(int factor) &#123;</span><br><span class="line">      this.factor = factor;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  public int eval(int s) &#123;</span><br><span class="line">      s = s % 3;</span><br><span class="line">      if(s == 2)</span><br><span class="line">          return Integer.valueOf(jedis.get(String.valueOf(s)));</span><br><span class="line">      else</span><br><span class="line">          return 0;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">BatchTableEnvironment tableEnv = TableEnvironment.getTableEnvironment(env);</span><br><span class="line">// set job parameter</span><br><span class="line">Map&lt;String,String&gt; hashmap = new HashMap&lt;&gt;();</span><br><span class="line">       hashmap.put(&quot;redis.host&quot;,&quot;localhost&quot;);</span><br><span class="line">       hashmap.put(&quot;redis.port&quot;,&quot;6379&quot;);</span><br><span class="line">       ParameterTool parameter = ParameterTool.fromMap(hashmap);</span><br><span class="line">       exeEnv.getConfig().setGlobalJobParameters(parameter);</span><br><span class="line">// register the function</span><br><span class="line">tableEnv.registerFunction(&quot;hashCode&quot;, new HashCode());</span><br><span class="line">// use the function in Java Table API</span><br><span class="line">myTable.select(&quot;string, string.hashCode(), hashCode(string)&quot;);</span><br><span class="line">// use the function in SQL</span><br><span class="line">tableEnv.sqlQuery(&quot;SELECT string, HASHCODE(string) FROM MyTable&quot;);</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文会主要讲三种udf：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ScalarFunction&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;TableFunction&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;AggregateFunction&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&amp;nbsp; &amp;
      
    
    </summary>
    
      <category term="实用技术" scheme="http://ellenadams.github.io/categories/%E5%AE%9E%E7%94%A8%E6%8A%80%E6%9C%AF/"/>
    
      <category term="Flink" scheme="http://ellenadams.github.io/categories/%E5%AE%9E%E7%94%A8%E6%8A%80%E6%9C%AF/Flink/"/>
    
    
      <category term="flink" scheme="http://ellenadams.github.io/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>google streaming102</title>
    <link href="http://ellenadams.github.io/2019/07/27/streaming102/"/>
    <id>http://ellenadams.github.io/2019/07/27/streaming102/</id>
    <published>2019-07-27T02:04:03.579Z</published>
    <updated>2019-07-27T02:04:03.579Z</updated>
    
    <content type="html"><![CDATA[<h1 id="streaming现实中的解决之道"><a href="#streaming现实中的解决之道" class="headerlink" title="streaming现实中的解决之道"></a>streaming现实中的解决之道</h1><h1 id="简单回顾和路线图在Streaming"><a href="#简单回顾和路线图在Streaming" class="headerlink" title="简单回顾和路线图在Streaming"></a>简单回顾和路线图在Streaming</h1><p>&ensp; &ensp;101中，首先澄清了一些术语,介绍了有限数据 VS无限数据。有限数据源具有有限的大小，通常被称为“批处理”数据。无限数据源源可能具有无限大小，通常被称为“流”数据。在后边将会尽量避免使用批处理和流式传输来修饰数据源，因为这些名称带有一些令人误解和限制性的含义。</p><p>&ensp; &ensp;然后，解释了批处理和流处理引擎之间的区别：批处理引擎是设计优先考虑有限数据(现在批处理引擎提供了micro-batch的方式处理流式数据)，而流处理引擎设计用于处理无限数据。目标是在描述执行引擎时使用批处理和流处理。</p><p>&ensp; &ensp;定义完术语之后，介绍了与处理有限数据有关的两个重要的基本概念。首先阐述事件时间（事件发生的时间）和处理时间（数据在系统中被处理的时刻）之间的关键区别。这为Streaming 101中提出的主要论文提供了基础：如果关心事件实际发生时间，则必须基于事件的事件时间，而不是处理时间。</p><p>&ensp; &ensp;接下来介绍了窗口的概念（即沿时间边界切分数据集），这是一种常用的方法，用于应对无限数据源的数据处理，无限数据源理论上永远不会结束。窗口策略的最常见且简单的例子是固定和滑动的窗口，更复杂的窗口类型，例如会话窗口（其中窗口由数据本身的特征决定，捕获每个用户的活动会话窗口，会话窗口之后紧接着是用户的不活动期）也比较广泛的用法。</p><blockquote><p>除了前文中介绍的概念，现在再介绍3个新的概念：</p></blockquote><ul><li><p>Watermark：Watermark是相对于事件时间的输入完整性的概念。Watermark表示一个时间X，表示所有事件时间&lt;X的所有数据到到齐了。因此，当处理无限数据源时，Watermark作为进度的度量。</p></li><li><p>触发器：触发器是一种由外部条件触发，来表明何时计算窗口结果的机制。触发器可以让我们灵活的选择何时计算结果并发送给下游，而且随着数据的不停的到来，窗口的可以产生多次输出。所以，窗口结束前可以先提供近似结果，并且能够灵活应对上游数据的变化(可能是上游发送的数据修正)或者数据延迟到达（例如，移动场景在某人的离线时，某人的电话记录了各种动作及其事件时间，然后在重新获得连接时继续上传这些事件进行处理）。</p></li><li><p>累积：累积模式指定在同一窗口中观察到的多个结果之间的关系。这些结果可能完全相互之间完全独立，或者它们之间可能存在重叠。不同的累积模式具有不同的语义和与计算成本，适用于不同的场景。</p></li></ul><p>最后，在回答无限数据处理中的4个问题时，更容易搞清楚这些概念和它们之间的关联关系：</p><p>• <strong>What 计算的结果是什么？</strong> </p><p>Pipeline中的转换来决定结果。例如计算总和，构建直方图，训练机器学习模型等等。它也是经典批处理回答的问题。</p><p>• <strong>Where 在事件时间中的哪个位置计算结果？</strong> </p><p>这个问题是通过在Pipeline中使用事件时间窗口来回答的。这包括从Streaming 101（固定，滑动和会话）窗口的常见示例，似乎没有窗口概念的用例（例如，Streaming 101中描述的时间不可知处理;经典批处理也通常属于此类别）和其他更复杂的窗口类型，如时间有限的拍卖。还要注意，它可以包括处理时间窗口，如果在记录到达系统时将入口时间指定为记录的事件时间。</p><p>• <strong>When 在处理时间中的哪个时刻触发计算结果？</strong> </p><p>通过使用Watermark和触发器来回答的这个问题。这个主题有无穷的变化，但最常见的模式是在给定窗口的输入完成时使用Watermak来描绘，触发器允许提前计算结果（对于在窗口完成之前发出的推测性的、部分的结果）和延迟计算结果（Watermark只是预估窗口的数据全部到达,并不是100%确定，在Watermark声明给定窗口的全部到达之后，也有可能会有隶属于该窗口的数据到达）。</p><p>• <strong>How 如何修正结果</strong> </p><p>这个问题由所使用的累积类型回答：丢弃（其中结果是相互独立和不同的），累加（后来的结果建立在先前的结果上），累加和撤销（当前的累加值和上次触发的值撤销一起发送）。</p><p>后边将一一讨论这些问题，试图让大量清楚哪些概念与What/Where/When/How中的哪个问题有关。</p><h1 id="Streaming-101-回顾"><a href="#Streaming-101-回顾" class="headerlink" title="Streaming 101 回顾"></a>Streaming 101 回顾</h1><p>首先，回顾一下Streaming 101中提出的一些概念，这一次还将提供一些具体的例子使这些概念更具体。</p><h2 id="What-Transform-变换"><a href="#What-Transform-变换" class="headerlink" title="What:Transform(变换)"></a>What:Transform(变换)</h2><p>&ensp; &ensp; 经典批处理中Transform解决了以下问题：“要计算什么结果？”许多人可能已经熟悉经典的批处理，所以我们将以它为基础，添加所有其他概念，更便于理解。</p><p>&ensp; &ensp; 对于这一部分，我们来看一个示例：计算由10个整数值组成的简单数据集中的数的总和。这么说有点抽象，在实际中，可以想象一个游戏，10个人组成一个团队，每个人的最终得分相加，就是团队的成绩。也可以想象计费和使用情况的监控使用情况这样的场景。</p><p>&ensp; &ensp;   对于每个示例，将包括一个简短的Dataflow Java SDK伪代码片段，以使Pipeline的定义更具体。因为是伪代码，所以有时会省略细节（如使用具体的I / O源）、使用简称（Java中的当前触发器名称太冗长）。除了这些（大部分我在Postscript中明确列举）的小事情之外，其它基本上是真实的Dataflow SDK代码。稍后还将提供一个链接到实际的代码演练，可以编译和运行自己的类似例子感兴趣的人，可以实际尝试一下。</p><p>&ensp; &ensp;  如果熟悉像Spark Streaming或Flink这样的计算引擎，那么在看Dataflow示例代码的时候就会容易一些。接下来开始让人崩溃的旅程，在Dataflow中有两个基本的原语：</p><ul><li>PCollection</li></ul><p>表示可以由PTransfrom并行处理的数据集，（因此名称开始处的“P”），可以是任意规模的数据集。</p><ul><li>PTransform转换</li></ul><p>处理PCollection并创建新的PCollection。 PTransform可以执行元素转换，它们可以将多个元素聚合在一起，或者它们可以是其他PTransform的组合。</p><p><img src="http://upload-images.jianshu.io/upload_images/13935362-6a8f8e5b6b16e118?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"><br>图1 Transform变换的类型</p><p>&ensp; &ensp;如果觉得不甚明白，或者只是想要参考，可以看Google Dataflow Java SDK文档。</p><p>&ensp; &ensp;为了对例子说明，假设我们从一个PCollection &lt;KV &lt;String，Integer &gt;&gt;命名为“input”（即由一个键/值对的字符串和整数组成的PCollection，其中字符串是类似团队名称，整数是相应团队中个人的得分）。在现实世界的Pipeline中，通过从I / O源读取PCollection原始数据（例如日志记录）获得输入，将日志记录解析为适当的键/值对,然后将其转换为PCollection &lt;KV &lt;String，Integer &gt;&gt; 。为了在第一个例子中清楚起见，将包括所有这些步骤的伪代码，但是在随后的例子中，删除了I / O和解析部分。</p><p>&ensp; &ensp;因此，对于简单地从I / O源读取数据的管道，解析出团队/分数键值对，并计算每队的得分数，代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">PCollection&lt;String&gt; raw = IO.read(...);</span><br><span class="line">        PCollection&lt;KV&lt;String, Integer&gt;&gt; input = raw.apply(ParDo.of(new ParseFn());</span><br><span class="line">        PCollection&lt;KV&lt;String, Integer&gt;&gt; scores = input</span><br><span class="line">          .apply(Sum.integersPerKey());</span><br></pre></td></tr></table></figure><p>列表1.计算总和Pipeline。从数据源读取键值对数据，键是String类型(团队名称)，值是Integer类型（团队中各人得分）。然后对每个键(团队)计算总和(团队得分),并输出。</p><p>&ensp; &ensp;对于所有的示例，在每个示例的Pipeline的代码片段之后，有1个该Pipeline执行的动画示例。动画中看到一个Key（即一个团队）的10条输入数据执行Pipeline的样子;在一个实际的Pipeline中，类似的操作将有成千上万个，在很多台机器上并行执行。为了能清晰的说明，示例中演示了1个Key的执行过程。</p><p>&ensp; &ensp;动画中每个点代表一个输入或输出数据，输入和输出都有两个时间维度：事件时间（X轴）和处理时间（Y轴）。因此，Pipeline按照处理时间维度执行，从下向上延伸，如加粗的上升白线所示。输入是圆圈，圆圈内的数字代表该特定记录的值。输入开始是灰色圆圈，随着Pipeline处理变换颜色。</p><p>&ensp; &ensp;当Pipeline处理到某一个值的时候，会将其累加并记录在State中，并最终将聚合结果作为输出。State和输出由矩形表示，矩形顶部不断变化的数字表示累加值，矩形覆盖的区域表示到当前处理时刻，所有矩形中的数据已经被处理。对于清单1中的Pipeline，在经典批处理引擎上执行时，会看起来像这样（请注意，点击下面的图片启动动画，然后会一直循环播放）：</p><p>[图片上传失败…(image-974d37-1542359894383)]<br>图2.经典的批处理</p><p>&ensp; &ensp;上边是在批处理引擎上执行Pipeline，累加输入的数据，直到所有输入处理完毕（由顶部的虚线绿色线表示），此时输出为51。在此示例中，因为没有应用任何特定的窗口，所以在事件时间维度上计算了整个数据集的总和; 因此，用于累加的State和输出的矩形覆盖X轴的整体。 但是，如果要处理一个无限数据源，那么经典批处理将是不够的，不能等待输入结束，因为它实际上永远不会结束。 所以需要的使用在Streaming 101中提到的一个概念是—窗口。因此，想要回答第二个问题“在事件时间的哪个位置计算结果？”，现在先简要回顾一下窗口。</p><h2 id="Where-窗口"><a href="#Where-窗口" class="headerlink" title="Where: 窗口"></a>Where: 窗口</h2><p>&ensp; &ensp;窗口化是把数据在时间上进行切分。常见的窗口策略有：固定窗口、滑动窗口、会话窗口。<br><img src="http://upload-images.jianshu.io/upload_images/13935362-5412eb56911fa7c4?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"><br>图3. 窗口类型示例，每个窗口类型中包含了3个key，图中呈现了对齐的窗口(应用在整个数据集上)和非对齐窗口(应用在数据子集上).</p><p>&ensp; &ensp;为了更好地了解实际中的如何使用窗口，来看一下的上边提到的整数求和Pipeline，使用了长度为2分钟的时间窗口。 使用Dataflow SDK，只需要简单的添加Window.into Transform变化即可（以蓝色文本突出显示）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">PCollection&lt;KV&lt;String, Integer&gt;&gt; scores = input</span><br><span class="line"> .apply(Window.into(FixedWindows.of(Duration.standardMinutes(2))))</span><br><span class="line">  .apply(Sum.integersPerKey());</span><br></pre></td></tr></table></figure><p>列表2. 使用窗口的求和代码</p><p>&ensp; &ensp;回想一下，Dataflow提供了一种统一的批处理和流处理模型，因为语义上，批处理只是流处理的一个子集。 因此，首先在批处理引擎上执行此Pipeline; 在批处理引擎上执行此Pipeline，原理简单明了，可以很好的跟在流处理引擎上执行做对比。<br>[图片上传失败…(image-81bcc8-1542359894383)]<br>图4在批处理引擎上执行基于窗口的求和</p><p>&ensp; &ensp;如前所述，输入在不断累加存储在State中，直到输入被完全处理，然后产生输出。 然而，在这种情况下，不是1个输出，而是4个：在时间上切分成了4个事件时间窗口，每个窗口产生一个输出。</p><p>&ensp; &ensp;到此为止，我们重新回顾了Streaming 101中引入的两个主要概念：事件时间和处理时间之间的关系以及窗口。 再进一步，开始阐述本节开头提到的新概念：Watermark，触发器和累积。 下边开始Streaming 102。</p><h1 id="Streaming-102"><a href="#Streaming-102" class="headerlink" title="Streaming 102"></a>Streaming 102</h1><p>&ensp; &ensp;在上边我们看到了在批引擎上执行使用了窗口的Pipeline。 理想情况下，我们希望具有较低的处理延迟，同时也希望能涵盖对无限数据集的处理。 切换到流式引擎是朝着正确方向迈出的一步。批处理引擎可以明确的知道，每个窗口的数据是否完整了（即，有限数据集中所有的数据都被处理了），但目前缺乏确定无限数据集的完整性的实用方法。 接下来介绍Watermark。</p><h2 id="When-Watermark"><a href="#When-Watermark" class="headerlink" title="When: Watermark"></a>When: Watermark</h2><p>&ensp; &ensp;Watermark是问题答案的前半部分：“在处理时间维度上，什么时候计算窗口的结果？”</p><p>&ensp; &ensp;Watermark是事件时间中输入完整性的时间概念。 换句话说，它们是系统根据当前处理的数据的事件时间判断处理进度和完整性的方法（有限或无限数据集，在无限数据的情况下作用更为明显）。</p><p>&ensp; &ensp;回想一下Streaming 101中这个图，这里稍作修改，其中描述了事件时间和处理时间之间的偏差，大多数真实世界的分布式数据处理系统中时间偏差一直在变化。<br><img src="http://upload-images.jianshu.io/upload_images/13935362-195a775d4aaf0fb0?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"><br>图5. 事件时间进度, 偏差, 和watermark</p><p>&ensp; &ensp;图中表示现实(reality)的曲折红线本质上是Watermark。随着处理时间的推移，它跟踪事件时间完整性的进度。在概念上，可以将Watermark视为函数F(P) - &gt; E，在处理时间中选取一个点，返回事件时间的一个点。 （更准确地说，对函数的输入实际上是在Pipeline中观察到Watermark的点上游的一切的当前状态：输入源，缓冲数据，正在处理的数据等;但在概念上，将其视为从处理时间到事件时间的映射更简单。）事件时间点E是系统认为事件时间小于E的所有数据都到齐了。换句话说，这是一个断言，不再有更多的事件时间少于E的数据。根据Watermark的类型：完美的或启发式的，这种断言可能是严格的保证或经过训练的猜测：</p><ul><li><strong>理想Watermark</strong></li></ul><p>在完全了解所有输入数据的情况下，可以构建理想的Watermark; 在这种情况下，没有延迟数据; 所有数据都提前或准时到达。</p><ul><li><strong>启发式Watermark</strong></li></ul><p>对于许多分布式输入源，完全了解输入数据是不切实际的，在这种情况下，最佳选择是提供启发式水印。 启发式Watermark使用任何有关输入的信息（分区，分区内排序，文件增长率等），以提供尽可能准确的进度估计。 在许多情况下，启发式Watermark可以预测的非常准确。 即使如此，使用启发式Watermark意味着它有时可能是不正确的的，这将导致有些数据被划分为延迟数据。 我们将在下面的触发器部分中了解如何处理延迟数据。</p><p>&ensp; &ensp;Watermark是一个有趣和复杂的话题，未来会写一篇新的文章专门阐述。 现在，为了更好地了解Watermark的作用以及缺点，我们来看一下使用Watermark的流处理引擎的两个例子，以确定何时在清单2中执行使用窗口的Pipeline时实现输出。 左边的例子使用理想的Watermark; 右边的一个使用启发式Watermark。<br>[图片上传失败…(image-e28956-1542359894383)]<br>图6. 在流处理引擎上使用理想（左）和推测(右)Watermark进行基于窗口的求和</p><p>&ensp; &ensp;在这两种情况下，当Watermark通过窗口的末尾时，窗口被触发计算。两个执行的主要区别在于右侧的Watermark计算中使用的启发式算法，值9因为迟到的问题而没有被计算在内，这大大改变了水印的形状[3]。这些例子突出了Watermark的两个缺点，具体如下：</p><ul><li><strong>太慢</strong> </li></ul><p>&ensp; &ensp;当任何类型的Watermark，由于已知的未处理数据（例如，由于网络带宽约束而缓慢增长的输入日志）被正确地延迟时，如果结果的计算只依赖Watermark的触发，将直接导致输出结果的延迟。<br>&ensp; &ensp;这在左图中是最明显的，即迟到的9阻止所有后续窗口的Watermark，即使这些窗口的输入数据已经更早的达到并且是完整的了。第二个窗口[12:02，12:04]尤其明显，从窗口中的第一个值到达到窗口计算并输出结果的时间需要将近七分钟。这个例子中的启发式Watermark要稍微好一点（五分钟直到输出），但这不意味着启发式Watermark从来不会受到其他Watermark滞后的影响;在本例子选择了特殊的数据突出了这种对比。<br>&ensp; &ensp;这里的重点在于：Watermark提供了一个非常有用的完整性概念，从延迟的角度来看，只考虑完整性是不够的。想象一下一个仪表板，显示重要的指标，按小时或天显示。我们不太可能想等待一整个小时或一天才能查看当前窗口的结果;这是使用经典批处理系统为这种系统提供数据的痛点之一。相反，随着输入的演变和最终的完成，这些窗口的结果会随着时间的推移而持续并不断的更新更好一些。</p><ul><li><strong>太快</strong></li></ul><p>&ensp; &ensp;当一个启发式Watermark比实际的Watermark更快的向前推进时，会导致原来没有延迟的数据变成了延迟数据。这是在右边的例子中发生的情况：在第1个窗口的输入数据全部到达之前，Watermark进入第1个窗口的末尾，导致错误的输出值为5而不是14。这个缺点是严格的启发式Watermark的问题;既然是启发式就意味着有时会是错误的。因此，如果关心正确性，单纯依靠Watermark确定何时计算结果并发出是不够的。</p><p>&ensp; &ensp; 在Streaming 101中，对关于无限数据流的强大的无序处理不足的完整性概念作了一些强调。Watermark太慢或太快，是这些论据的基础。完全依赖于完整性概念的系统无法同时获得低延迟和正确性。触发器是解决这些缺点解决方案。</p><h2 id="When-触发器"><a href="#When-触发器" class="headerlink" title="When:触发器"></a>When:触发器</h2><p>&ensp; &ensp;触发器是问题的另一半答案：“在处理时间维度上，什么时候该计算窗口的结果并发出？”触发器用来表明在处理时间维度上的哪个时刻该触发窗口计算结果（尽管触发器本身可能会根据其他时间触发，例如在事件时间维度上使用Watermark）。 窗口的每个特定输出都称为窗口的窗格（Pane）。</p><p>&ensp; &ensp;用于触发的信号的示例包括：</p><ul><li>Watermark进度 </li></ul><p>即事件时间进度，是图6中我们已经看到的隐式版本，当Watermark通过窗口的末尾时，计算结果并输出[4]。另一个用例是在窗口的生命周期末尾时触发垃圾回收，稍后我们将看到一个例子。</p><ul><li>处理时间进度 </li></ul><p>对于提供定期的定期更新是有用的，因为处理时间（不像事件时间）总是均匀地，没有延迟地演进。</p><ul><li>元素计数 </li></ul><p>在窗口中累积有n条数据之后触发。</p><ul><li>标点或其他依赖于数据的触发器</li></ul><p>其中记录的一些记录或特征（例如，EOF元素或刷新事件）指示应当生成输出。</p><p>除了基于具体信号触发的简单触发器之外，还有复合触发器，允许创建更复杂的触发逻辑。示例复合触发器如下：</p><ul><li>Repeat重复触发器</li></ul><p>重复触发器特别适用于处理时间触发器以提供定期更新。</p><ul><li>AND触发器（逻辑AND） </li></ul><p>所有子触发器都符合触发条件才触发（例如，在Watermark通过窗口结束之后，我们观察到一个终止的标点符号记录），它才会触发。</p><ul><li>Or触发器（逻辑或）</li></ul><p>子触发器中的任何一个符合触发条件都会引起触发（例如，在水印通过窗口结束之后或我们观察到终止的标点符号记录）时。</p><ul><li>Sequence触发器 </li></ul><p>以子触发器按照预定义的顺序触发子依次触发。</p><p>为了使触发器的概念更具体，继续介绍图6中使用的隐式默认触发器，将其添加到清单2中的代码中：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">PCollection&lt;KV&lt;String, Integer&gt;&gt; scores = input</span><br><span class="line"> .apply(Window.into(FixedWindows.of(Duration.standardMinutes(2)))</span><br><span class="line">               .triggering(AtWatermark()))</span><br><span class="line">  .apply(Sum.integersPerKey());</span><br></pre></td></tr></table></figure><p>清单3. 明确设定默认触发器</p><p>&ensp; &ensp;对触发器能够做什么有了基本的了解，可以开始考虑解决Watermark太慢或太快的问题。在这两种情况下，我们希望在Watermark超过窗口末尾之前或之后能够有机会计算窗口的结果，并能够提供持续更新的机制（除了Watermark超过窗口末尾那一刻）。所以，需要一些多次触发触发器。那么问题就变成了：多次触发用来干什么？</p><ul><li><p><strong>在太慢的情况下</strong>，即提供提前的推测结果，我们可能应该假设任何给定的窗口可能有稳定的输入数据，因为我们知道（通过窗口的早期阶段），我们观察到的这个窗口的输入是非常不完整的。因此，当处理时间提前（例如，每分钟一次）时周期性地触发可能是明智的，因为触发发射的数量将不依赖于实际观察到的窗口的数据量;在最坏的情况下，我们只会得到稳定的定期触发发射。</p></li><li><p><strong>在太快的情况下</strong>（即，由于启发式Watermark可能存在错误的推测，所以需要一种机制去能够处理延时数据去修正计算结果），假设Watermark基于相对准确的启发式（通常是相当安全的假设）。在这种情况下，预计不会经常看到延迟很久的数据，但是在实际中确实存在挺多延迟数据，不过结果很快会得到修正。每收到1个延时数据触发一次的策略，能够让我们更快的修正更新计算结果，但是由于预期的后期数据不频繁，应该不会给系统带来大的冲击。请注意，这些只是示例：如果有不同的应用场景，可以自由选择不同的触发器（或选择不适用触发器）。</p></li></ul><p>&ensp; &ensp;最后，我们需要协调这些各种触发器的时间安排：提前，准时和延迟。我们可以使用Sequence触发器和一个特殊的OrFinally触发器组合来实现，OrFinally触发器用来中止这个组合触发器。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">PCollection&lt;KV&lt;String, Integer&gt;&gt; scores = input</span><br><span class="line"> .apply(Window.into(FixedWindows.of(Duration.standardMinutes(2)))</span><br><span class="line">               .triggering(Sequence(</span><br><span class="line">        Repeat(AtPeriod(Duration.standardMinutes(1)))</span><br><span class="line">                   .OrFinally(AtWatermark()),</span><br><span class="line">                 Repeat(AtCount(1))))</span><br><span class="line">  .apply(Sum.integersPerKey());</span><br></pre></td></tr></table></figure><p>清单4. 手动设定提前也延迟触发<br>&ensp; &ensp;如上所示，伪代码看起来不错，给出了提前、准时、延迟触发的常用模式，使用略有不便，对应在Dataflow中，提供了一个定制（但语义上相当的）API，使得更容易使用这样的触发器，如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">PCollection&lt;KV&lt;String, Integer&gt;&gt; scores = input</span><br><span class="line">  .apply(Window.into(FixedWindows.of(Duration.standardMinutes(2)))</span><br><span class="line">               .triggering(</span><br><span class="line">                 AtWatermark()</span><br><span class="line">                   .withEarlyFirings(AtPeriod(Duration.standardMinutes(1)))</span><br><span class="line">                   .withLateFirings(AtCount(1))))</span><br><span class="line">  .apply(Sum.integersPerKey());</span><br></pre></td></tr></table></figure><p>清单5. 使用early/late api指定提前和延迟触发</p><p>&ensp; &ensp;在流处理引擎上执行清单4或清单5中的示例（包含了理想的Watermark和启发式的Watermak），如下所示：<br>[图片上传失败…(image-c24118-1542359894383)]<br>图 7. 在流处理引上执行基于窗口的求和，使用提前和延迟触发</p><p>&ensp; &ensp;这个版本对图6有两个明显的改进： </p><ol><li>对于第二个窗口中的“Watermark太慢”的情况，[12:02，12:04]：我们现在每分钟提供一次定期的提前计算。在理想的Watermark案例中，差异最为突出，其中时间到首次输出从近7分钟降至3分半;在启发式案例中也有明显改善。这两个版本现在都可以随着时间的推移而稳定地进行计算和修正计算结果（具有值7,14，然后是22的窗格），降低了从数据输入到得到计算结果之间的延迟。</li><li>对于第一个窗口中的“启发式Watermark太快”的情况，[12:00，12:02]：当9的值延迟到达时，立即将其合并到一个值为14的新的修正的窗格中。<br>这些新触发器的一个有趣的副作用是，它们有效地使理想和启发式Watermark版本之间的输出模式标准化。而图6中的两个版本是截然不同的，而现在这两个版本看起来很相似。</li></ol><p>&ensp; &ensp;此时剩下的最大差异是窗口生命周期。在理想的Watermark案例中，当Watermark超过窗口末尾后，窗口过期，窗口中的数据再也不会被处理，可以被安全的回收。在启发式Watermark案例中，我们仍然需要保留窗口一段时间来处理延迟数据。但是到目前为止，系统没有任何好的方式知道每个窗口需要保留多长时间。这是最大允许延迟的用武之地。</p><h2 id="When-最大允许延迟-超过即可回收"><a href="#When-最大允许延迟-超过即可回收" class="headerlink" title="When: 最大允许延迟(超过即可回收)"></a>When: 最大允许延迟(超过即可回收)</h2><p>&ensp; &ensp;在谈到最后一个问题（“如何修正结果？”）之前，先来聊一下持续运行、乱序数据流处理系统中的实际面对的问题：垃圾收集。在图7中的启发式Watermark示例中，每个窗口的持续状态在该示例的整个生命周期内都会持续;这是必要的，以便在到达时适当地处理延迟数据。但是，尽管能够保留所有持续状态，直到数据全部处理完毕。实际上，当处理无限数据源时，一直保留给定窗口的状态（包括元数据）通常是不切实际;最终会耗尽内存、磁盘等的空间。<br>&ensp; &ensp;因此，任何现实世界的无序处理系统都需要提供一些限制其正在处理的窗口的生命周期的方法。最简洁的实现方在系统内定义一个最大允许延迟的边界，即限制任何给定记录最晚到达时间（相对于Watermark时间）不能超过这个时间;任何超过这个时间的数据不再处理，直接丢弃掉。定义了最大允许延迟之后，还需要准确地确定窗口需要保留的时间：直到Watermark超过了窗口的末尾时间+最大允许延迟时间[5]。允许系统丢弃超过最大延迟的数据，还能够节省系统的计算资源。<br>&ensp; &ensp;由于最大允许延迟和Watermark之间的相互作用有点晦涩，举个例子说明一下。我们来看一下清单5 /图7中的启发式Watermark Pipeline，并添加1分钟的最大允许延迟时间（请注意，之所以选择1分钟是为了更好的在图中说明概念，在现实世界中需要根据场景来确定合理的最大允许延迟时间）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">PCollection&lt;KV&lt;String, Integer&gt;&gt; scores = input</span><br><span class="line">  .apply(Window.into(FixedWindows.of(Duration.standardMinutes(2)))</span><br><span class="line">               .triggering(</span><br><span class="line">                 AtWatermark()         .withEarlyFirings(AtPeriod(Duration.standardMinutes(1)))</span><br><span class="line">                   .withLateFirings(AtCount(1)))</span><br><span class="line">       .withAllowedLateness(Duration.standardMinutes(1)))</span><br><span class="line">  .apply(Sum.integersPerKey());</span><br></pre></td></tr></table></figure><p>清单6. 带有最大允许延迟的提前和延迟触发</p><p>&ensp; &ensp;这个Pipeline的执行看起来像下面的图8所示，添加了以下功能来突出显示允许的延迟效应：</p><ul><li><p>加粗的水平方向的白线表示当前的处理时间，注释为Lateness Horizon的小刻度表示窗口的最大延时线（事件时间）。</p></li><li><p>一旦Watermark超过窗口的最大延迟线，该窗口将被回收，这意味着窗口的所有信息都将被销毁。</p></li><li><p>虚线的矩形，表示窗口关闭时窗口覆盖的时间范围（在处理时间和事件时间两个维度上），一个小尾巴向右延伸，以表示窗口的延迟水平（与Watermark对照）。</p></li></ul><p>&ensp; &ensp;在这个图中，为第一个窗口添加了一个额外的延迟数据6。6相对窗口是迟到的，但仍然在允许的最大延迟时间范围内，所以6被累加修正计算结果为11。然而，9 超过了最大允许延迟，直接被丢弃掉。<br>[图片上传失败…(image-d4bee5-1542359894383)]<br>图8：在流处理引擎上切分窗口并计算，窗口使用提前、延迟触发，并设置了最大允许延迟时间<br>&ensp; &ensp;关于最大迟延线的两个最后的说明：</p><ul><li>要完全清楚，如果正在从能够提供理想Watermark的资源中获取数据，则无需处理延迟数据，而0秒的最大延迟时间将是最佳的。这是我们在图7的理想Watermark部分中看到的。</li><li>有一些例外情况不需要指定最大延迟，即使在使用启发式Watermark时，比如在数据覆盖的时间的范围内，对有限的key进行统计，（例如，数据覆盖的时间的范围内内，按照Web浏览器分组，统计网站的总访问次数）。在这种情况下，系统中活动窗口的数量受限于使用的Key的数量。只要Key的数量仍然很低，就无须通过设置最大允许的延迟时间来限制窗口的生命周期。</li></ul><p>&ensp; &ensp;接下来继续讨论第4个也是最后一个问题。</p><h2 id="How-累积"><a href="#How-累积" class="headerlink" title="How: 累积"></a>How: 累积</h2><p>&ensp; &ensp;随着时间推移，触发器被用于为一个窗口生成多个窗格，我们发现自己面临最后一个问题：“如何随着时间修正结果？”在我们已经看到的例子中，每个窗格建立在其前一个窗格基础之上。然而，实际上有三种不同的累积方式[6]：</p><ul><li><strong>丢弃</strong></li></ul><p>&ensp; &ensp;每当窗格计算完毕时，任何存储的窗口状态都将被丢弃。这意味着每个窗格与之前的窗格都是相互独立的。当下游消费者本身正在执行某种累加时，例如当将整数发送到希望自己计算总和的系统时，丢弃模式是有用的，下游系统将数据累加在一起形成最后的结果。</p><ul><li><strong>累加</strong></li></ul><p>&ensp; &ensp;如图7所示，每当窗格计算完毕时，保留该窗格所有的状态，未来输入的数据会累加到并更新现有状态。这意味着窗格是建立在前面窗格的基础之上的。以后的结果可以简单地覆盖以前的结果，例如在诸如BigTable或HBase的键/值存储中存储输出结果时，累加模式很有用。</p><ul><li><strong>累加和撤销</strong></li></ul><p>&ensp; &ensp;像累加模式一样，但是当生成新窗格时，同时会为前一个窗格生成1个独立的撤销。撤销（与新的累加结果一起）本质上是在表达，“我以前告诉过你的结果是X，但我错了。撤销我上次告诉你的X，并将其替换为Y.“有两种情况，撤销是特别有用的：</p><p>• 当下游消费者将不同维度的数据重新分组时，新值可能会与先前的值不同，因此最终会在不同的组中。在这种情况下，新值不能简单的覆盖旧值;需要从旧组中删除旧值，然后将新值添加到新组中。</p><p>• 当使用动态窗口（例如，后边会有更详细的介绍）时，由于窗口合并，新值可能会替换多个旧窗口。在这种情况下，只从新窗口的信息中难以确定哪些旧窗口中需要撤销。对于旧的窗口进行明确的撤销使得任务变得简单明了。</p><p>&ensp; &ensp;放在一起看时，每个类型的累加语义会更清晰。考虑图7中第二个窗口的三个窗格（事件时间范围[12:02，12:04））。下表显示了三个支持的累加模式（每个窗格的值）将在三种支持的累加模式中显示（累积模式是图7中使用的特定模式）：<br><img src="http://upload-images.jianshu.io/upload_images/13935362-6134642f155153a2?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"><br>表1. 对比三种累积模式，使用了图7中的第2个窗口</p><ul><li>*<em>丢弃 *</em></li></ul><p>每个窗格仅包含在特定窗格中到达的值。因此，该窗口的最终值是最后一个窗格的值，而不是总和。但是，如果要自己计算所有独立窗格，将得到正确的答案22.这就是为什么丢弃模式下，下游消费者自己在窗格上执行聚合时很有用。</p><ul><li><strong>累加</strong> </li></ul><p>如图7所示，每个窗格包含在该特定窗格中到达的值以及前一个窗格中的所有值。因此，最后一个窗格的值是该窗口所有值的总和22。但是，如果要自己累加该窗口的所有窗格，则会对来自窗格2和窗格1的输入进行双重和三重计数，给出的总和是不正确的51.这就是为什么累加模式是最有用的，可以简单地用新的值覆盖以前的值，新值已经包含了迄今为止收到的所有数据。</p><ul><li><strong>累积和撤销</strong><br>每个窗格都包含一个新的累加模式值以及前一个窗格值的撤销。因此，观察到的最后（非撤销）值以及所有窗格（包括撤销）的总和是正确的答案22.这就是为什么撤回是如此强大。</li></ul><p>下边的代码示例了丢弃模式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">PCollection&lt;KV&lt;String, Integer&gt;&gt; scores = input</span><br><span class="line"> .apply(Window.into(FixedWindows.of(Duration.standardMinutes(2)))</span><br><span class="line">               .triggering(</span><br><span class="line">                 AtWatermark()            .withEarlyFirings(AtPeriod(Duration.standardMinutes(1)))</span><br><span class="line">                   .withLateFirings(AtCount(1)))</span><br><span class="line">               .discardingFiredPanes())</span><br><span class="line">  .apply(Sum.integersPerKey());</span><br></pre></td></tr></table></figure><p>清单7. 丢弃模式与提前和延迟触发   </p><p>&ensp; &ensp;在流处理引擎上使用启发式Watermark的效果如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">PCollection&lt;KV&lt;String, Integer&gt;&gt; scores = input</span><br><span class="line"> .apply(Window.into(FixedWindows.of(Duration.standardMinutes(2)))</span><br><span class="line">               .triggering(</span><br><span class="line">                 AtWatermark()</span><br><span class="line">   .withEarlyFirings(AtPeriod(Duration.standardMinutes(1)))</span><br><span class="line">                   .withLateFirings(AtCount(1)))</span><br><span class="line">               .accumulatingAndRetractingFiredPanes())</span><br><span class="line">  .apply(Sum.integersPerKey());</span><br></pre></td></tr></table></figure><p>清单8. 累加和撤销模式，使用提前/延迟触发</p><p>&ensp; &ensp;在流处理引擎的执行如下所示:<br>[图片上传失败…(image-457dcc-1542359894383)]<br>图10. 在流处理引擎上，执行累加和撤销模式，使用提前/延迟触发</p><p>&ensp; &ensp;由于每个窗口的窗格都是重叠的，所以看起来有点乱。 撤销用红色表示，它与蓝色窗格结合重叠，看起来略带紫色。 在一个给定的窗格中略微移动了两个输出的值（并用逗号分隔），使它们更容易区分。<br>将图9,7（启发式）和10的三张图动画效果的最终图放在一起，提供了三种模式的很好的视觉对比：<br><img src="http://upload-images.jianshu.io/upload_images/13935362-0fef365bcb420602?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"><br>图 11. 丢弃模式、累加模式、累加&amp;撤回模式对比</p><p>&ensp; &ensp;从左到右是丢弃模式、累加模式、累加&amp;撤回模式，三种模式需要的存储和计算成本依次递增。可以想像，在存储和计算成本方面，呈现的顺序（丢弃，累加，累加和撤回）的模式都相继更昂贵。 为此，累积提供了一种新的维度，在正确性，延迟和成本的之间进行权衡。</p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>&ensp; &ensp;到此为止，我们接触了4个问题：</p><ol><li>What要计算什么结果? Transform.</li><li>Where在事件时间中的哪个位置计算结果? 窗口</li><li>When在处理时间中的哪个时刻触发计算结果?Watermark和触发</li><li>How如何修正结果? 累积</li></ol><p>&ensp; &ensp;我们目前只了解了一种窗口类型：基于事件时间的固定窗口。 从Streaming 101中我们提到了多种窗口，其中有两个是今天要详细阐述的：基于处理时间的固定窗口，基于事件时间的会话窗口。</p><h2 id="When-Where-基于处理时间的窗口"><a href="#When-Where-基于处理时间的窗口" class="headerlink" title="When/Where: 基于处理时间的窗口"></a>When/Where: 基于处理时间的窗口</h2><p>处理时间窗口重要的原因有两个：</p><ul><li>对于某些使用情况，例如使用情况监控（例如，Web服务流量QPS），希望在收到数据流时分析数据，处理时间窗口绝对是适当的方法。</li><li>对于事件发生时间很重要的（例如，分析用户行为趋势，计费，评分等）的场景，处理时间窗口绝对是错误的选择，要能够清晰的区分哪些场景合适。</li></ul><p>&ensp; &ensp;因此，值得深入了解处理时间窗口和事件时间窗口之间的差异，特别是考虑到当今大多数流处理系统中广泛使用了处理时间窗口。<br>当使用模型时，例如在这篇文章中提到的，作为一等公民的窗口是严格基于事件时间的，有两种方法可以用来实现处理时间窗口：</p><ul><li>触发器：忽略事件时间（即，使用跨越所有事件时间的全局窗口），并使用触发器在处理时间轴中提供该窗口的快照。</li><li>进入时间：即数据到达系统的时间，将入口时间分配为数据作为事件时间，并使用正常的事件时间窗口进行后续处理。 SparkStreaming中的处理时间就是这么做的。</li></ul><p>&ensp; &ensp;请注意，这两种方法或多或少等同，但在在多处理步骤Pipeline的情况下略有不同：在触发器版本中，每个处理步骤都使用处理时间切分窗口，步骤之间相互独立，因此例如窗口X中的数据为 一个阶段可能会在下一阶段的窗口X-1或X + 1中; 在进入时间版本中，一旦将数据归于窗口X中，由于不同的处理步骤时间使用Watermark同步处理进度（Dataflow的做法），在整个处理过程中都会一直属于窗口X。对micro-batch来说（ Spark Streaming的做法），micro-batch的边界或其他因素，是在引擎级别协调处理。</p><p>&ensp; &ensp;正如一直强调的，处理时间窗口的最大缺点是，当输入的顺序发生变化时，窗口的内容会发生变化。 为了更具体地说明这一点，我们来看这三种用例：</p><ul><li>事件时间窗口</li><li>使用触发器的处理时间窗口</li><li>使用进入时间的处理时间窗口</li></ul><p>&ensp; &ensp;我们将每个窗口应用到两个不同的输入数据集（总共有6个变体）。 两个输入数据包含完全相同的事件（即相同的值，发生在相同的事件时间），但顺序不同。 第1个数据集跟我们之前例子中的顺序一致，颜色为白色; 第二个数据集调整了事件的处理顺序，如下图12所示，为紫色。</p><h2 id="基于事件时间的窗口Event-time-windowing"><a href="#基于事件时间的窗口Event-time-windowing" class="headerlink" title="基于事件时间的窗口Event-time windowing"></a>基于事件时间的窗口Event-time windowing</h2><p>&ensp; &ensp;为了建立一个基线，我们首先将基于事件时间的使用启发式Watermark的固定窗口处理两个顺序不同的数据集。 我们将重用清单5 /图7中的提前/延迟处理的代码，即如果如下。 左边实际上是我们以前看到的; 右边是第二个数据集的结果。 这里要注意的一点是：尽管输出的整体形状不同（由于处理时间不同），四个窗口的最终结果保持不变：14,22,3和12：<br>[图片上传失败…(image-4e5490-1542359894383)]<br>图13. 基于事件时间窗口处理两个内容一样但顺序不一样的输入数据集</p><h2 id="使用触发器的处理时间窗口"><a href="#使用触发器的处理时间窗口" class="headerlink" title="使用触发器的处理时间窗口"></a>使用触发器的处理时间窗口</h2><p>&ensp; &ensp;现在我们来比较上述两种处理时间方法。 首先，将尝试触发器方法。使用处理时间窗口达到效果，需要考虑以下三个方面：</p><ul><li><p>窗口: 使用全局事件时间窗口，本质上是以事件窗格模拟处理时间窗口</p></li><li><p>触发: 根据处理时间窗口的期望大小，在处理时间维度上周期性触发。</p></li><li><p>累加: 使用丢弃模式来保持窗格彼此独立，从而让每个窗格都像一个独立的处理时间窗口。</p></li></ul><p>相应的代码看起来像清单9; 请注意，全局窗口是默认的，因此没有具体的覆盖策略：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">PCollection&lt;KV&lt;String, Integer&gt;&gt; scores = input</span><br><span class="line">  .apply(Window.triggering(</span><br><span class="line">                  Repeatedly(AtPeriod(Duration.standardMinutes(2))))</span><br><span class="line">               .discardingFiredPanes())</span><br><span class="line">  .apply(Sum.integersPerKey());</span><br></pre></td></tr></table></figure><p>清单9. 在全局事件窗口上使用重发触发器、丢弃模式，模拟处理时间窗口       当流处理引擎上输入两个不同顺序的数据集的时候，结果如下图14所示。 有趣的笔记与这个数字：       由于我们了基于事件时间的窗格模拟处理时间窗口，所以在处理时间轴中勾画了“窗口”，这意味着窗口宽度是在Y轴上度量而不是X轴。由于处理时间窗口对输入数据的顺序敏感，在两个数据集中，每个窗口包含的数据都是不同的，即时事件发生的时间相同。 在左边我们得到12,21,18，而在右边我们得到7,36,4。<br>[图片上传失败…(image-e08f77-1542359894383)]<br>图14. 使用触发器模拟模拟处理时间窗口，处理两个内容一但顺序不一样的数据集</p><h2 id="使用入口时间的处理时间窗口"><a href="#使用入口时间的处理时间窗口" class="headerlink" title="使用入口时间的处理时间窗口"></a>使用入口时间的处理时间窗口</h2><p>&ensp; &ensp;最后，我们来看看通过将输入数据的事件时间映射为入口时间来实现的处理时间窗口。在代码方面，这里有四个方面值得一提：</p><ul><li><p><strong>时移</strong><br>当数据到达时，数据的事件时间被入口时间（数据到达时的处理时间）覆盖。请注意，我们目前在Dataflow中没有标准API来处理时间，尽管我们接下来会可能会使用伪代码I / O源中的虚构方法来代表下面的代码。对于Google Cloud Pub / Sub，只需在发布消息时将消息的timestampLabel字段留空;对于其他来源，需要查阅源代码文档。</p></li><li><p><strong>窗口</strong><br>返回使用标准的固定事件时间窗口。</p></li><li><p><strong>触发</strong><br>由于入口时间提供了计算理想Watermark的能力，所以可以使用默认触发器，在这种情况下，当Watermark通过窗口的末尾时，触发器会隐式触发一次。</p></li><li><p><strong>累积模式</strong><br>由于我们每个窗口只有一个输出，所以累积模式是无关紧要的。</p></li></ul><p>实际的代码可能看起来像这样：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">PCollection&lt;String&gt; raw = IO.read().withIngressTimeAsTimestamp();</span><br><span class="line">PCollection&lt;KV&lt;String, Integer&gt;&gt; input = raw.apply(ParDo.of(new ParseFn());</span><br><span class="line">PCollection&lt;KV&lt;String, Integer&gt;&gt; scores = input</span><br><span class="line">  .apply(Window.into(FixedWindows.of(Duration.standardMinutes(2))))</span><br><span class="line">  .apply(Sum.integersPerKey());</span><br></pre></td></tr></table></figure><p>清单10. 明确的默认触发器<br>&ensp; &ensp;在流式引擎上的执行将如下面的图15所示。当数据到达时，它们的事件时间被覆盖为它们的进入时间（即到达时的处理时间），导致在理想Watermark线上的向右水平移位。该图中有趣的注释： - 与其他处理时间窗口示例一样，当输入的顺序变化时，即使输入的值和事件时间保持不变，我们也会得到不同的结果。 - 与其他示例不同，窗口在事件时间维度上（因此沿X轴）重新划分了。尽管如此，这些窗口并不是原生的事件时间窗口;而是我们将处理时间简单地映射到事件时间上，擦除每个输入的原始记录，并用新的记录代替它，而事件的时间是表示Pipeline首次收到到数据的时间。 - 尽管如此，由于使用了Watermark，触发器仍然在与之前的处理时间示例完全相同的时间触发。此外，所产生的输出值与该示例相同，如左侧的12,21,18，右侧的7,36,4。 - 由于使用入口时间，所以理想的Watermark是可能的，所以实际的Watermark与理想的Watermark相匹配，斜率为1，向右上方延伸。<br>[图片上传失败…(image-f82f32-1542359894383)]<br>图15. 使用入口时间的处理时间窗口，处理两个内容一样但顺序不同的数据集</p><p>&ensp; &ensp;虽然看到不同的方法可以实现处理时间窗口很有趣，但是这里的大部分内容是自从第一篇文章以来一直提到的：事件时间窗口与顺序无关，至少在极限情况下如此（实际 在处理过程中的窗格可能会不同，直到输入完成），而处理时间窗口不是。 如果关心事件实际发生的时间，必须使用事件时间窗口，否则计算结果是无意义的。</p><h2 id="Where-会话窗口"><a href="#Where-会话窗口" class="headerlink" title="Where: 会话窗口"></a>Where: 会话窗口</h2><p>&ensp; &ensp;现在来看一下我最喜欢的特性之一：动态的、数据驱动的窗口，称为会话窗口。<br>&ensp; &ensp;会话是一种特殊类型的窗口，它捕获数据中的一段活动，在不活动一段时间后窗口中止。 它们在数据分析中特别有用，因为可以让我们看到某一个特定用户在一段时间内的行为。 这可以让我们分析会话内的活动的相关性，基于会话的长度来推断用户的参与水平等。<br>&ensp; &ensp;从窗口的角度来看，会话窗口在两个方面很有趣：</p><ul><li><p>它们是数据驱动窗口的示例：窗口的位置和大小是输入数据本身来决定，而不是在时间内基于某些预定义模式，如固定和滑动窗口。</p></li><li><p>它们也是不对齐的窗口的示例，即，窗口并不将数据一视同仁，而是将数据的特定子集（例如，每个用户）进行切分。<br>这与对齐的窗口（如固定和滑动窗口）形成对比，这些窗口通常对数据一视同仁，进行切分。</p></li></ul><p>&ensp; &ensp;对于一些用例，可以提前在一个会话中的数据中标记一个共同标识符（例如，在线的的视频播放器，定时发出心跳包，心跳包内容是服务质量信息，对于任何给定的一次观看，分配一个会话ID，所有的心跳信息中都添加这个会话ID）。在这种情况下，会话更容易构建(按照会话ID区分会话)，本质上是按键分组的一种形式。</p><p>&ensp; &ensp;然而，在更一般的情况下（即，实际会话提前并不知道），会话只能从从数据中构建出来。当处理无序数据时，这变得特别棘手。<br>&ensp; &ensp;提供一般会话支持的关键是，根据定义，完整的会话窗口是一组较小的重叠窗口的组合，每个窗口包含单个记录，每个记录中的每个记录与下一个记录的间隔不超过预先定义的间隔。因此，即使会话中的数据乱序了，也可以简单地通过将各个数据的重叠窗口合并在一起来构建最终会话。<br><img src="http://upload-images.jianshu.io/upload_images/13935362-695a8c68db50e1e2?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"><br>图16. 未合并的原始会话窗口和合并之后的会话窗口</p><p>&ensp; &ensp;下边看一个代码示例，以清单8中的代码为基础，修改为使用会话窗口：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">PCollection&lt;KV&lt;String, Integer&gt;&gt; scores = input</span><br><span class="line">  .apply(Window.into(Sessions.withGapDuration(Duration.standardMinutes(1)))</span><br><span class="line">               .triggering(</span><br><span class="line">                 AtWatermark()</span><br><span class="line">                   .withEarlyFirings(AtPeriod(Duration.standardMinutes(1)))</span><br><span class="line">                   .withLateFirings(AtCount(1)))</span><br><span class="line">               .accumulatingAndRetractingFiredPanes())</span><br><span class="line">  .apply(Sum.integersPerKey());</span><br></pre></td></tr></table></figure><p>清单11. 基于会话窗口，提前和延迟触发，使用累加和撤销模式       在流处理引擎上执行如下所示：<br>[图片上传失败…(image-ed484b-1542359894383)]<br>图17. 基于会话窗口，提前和延迟触发，使用累加和撤销模式</p><p>这里有很多事情，所以我将介绍一些它：</p><ul><li><p>当遇到具有值为5的第一个记录时，它被放置在从该记录的事件时间开始的单个原始会话窗口中，窗口宽度为会话窗口的超时时长，例如超时时长为1分钟，会话窗口宽度为1分钟。在后边遇到的任何窗口与该窗口重叠的都应该隶属于同一个会话，并且合并到此窗口中。</p></li><li><p>第二个到达记录是7，它类似地放在自己的原始会话窗口中，因为它不与5的窗口重叠。</p></li><li><p>同时，Watermark已经过第一个窗口的末尾，所以在12:06之前，包含值5的窗口被物化为准时的窗口。此后不久，当处理时间正好为12:06的时候，第二个窗口也被物化为具有值7的推测结果。</p></li><li><p>我们接下来观察一系列的记录，3,4和3，这3个会话窗口相互重叠。因此，它们都被合并在一起，并且在12:07的时候提前触发，发出一个值为10的单个窗口。</p></li><li><p>当8到达不久之后，它与具有值7的会话和与值10的会话重叠。所有这三个因此被合并在一起，形成具有值25的新的组合会话。当Watermark然后通过这个会话的末尾时，它物化了一个包含值25的新会话以及之前发布的两个窗口的撤消，但后来被并入它：7和10。</p></li><li><p>当9到达延迟到达时，类似的舞蹈发生在9号晚上，与值为5的原始会话，和值为25的会话变成了一个更大的值为39的一个较大的会话。值39和窗口25、5的撤销被立即延迟触发。</p></li></ul><p>&ensp; &ensp;窗口是极其有用的工具，可以非常容易的将流处理的维度分解成不同的可组合的部分。这样可以让我们更多地关注业务逻辑，而不是花费很多的精力处理数据的格式相关的问题。<br>&ensp; &ensp;如果不相信，请看Spark的文章，介绍如何在Spark Streaming上手动构建会话（请注意，这不足以指出他们; Spark人员刚刚完成了足够的工作，有人实际上打扰了记录在其上构建特定种类的会话支持所需要的麻烦;对于大多数其他系统来说，我不能说相同）。这很相关，他们甚至没有做适当的事件时间会话，或提供投机或晚期的启动，也不会撤退。（这一段是原文，随着Spark的新版本的发布，对Spark的描述已经过时了）</p><h1 id="结尾"><a href="#结尾" class="headerlink" title="结尾"></a>结尾</h1><p>&ensp; &ensp; 现在我们已经深入了解了建立强大的流处理系统的基础，快速回顾一下我们所讲的内容。首先，我们提到的主要概念：</p><ol><li>事件时间与处理时间：事件发生时间和被数据处理系统处理的时间之间的重要区别。</li><li>窗口：通常使用的方法是通过在时间边界（通过处理时间或事件时间）对其进行切分来管理无限数据，尽管我们将数据流模型中的窗口定义缩小仅表示事件时间内）。</li><li>Watermark：事件时间进度的概念，为在无限数据上运行的乱序处理系统提供了估计窗口数据完整性的手段。</li><li>触发器：用于精确指定在合适计算窗口结果的机制，对于特定用例是有意义的。</li><li>累积：在单个窗口被多次触发计算的情况下，随着触发持续的修正窗口结果。其次，我们用来构建我们探索的四个问题（我承诺我不会再在此之后再读）</li><li>What 要计算出什么结果？ =变换Transform</li><li>Where事件在哪里结果计算？ =窗口</li><li>When 在处理时间维度上什么时候计算窗口结果？=Watermark+触发器</li><li>How如何不断的修正计算结果？ =累积</li></ol><p>&ensp; &ensp;第三，最后一点，这种流处理模式所带来的灵活性（最终，需要做的是在处理数据的各种要素之间取得平衡，如正确性，延迟和成本），回顾一下，通过少量的代码修改，对相同的数据集处理而得到的输出的变化如结束。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;streaming现实中的解决之道&quot;&gt;&lt;a href=&quot;#streaming现实中的解决之道&quot; class=&quot;headerlink&quot; title=&quot;streaming现实中的解决之道&quot;&gt;&lt;/a&gt;streaming现实中的解决之道&lt;/h1&gt;&lt;h1 id=&quot;简单回顾和
      
    
    </summary>
    
      <category term="实用技术" scheme="http://ellenadams.github.io/categories/%E5%AE%9E%E7%94%A8%E6%8A%80%E6%9C%AF/"/>
    
      <category term="Flink" scheme="http://ellenadams.github.io/categories/%E5%AE%9E%E7%94%A8%E6%8A%80%E6%9C%AF/Flink/"/>
    
    
      <category term="flink" scheme="http://ellenadams.github.io/tags/flink/"/>
    
      <category term="google" scheme="http://ellenadams.github.io/tags/google/"/>
    
  </entry>
  
  <entry>
    <title>google streaming101</title>
    <link href="http://ellenadams.github.io/2019/07/27/streaming101/"/>
    <id>http://ellenadams.github.io/2019/07/27/streaming101/</id>
    <published>2019-07-27T02:03:07.220Z</published>
    <updated>2019-07-27T02:03:07.220Z</updated>
    
    <content type="html"><![CDATA[<h1 id="批处理之外的流式世界"><a href="#批处理之外的流式世界" class="headerlink" title="批处理之外的流式世界"></a>批处理之外的流式世界</h1><p>开宗明义！本文根据Google Beam大神Tyler Akidau的系列文章《The world beyond batch: Streaming 101》(批处理之外的流式世界)整理而成， 主要讨论流式数据处理。</p><p>在大数据领域，流式数据处理越发地重要了。原因有以下几点：</p><ul><li>人们越来越想要得到更及时的数据，而切换到流式处理(streaming)无疑是一个降低延时的好办法</li><li>海量数据的生产变得越来越频繁，即使是小公司也会产出超大量的每日数据。因此必然要求有一种系统能够处理这种无穷多的数据集合</li><li>数据更快地被处理可以实现负载均衡，对资源的消耗也更加可控<br>基于这种业务需求驱动的流式处理浪潮逐渐兴起，但现存的流式处理系统比起它们的“一生之敌”批处理系统而言尚不能算成熟，故而在这个领域内依然大有可为。</li></ul><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>讨论流式处理，有些问题必须要先搞清楚：</p><ul><li>术语：如此复杂的讨论不明晰术语一定是举步维艰的。当前在流式处理的概念中名词歧义现象十分常见，故消除歧义明确含义的事情一定要首先完成</li><li>能力边界：知其为，也要知其不可为。流式处理系统能做什么，不能做什么，这是个大问题</li><li>时间概念：明确两个时间维度的名词概念以及它们之间的联系还有各自的优劣</li></ul><h2 id="术语：什么是流式？"><a href="#术语：什么是流式？" class="headerlink" title="术语：什么是流式？"></a>术语：什么是流式？</h2><p>Streaming——流式一词含义极多，澄清有些难度。困难的原因在于我们解释一个事物通常喜欢以解决或完成这个事物的方式进行描述，而非它的本质。这种不好的习惯掩盖了streaming的本质。在某些情况下，这可能会给人带来一种误解：仿佛流式系统就只能以流式方式进行处理，从而计算出来的结果值也不是准确的。实际上，如果设计得当，流式系统完全可以重复地计算出正确的一致性结果。那么何为streaming？streaming就是一类数据处理引擎，旨在处理无限的数据集——广义上说，它既包括纯streaming也包含模拟streaming的微批次实现(micro-batch)。Spark Streaming就是micro-batch思想的实现。</p><p>Streaming经常也被解释成以下几个名词表示的意思：</p><ul><li>无限数据(unbounded data)—— 表示一直增长，无穷无尽的数据集合，它们甚至被称为“流式数据“。 这里面的问题就在于当我们说streaming或batch的时候我们其实并不是在表征它们处理的数据的特性。如前所述，streaming或batch的本质是处理这些数据的执行引擎，而非数据本身。streaming和batch的主要区别其实也在于它们处理的数据的有限性，所以刻画事物时应该抓住事物本质上的特点。这类数据的正确提法是：unbounded data和bounded data，而不是流式数据</li><li>无限数据处理(unbounded data processing)—— 应用在unbounded data上持续的数据处理。把streaming解释成这个意思也是有问题的，因为batch引擎其实也可以处理unbounded data——重复多次地运行batch引擎已经被用于处理这类数据了，所以要区分streaming和unbounded data processing的区别</li><li>能做到低延时但计算结果不准确，只是近似值—— 说起streamig好像它就无法产生出准确计算的值一样，这是不对的。事实上，batch系统不能做到低延时或产生近似值的观念也只过时了——batch引擎当然可以产生近似准确的值。因此，我们最好使用低延时/近似值来表示这个意思，不要因为历史上它们是由streaming引擎产生出来的，就认为把它们和streaming等同起来。</li></ul><hr><p>再次强调一下，streaming表示的是用于处理unboundeddata的执行引擎，仅此而已</p><hr><h2 id="确定能力边界-——-特别在世人夸大了streaming的限制之后"><a href="#确定能力边界-——-特别在世人夸大了streaming的限制之后" class="headerlink" title="确定能力边界 —— 特别在世人夸大了streaming的限制之后"></a>确定能力边界 —— 特别在世人夸大了streaming的限制之后</h2><p>下面我们讨论一下streaming系统能做什么，不能做什么，重点强调它能做什么。Streaming系统长期以来一直被视为是一个小众领域，它以低延时的方式产出近似准确的结果，而且streaming通常还与功能更加强大的batch系统协同工作最终为用户提供准确的结果。具体而言就是同时部署一套batch系统和一套streaming系统，两套系统一起执行相同的计算。streaming系统实时运行，延时低但结果不准确(因为使用了近似算法或系统本身就没有提供准确性保障)，而batch系统虽稍后登场，但能够保证计算结果是准确的——这种部署方式或架构最早由Apache Storm的作者Nathan Marz提出，并经实践证明后被认为是在当时非常成功的。从准确性这点来看，streaming系统的确不尽如人意，而batch系统通常又很笨拙，因此两者的结合简直可谓是“鱼与熊掌的兼得”。令人遗憾的是，维护两套系统的成本是很高的——因为它们是两套独立的数据管道，同时它们产出的结果有需要执行合并操作。</p><p>Tyler本人对于强一致性的streaming引擎有着很深的造诣，他本人并不赞同这种两套系统的架构设计——相反地，他是Jay Kreps提出的可重演系统的拥趸(你不知道Jay Kreps是谁？ 好吧，你总听过Kafka吧，他是Kafka的原作者)：使用Kafka这样的可重演系统连接streaming引擎以解决可重复性的问题，并自始至终地使用一套管道来进行数据处理。如果把这个观点更进一步，我们可以认为定义良好的streaming系统甚至提供的是batch引擎所具功能的超集(superset)——事实上， 去年火爆开源社区的Apache Flink就是这样的思想，Flink中的batch引擎是作为streaming引擎的一个特例而实现的，这点和Spark streaming正好相反：Spark streaming的streaming其实是借助于micro-batch的思想而实现的。如果不是目前执行效率上的一些差异，当今batch系统根本没有存在的必要的。在这点上要感谢Flink开发者为我们构建了一个”随时随地streaming化“的系统，即使是batch模式，Flink底层也是使用streaming实现的。</p><p>所有这一切的结论就是：streaming系统的广泛成熟与无穷数据处理框架的结合必然会令batch引擎逐步退出历史舞台。不过streaming系统若要打败batch系统，还需要完成两件事情：</p><hr><ol><li><h2 id="正确性"><a href="#正确性" class="headerlink" title="正确性"></a>正确性</h2>正确性帮助streaming系统足以匹敌batch系统。从本质上说，正确性可归结为一致性存储。streaming系统需要有能力定期地持久化状态(checkpoint)并且还要能够维护系统崩溃下的一致性。Spark streaming在这方面是先驱，它很好地维护了一致性。时至今日很多streaming系统都能够做到这点了——最多一次的处理语义实在是个伪命题，但目前它依然存在。再次强调一下：强一致性是实现”精确一次处理语义”的必要条件，“精确一次处理语义”是实现争取性的必要条件，而任何streaming系统，若想要打败batch系统就必须实现正确性。除非真的不在乎计算结果，否则还是建议尽量不要使用那些不提供强一致性的streaming系统。若要学习如何实现强一致性，Spark streaming论文是很好的材料，推荐大家读一读。</li></ol><hr><ol start="2"><li>推导时间的工具</li></ol><hr><p>如果说正确性帮助你的streaming系统匹敌batch系统，那么这些工具将令你超越batch。推导时间的工具是处理无界无序数据集的利器。当前海量数据表现出来的特点是随机变化的数据倾斜——即事件被处理的时间与事件真实发生时间的差值随机分布，而现有的bach系统(以及大部分的streaming系统)都无法处理这种情况——这也是streaming系统着重要解决的问题之一。</p><p>接下来我们需要了解一下时间方面的2个概念，然后才能深入地去讨论下之前说的无界无序数据随机变化的时间差值是什么意思，最后针对这些问题streaming系统都有哪些解决之道。</p><h2 id="Event-time-VS-processing-time-发生时间-VS-处理时间"><a href="#Event-time-VS-processing-time-发生时间-VS-处理时间" class="headerlink" title="Event time VS. processing time   发生时间 VS. 处理时间"></a>Event time VS. processing time   发生时间 VS. 处理时间</h2><p>坦率地说，无界数据处理先搞清楚时间概念。在任何数据处理系统中，通常都有两类时间维度的概念：</p><ul><li><p>Event time，即事件真实发生的时间，正式名称是发生时间</p></li><li><p>Processing time: 事件在系统中被观测到的时间，正式名称是处理时间<br>并非所有情况都需要考虑event time——事实上，如果你根本不care发生时间，事情变得简单多了，也许后面的你都不用看了——但很多场景下event time确实是需要被考虑的，比如统计用户行为、计费系统以及很多异常检测等。理想情况下，event time和processing time应该是相等的，即事件一旦发生就立即被处理。显然，这不可能是真的，两者之间的差值不仅不为0，而且通常是由各种因素影响的一个变化的函数——我们把这个差值不为0的事实成为时间倾斜，或简称为倾斜(skew)。影响这种skew的因素可能有输入源、执行引擎或硬件等。具体来说包括：</p></li><li><p>共享资源限制：比如带宽争用、网络分区或CPU资源共享等</p></li><li><p>软件原因：分布式系统逻辑限制、竞争等</p></li><li><p>数据本身的特性导致，包括key分布，TPS变动或无序性变动<br>因此，如果分别以event time和process time为轴画一张图的话，那么一个真实场景下的数据倾斜分布就应该类似如下图这个样子：</p><p><img src="http://upload-images.jianshu.io/upload_images/13935362-4136dd979a50b9dd.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></p></li></ul><p>黑虚线表示理想情况，斜率=1表示event time总是等于processing time；红线表示实际情况。在实际场景中系统总是会滞后一些，表现为processing time永远大于event time，但两者的差值其实一条变动的曲线，最开始时差距很大，在中段逐渐靠近理想情况，最后又开始偏离。曲线上同一个纵轴点对应的两个横坐标的差值即标识了现实与理想之间的skew——显然这种skew是因为数据处理管道的延时所引入的。</p><p>event time与processing time之间的差值不是固定的，这就意味着如果要使用event time，单靠processing time是不够的。令人遗憾地是，目前大多数streaming系统在设计的时候都只是考虑了processing time。如果要处理这种无穷多的数据，streaming系统必须要规定一种类似于时间窗口似的的概念。本质上它就是沿着时间维度把数据划分到不同的时间窗口中。虽然大部分系统就是这样做的， 但如果要实现基于event time的正确性，使用processing time来定义时间窗口显然是不行的。鉴于event time和processing time之间并没有一致性的关系，很有可能我们会把某些event time数据划分到错误的processing time窗口(比如因为延时)从而导致计算的不准确。后面需要详细讨论一下解决之道。</p><p>即使是根据event time进行时间窗口划分也不是所有问题都解决了。对于unbounded数据而言，无序性和skew的不确定性会带来一个完整性的问题：因为没有可控的event time/processing time映射关系，我们如何能够确定在时间窗口X中观测到的数据是完备的？真实场景中，我们无法提供完备性验证。主流的处理系统都依赖于完备性的概念，但当应用于无穷数据集时这些系统就有些捉襟见肘了。</p><p>与其把无限数据集打散到有限的batch中，我们不如设计一种工具可以让我们能够应付真实场景下的这种不确定性。新数据必将到达，旧数据可能会被删除或更新，任何系统都应该独立地处理这些事情。在这些系统中完备性的概念只是一个辅助而非一个必要条件。</p><p>下面我们讨论一下常见的数据处理范型(data processing pattern)，既包括streaming引擎也包括batch引擎。micro-batch也被算作是streaming引擎。</p><h2 id="有限数据集"><a href="#有限数据集" class="headerlink" title="有限数据集"></a>有限数据集</h2><p>处理有限数据集很简单，如下图所示：</p><p><img src="http://upload-images.jianshu.io/upload_images/13935362-5edf0fdcc9ec94e7.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></p><p>上图中左边的数据集杂乱无章，运行某个数据处理引擎后(通常是batch引擎，比如MapReduce)变成了右边的“更有序”的样子。怎么捣腾数据虽然玩法是无穷的，但万变不离其宗，这种处理方式是不变的，依然非常简单。有挑战的还是处理无穷数据集，包括batch处理无穷数据集和streaming处理无穷数据集。</p><h2 id="batch处理无穷数据"><a href="#batch处理无穷数据" class="headerlink" title="batch处理无穷数据"></a>batch处理无穷数据</h2><p>虽然设计的时候并不是用于处理无穷数据集的，但batch引擎处理unbounded data可谓历史悠久，谁让batch是先发明出来的呢。具体的方法就是分而治之的思想，即以批处理的方式把无穷数据集划分成一组有限数据集进行处理。</p><h2 id="固定时间窗口"><a href="#固定时间窗口" class="headerlink" title="固定时间窗口"></a>固定时间窗口</h2><p>最常用的方式就是不断执行batch引擎从而把输入数据划分成大小相等的窗口，如下图所示：<br><img src="http://upload-images.jianshu.io/upload_images/13935362-37988a539ce87836.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"><br>然后独立地处理每个窗口中的数据。对于像日志这种类型的输入数据，日志被写入到不同的路径和文件中，因此路径和文件的名字就特别适合用于命名时间窗口。这样看来似乎事情变得非常简单了，你只需要执行一个基于时间的路由策略就可以把所有数据按照event-time发送到不同的时间窗口中。在实际使用时，大多数的系统会遭遇完备性的问题：某些事件在写入到日之前被耽搁了(比如网络原因或磁盘IO)，或者事件虽然是全局收集的但在处理前被转移到一个公共的地方了，再或者事件是由移动设备发送过来的。这些情况中我们就需要一些手段来处理完备性，比如引入某种延时处理机制直到我们确信所有的时间都已经被收集了，或者只要那些晚到的数据到达，之前时间窗口中的数据就重新被处理一次。</p><p>如果batch引擎使用更加复杂的窗口策略(比如会话，session)来处理无界数据时，上面的方法就会更加的有局限性。Session本质上都被定义为特定用户的操作时段。Session之间的时段就是该用户无操作的时段。若使用batch引擎计算session，得到的session通常都是跨batch的，如下图中红色箭头部分所示：</p><p><img src="http://upload-images.jianshu.io/upload_images/13935362-a9723d598fa9df02.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></p><p>增大batch size固然可以减少这种跨度，但代价就是延时的增加。另一种办法就是增加额外的逻辑将这种“断裂”的session缝合在一起，不过想想就知道这实现起来有多复杂。不论那种方式，使用经典的batch引擎来计算session效率很低。更好的办法是使用streaming的方式。</p><h2 id="streaming处理无穷数据集"><a href="#streaming处理无穷数据集" class="headerlink" title="streaming处理无穷数据集"></a>streaming处理无穷数据集</h2><blockquote><p>和大多数batch处理无穷数据集相反的是，streaming系统天生就是处理无穷数据集的。真实场景下的无限数据集有以下特点：</p><ul><li>与event time高度无序——意味着你需要某种基于时间的路由规则</li><li>变动的event time skew——意味着你不能想当然地认为在[Y - a, Y + a]时间范围内总是看到event time = X的所有数据</li></ul></blockquote><p>当然，处理这类数据时还是有一些方法可用的，基本上可以划分成以下四类：</p><ul><li>时间无关性方法</li><li>近似方法</li><li>基于process time的时间窗口</li><li>基于event time的时间窗口</li></ul><h2 id="时间无关性方法"><a href="#时间无关性方法" class="headerlink" title="时间无关性方法"></a>时间无关性方法</h2><p>如果本质上不关心时间——比如所有的逻辑都是数据驱动的——那么这类方法就非常适合了。其实这也没什么新鲜的，一个streaming引擎通常都是要支持的。本质上说，所有现存的streaming系统都天然支持这种与时间无关的使用场景。Batch系统也非常适合这种时间无关性的数据处理，只需简单地把无穷输入源划分成任意序列长度的有界数据集并分别独立处理即可。下面举几个例子来说明一下：</p><p><strong>Filtering</strong></p><p>一个典型的例子就是过滤(filtering)，如下图所示：</p><p><img src="http://upload-images.jianshu.io/upload_images/13935362-7f00f3ded11a4326.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></p><p>假设我们处理的是Web流量日志，想要过滤出某个特定领域来的所有流量，那么我们只需查看每条日志的来源，如果不符合条件直接pass掉。显然这和时间是没有关系的，因此数据源是否是无序，无穷或是变动的skew就显得不重要了。</p><p><strong>Inner-joins</strong></p><p>另一个时间无关性的例子就是内连接(inner-joins)。当连接两个无穷数据源时倘若我们只在乎连接的结果，则处理逻辑就不需要考虑时间的因素。一旦看到某股输入源中出现一个值，那么我们就把这个值缓存起来。当值出现在第二股输入源时，只需要发送合并的消息即可了，如下图所示：</p><p><img src="http://upload-images.jianshu.io/upload_images/13935362-e91cb4f24826e190.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></p><p>如果切换到外连接将引入数据完备性的问题：一旦看到了join的一边，那么如何才能确定另一边也到达了呢？老实说，我们没法得知，因此我们就必须引入某种超时机制——而这必然会引入时间因素。时间因素本质上就是时间窗口的形式。</p><h2 id="近似算法"><a href="#近似算法" class="headerlink" title="近似算法"></a>近似算法</h2><p><img src="http://upload-images.jianshu.io/upload_images/13935362-59462ae279584614.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></p><p>第二大类方法就是近似算法，比如近似的TopN，streaming K-means等。这些算法接收无穷数据源作为输入，而输出结果只能算是基本上满足我们的预期。近似算法的好处在于开销很低并且天生就是用于处理无穷数据集的，而缺点在于算法通常是很复杂的，而且它们的近似特性限制了它们的应用。值得注意的是，这些算法在设计上通常都引入了时间的元素。算法在处理事件时，时间因素通常都是基于processing time的，这对于提供了某类可控错误边界的算法而言是极其重要的。近似算法本身也可以被视为是与时间无关性处理的另一个例子。</p><h2 id="时间窗口"><a href="#时间窗口" class="headerlink" title="时间窗口"></a>时间窗口</h2><p>剩下的两类方法都是时间窗口的变种，首先讨论下时间窗口的具体含义。时间窗口本质上就是将数据源沿着时间线划分成有限的数据块。下图表明不同的窗口范型：</p><p><img src="http://upload-images.jianshu.io/upload_images/13935362-bcbaee66253df028.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></p><ul><li>固定窗口———— 固定窗口把时间划分成固定大小的段。具体还可以细分为对齐窗口和未对齐窗口</li><li>滑动窗口———— 固定窗口的一种广义形式，滑动窗口也是有固定的长度以及固定的间隔。如果间隔长度&lt;窗口长度，那么窗口必然会造成重叠。如果间隔长度=窗口长度，那么就是固定窗口。如果间隔长度&gt;窗口长度，这就被称为“取样窗口”，它只会查询一部分数据。滑动窗口通常是对齐的。</li><li>会话———— 属于动态窗口，会话就是一组事件序列，通常被用于分析用户行为。既然是用户操作事件序列，我们无法提前为session定义窗口长度，而且由于在实际中不同的用户其session也是不同的，因此它们属于经典的未对齐窗口</li></ul><p>对于processing time和event time而言，时间窗口都是适用的，当然还是有区别的。我们首先来看基于processing time的时间窗口:</p><p>根据processing time创建时间窗口时，系统会缓存输入数据到窗口中直至超过了某段时间。比方说对于5分钟的固定时间窗口，系统会缓存之前5分钟的所有数据并封装进一个窗口中，之后发送给下游系统用于处理。</p><p> <img src="http://upload-images.jianshu.io/upload_images/13935362-6c0488c19d1528b1.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></p><p>这种窗口的特点如下：</p><ul><li>简单</li><li>极易检验完备性：系统完全知道所有输入数据是否已经到来，无需处理延时数据</li><li>适用于数据被观测被产生价值的使用场景，比如通过计算每秒请求数的变化来判断是否出现服务中断</li></ul><p>不过这种基于processing time的窗口有一个非常大的缺陷：必须要求数据按照event time顺序到达，否则无法真实再现事件发生场景，但是按照event time顺序的输入数据几乎不存在。。。。举个简单的例子，假设手机上的一个app收集用户统计信息。当手机未连上网络时，这段时间内收集到的数据就无法上传。这就意味着数据可能比真实的发生时间晚几分钟、几个小时、几周甚至更长。在处理时间窗口时，期望从这样的数据集中获取任何有用的结论都是不可能的。另一个例子，假设有一个全球服务处理从各个大洲收集上来的数据。如果网络问题导致带宽受阻，那么此时必然造成数据的skew。如果对这种数据基于processing time做窗口，那么这种窗口就无法表达包含在它们之下数据的真实发生情况。相反地，它们表示的是事件到达时的情况，必然是新旧数据相互混合的。这两个例子其实都应该以event time进行时间窗口的划分——即所谓的基于event time的时间窗口</p><p>基于event time的时间窗口：反映事件发生时间的时间窗口。下图展示了一个基于event time的1小时固定时间窗口：</p><p><img src="http://upload-images.jianshu.io/upload_images/13935362-e1c630a8ac0f9eca.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></p><p>两条白线表明了两个特殊的数据：这两个数据点上的数据对应的processing time时间窗口与基于event time的时间窗口是错配的。因此如果使用基于processing time的时间窗口必然造成结果的不准确。由此可见，能够提供正确性是基于event time时间窗口的一大优势。</p><p>基于event time时间窗口的另一个优势在于它的大小可以动态变更，比如session，再不会有跨batch或跨窗口的情形发生，如下图所示：<br> <img src="http://upload-images.jianshu.io/upload_images/13935362-28e5c7c405c4db6d.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></p><p>天下没有免费的午餐。这种时间窗口有2个缺陷：</p><ul><li>需要额外缓存：因为时间窗口的时间周期来拉长，需要缓存更多的数据。当然现在存储的成本不断下降，此缺陷便显得不是那么重要了</li><li>完备性：因为无法明确得知某个窗口下的所有数据都已经到来，因此便无法确认何时才能开始处理这个窗口下的数据。在实践过程中，系统通常会给一个经验值来定义窗口的完备性，但如果从绝对正确性的角度来考虑，唯一的解决办法就是提供一种方式能够让窗口中的数据可以被重新处理从而不断修正计算结果</li></ul><p>以上就是我们对于streaming以及streaming系统的一些初级讨论，第二篇中将会讨论实际场景中streaming系统的解决之法。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;批处理之外的流式世界&quot;&gt;&lt;a href=&quot;#批处理之外的流式世界&quot; class=&quot;headerlink&quot; title=&quot;批处理之外的流式世界&quot;&gt;&lt;/a&gt;批处理之外的流式世界&lt;/h1&gt;&lt;p&gt;开宗明义！本文根据Google Beam大神Tyler Akidau的系列文
      
    
    </summary>
    
      <category term="实用技术" scheme="http://ellenadams.github.io/categories/%E5%AE%9E%E7%94%A8%E6%8A%80%E6%9C%AF/"/>
    
      <category term="Flink" scheme="http://ellenadams.github.io/categories/%E5%AE%9E%E7%94%A8%E6%8A%80%E6%9C%AF/Flink/"/>
    
    
      <category term="flink" scheme="http://ellenadams.github.io/tags/flink/"/>
    
      <category term="google" scheme="http://ellenadams.github.io/tags/google/"/>
    
  </entry>
  
  <entry>
    <title>Apache Flink如何管理Kafka consumer offsets</title>
    <link href="http://ellenadams.github.io/2019/07/27/flinkKafkaOffset/"/>
    <id>http://ellenadams.github.io/2019/07/27/flinkKafkaOffset/</id>
    <published>2019-07-27T02:01:42.055Z</published>
    <updated>2019-07-27T02:01:42.055Z</updated>
    
    <content type="html"><![CDATA[<p>在我们Flink Friday Tip的这一集中，我们将逐步说明Apache Flink如何与Apache Kafka协同工作，以确保Kafka主题的记录以一次性保证进行处理。</p><p>检查点是Apache Flink的内部机制，可以从故障中恢复。检查点是Flink应用程序状态的一致副本，包括输入的读取位置。如果发生故障，Flink将通过从检查点加载应用程序状态并从恢复的读取位置继续恢复应用程序，就像没有发生任何事情一样。您可以将检查点视为保存计算机游戏的当前状态。如果你在游戏中保存了自己的位置后发生了什么事情，你可以随时回过头再试一次。</p><p>检查点使Apache Flink具有容错能力，并确保在发生故障时保留流应用程序的语义。应用程序可以定期触发检查点。</p><p>Apache Flink中的Kafka消费者将Flink的检查点机制与有状态运算符集成在一起，其状态是所有Kafka分区中的读取偏移量。触发检查点时，每个分区的偏移量都存储在检查点中。Flink的检查点机制确保所有操作员任务的存储状态是一致的，即它们基于相同的输入数据。当所有操作员任务成功存储其状态时，检查点完成。因此，当从潜在的系统故障重新启动时，系统提供一次性状态更新保证。</p><p>下面我们将介绍Apache Flink如何在逐步指南中检查Kafka消费者抵消。在我们的示例中，数据存储在Flink的Job Master中。值得注意的是，在POC或生产用例下，数据通常存储在外部文件存储器（如HDFS或S3）中。</p><h2 id="第1步："><a href="#第1步：" class="headerlink" title="第1步："></a>第1步：</h2><p>下面的示例从Kafka主题中读取两个分区，每个分区包含“A”，“B”，“C”，“D”，“E”作为消息。我们将两个分区的偏移量设置为零。</p><p><img src="https://www.ververica.com/hs-fs/hubfs/Imported_Blog_Media/2018-10-11-Flink-Kafka-Checkpoints-Step-1.png?width=1684&name=2018-10-11-Flink-Kafka-Checkpoints-Step-1.png" alt="image"></p><h2 id="第2步："><a href="#第2步：" class="headerlink" title="第2步："></a>第2步：</h2><p>在第二步中，Kafka消费者开始从分区0读取消息。消息“A”在“飞行中”处理，第一个消费者的偏移量变为1。<br><img src="https://www.ververica.com/hs-fs/hubfs/Imported_Blog_Media/2018-10-11-Flink-Kafka-Checkpoints-Step-2.png?width=1684&name=2018-10-11-Flink-Kafka-Checkpoints-Step-2.png" alt="image"></p><h2 id="第3步："><a href="#第3步：" class="headerlink" title="第3步："></a>第3步：</h2><p>在第三步中，消息“A”到达Flink Map Task。两个消费者都读取他们的下一个记录（分区0的消息“B”和分区1的消息“A”）。两个分区的偏移量分别更新为2和1。与此同时，Flink的Job Master决定在源头触发检查点。<br><img src="https://www.ververica.com/hs-fs/hubfs/Imported_Blog_Media/2018-10-11-Flink-Kafka-Checkpoints-Step-3.png?width=1684&name=2018-10-11-Flink-Kafka-Checkpoints-Step-3.png" alt="image"></p><h2 id="第4步："><a href="#第4步：" class="headerlink" title="第4步："></a>第4步：</h2><p>在接下来的步骤中，Kafka使用者任务已经创建了状态的快照（“offset = 2,1”），现在存储在Apache Flink的Job Master中。源分别在来自分区0和1的消息“B”和“A”之后发出检查点屏障。检查点障碍用于对齐所有操作员任务的检查点，并保证整个检查点的一致性。消息“A”到达Flink Map Task，而顶级消费者继续读取其下一条记录（消息“C”）。  </p><p><img src="https://www.ververica.com/hs-fs/hubfs/Imported_Blog_Media/2018-10-11-Flink-Kafka-Checkpoints-Step-4.png?width=1684&name=2018-10-11-Flink-Kafka-Checkpoints-Step-4.png" alt="image"></p><h2 id="第5步："><a href="#第5步：" class="headerlink" title="第5步："></a>第5步：</h2><p>此步骤显示Flink Map Task从两个源和检查点接收检查点障碍，其状态为Job Master。与此同时，消费者继续从Kafka分区阅读更多活动。</p><p><img src="https://www.ververica.com/hs-fs/hubfs/Imported_Blog_Media/2018-10-11-Flink-Kafka-Checkpoints-Step-5.png?width=1340&height=696&name=2018-10-11-Flink-Kafka-Checkpoints-Step-5.png" alt="image"></p><h2 id="第6步："><a href="#第6步：" class="headerlink" title="第6步："></a>第6步：</h2><p>此步骤显示Flink Map Task在检查其状态后与Flink Job Master进行通信。当作业的所有任务确认其状态为检查点时，作业主管完成检查点。从现在开始，检查点可用于从故障中恢复。值得一提的是，Apache Flink不依赖于Kafka偏移来恢复潜在的系统故障。<br><img src="https://www.ververica.com/hs-fs/hubfs/Imported_Blog_Media/2018-10-11-Flink-Kafka-Checkpoints-Step-6.png?width=1342&height=666&name=2018-10-11-Flink-Kafka-Checkpoints-Step-6.png" alt="image"></p><p><strong>在发生故障时恢复</strong></p><p>如果发生故障（例如，工作人员故障），则重新启动所有操作员任务，并将其状态重置为上次完成的检查点。如下图所示。<br><img src="https://www.ververica.com/hs-fs/hubfs/Imported_Blog_Media/2018-10-11-Flink-Kafka-Checkpoints-Step-8.png?width=1340&height=652&name=2018-10-11-Flink-Kafka-Checkpoints-Step-8.png" alt="image"></p><p>Kafka源分别从偏移量2和1开始，因为这是完成的检查点的偏移量。当作业重新启动时，我们可以期待正常的系统操作，就好像之前没有发生故障一样。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在我们Flink Friday Tip的这一集中，我们将逐步说明Apache Flink如何与Apache Kafka协同工作，以确保Kafka主题的记录以一次性保证进行处理。&lt;/p&gt;
&lt;p&gt;检查点是Apache Flink的内部机制，可以从故障中恢复。检查点是Flink应
      
    
    </summary>
    
      <category term="实用技术" scheme="http://ellenadams.github.io/categories/%E5%AE%9E%E7%94%A8%E6%8A%80%E6%9C%AF/"/>
    
      <category term="Flink" scheme="http://ellenadams.github.io/categories/%E5%AE%9E%E7%94%A8%E6%8A%80%E6%9C%AF/Flink/"/>
    
    
      <category term="flink" scheme="http://ellenadams.github.io/tags/flink/"/>
    
      <category term="kafka" scheme="http://ellenadams.github.io/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>flink on yarn 部署</title>
    <link href="http://ellenadams.github.io/2019/07/27/flinkCluster/"/>
    <id>http://ellenadams.github.io/2019/07/27/flinkCluster/</id>
    <published>2019-07-27T01:52:16.389Z</published>
    <updated>2019-07-27T01:52:16.389Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、部署说明"><a href="#一、部署说明" class="headerlink" title="一、部署说明"></a>一、部署说明</h2><hr><p>flink是apache一款大数据实时计算应用，在生产环境中，用来实时计算应用产生的日志，数据等，满足预警，入库等需求</p><hr><h2 id="二、系统环境"><a href="#二、系统环境" class="headerlink" title="二、系统环境"></a>二、系统环境</h2><ul><li>系统版本：centos 7.2</li><li>java版本: jdk 1.8.0_161</li><li>zookeeper版本: zookeeper-3.4.9</li><li>hadoop版本： Hadoop-2.8.3.tar.gz</li><li>flink版本： flink-1.4.0</li></ul><blockquote><p> 四个机器，其中192.168.3.60作为flink 的master，也就是jobmanager，其它三个机器作为taskmanager</p></blockquote><h2 id="三、准备部署"><a href="#三、准备部署" class="headerlink" title="三、准备部署"></a>三、准备部署</h2><h3 id="1、关闭selinux"><a href="#1、关闭selinux" class="headerlink" title="1、关闭selinux"></a>1、关闭selinux</h3><p><code>sed ‘s/SELINUX=enforcing/SELINUX=disabled/‘ /etc/selinux/config</code></p><h3 id="2、关闭防火墙"><a href="#2、关闭防火墙" class="headerlink" title="2、关闭防火墙"></a>2、关闭防火墙</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">firewall-cmd --state #查看防火墙状态</span><br><span class="line">systemctl stop firewalld.service  #停用firewall</span><br><span class="line">systemctl disable firewalld.service #禁止防火墙开机启动</span><br><span class="line">init 6  #重启主机，然后再输入第一条命令查看防火墙状态</span><br></pre></td></tr></table></figure><h3 id="3、安装jdk1-8"><a href="#3、安装jdk1-8" class="headerlink" title="3、安装jdk1.8"></a>3、安装jdk1.8</h3><p>  由于centos7.2自带jdk，但是是sun公司的jdk，一般我们都是用自己的jdk包，所以先卸载</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rpm -qa | grep java | xargs rpm -e --nodeps</span><br><span class="line">#根据java关键词找出对应包，然后卸载</span><br></pre></td></tr></table></figure><h3 id="4、创建普通用户以及设置应用目录"><a href="#4、创建普通用户以及设置应用目录" class="headerlink" title="4、创建普通用户以及设置应用目录"></a>4、创建普通用户以及设置应用目录</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /app/appflink #创建用户目录</span><br><span class="line">useradd -d /app/appflink appflink</span><br><span class="line">passed appflink  #设置密码</span><br></pre></td></tr></table></figure><h3 id="5、以普通用户上传程序包到上面配置的用户目录，配置变量"><a href="#5、以普通用户上传程序包到上面配置的用户目录，配置变量" class="headerlink" title="5、以普通用户上传程序包到上面配置的用户目录，配置变量"></a>5、以普通用户上传程序包到上面配置的用户目录，配置变量</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cd /app/appflink</span><br><span class="line">tar zxvf jdk-8u101-linux-x64.tar.gz #解压到用户目录</span><br><span class="line">vi vi ~/.bash_profile</span><br><span class="line">配置如下:</span><br><span class="line"> export PS1=&apos;[\u@\h \w]&apos;</span><br><span class="line"> export JAVA_HOME=/app/appflink/jdk1.8.0_101</span><br><span class="line"> export JRE_HOME=$&#123;JAVA_HOME&#125;/jre</span><br><span class="line"> export CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/lib</span><br><span class="line"> export PATH=$&#123;JAVA_HOME&#125;/bin:$PATH</span><br></pre></td></tr></table></figure><h3 id="6、配置master免密码登陆其余机器"><a href="#6、配置master免密码登陆其余机器" class="headerlink" title="6、配置master免密码登陆其余机器"></a>6、配置master免密码登陆其余机器</h3><p>  CentOS默认没有启动ssh无密登录，去掉/etc/ssh/sshd_config其中2行的注释，每台服务器都要设置，</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">RSAAuthentication yes</span><br><span class="line">PubkeyAuthentication yes</span><br></pre></td></tr></table></figure><p>  输入命令，ssh-keygen -t rsa，生成key，都不输入密码，一直回车，在用户根目录就会生成.ssh文件夹，每台服务器都要设置<br>  进入用户根目录下面的认证文件夹</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cd ~/.ssh/</span><br><span class="line">#合并公钥到authorized_keys文件，在flink-master服务器，通过SSH命令合并</span><br><span class="line">cat id_rsa.pub&gt;&gt; authorized_keys</span><br><span class="line">ssh appflink@192.168.3.61 cat ~/.ssh/id_rsa.pub&gt;&gt; authorized_keys</span><br><span class="line">ssh appflink@192.168.3.62 cat ~/.ssh/id_rsa.pub&gt;&gt; authorized_keys</span><br><span class="line">ssh appflink@192.168.3.63 cat ~/.ssh/id_rsa.pub&gt;&gt; authorized_keys</span><br></pre></td></tr></table></figure><h2 id="四、部署zookeeper集群"><a href="#四、部署zookeeper集群" class="headerlink" title="四、部署zookeeper集群"></a>四、部署zookeeper集群</h2><p>  这里我们使用，192.168.3.61, 192.168.3.62, 192.168.3.63</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">cd ./bin/zookeeper-3.4.9/conf    #这里进入配置目录</span><br><span class="line">   mv zoo_sample.cfg zoo.cfg</span><br><span class="line">  #修改主要配置，</span><br><span class="line">  dataDir=/app/appflink/bin/zookeeper-3.4.9/data</span><br><span class="line">  dataLogDir=/app/appflink/bin/zookeeper-3.4.9/log</span><br><span class="line"></span><br><span class="line">  #最后一行添加，使用三个机器组合集群</span><br><span class="line">  server.1=flink-slave1:2888:3888</span><br><span class="line">  server.2=flink-slave2:2888:3888</span><br><span class="line">  server.3=flink-slave3:2888:3888</span><br><span class="line"></span><br><span class="line">  #修改hosts,ip和主机名自定义</span><br><span class="line">  cat /etc/hosts</span><br><span class="line">  192.168.3.60 flink-master</span><br><span class="line">  192.168.3.61 flink-slave1</span><br><span class="line">  192.168.3.62 flink-slave2</span><br><span class="line">  192.168.3.63 flink-slave3</span><br><span class="line"></span><br><span class="line">  #创建数据目录，日志目录，写入自身id</span><br><span class="line">  mkdir -p /app/appflink/bin/zookeeper-3.4.9/data</span><br><span class="line">  mkdir -p /app/appflink/bin/zookeeper-3.4.9/log</span><br><span class="line">  vi /app/appflink/bin/zookeeper-3.4.9/data/myid</span><br><span class="line">  #这里id要注意，要和zoo.cfg配置里的1，2，3对应，然后分别写入1，2，3，内容就一个id就好了</span><br><span class="line"></span><br><span class="line">  #启动zookeeper,三个机器依次启动</span><br><span class="line">  cd /app/appflink/bin/zookeeper-3.4.9/bin</span><br><span class="line">  ./zkServer.sh start</span><br><span class="line">  ./zkServer.sh status  #查看状态，正常情况下，应该是flower或者leader</span><br></pre></td></tr></table></figure><h2 id="五、部署hadoop"><a href="#五、部署hadoop" class="headerlink" title="五、部署hadoop"></a>五、部署hadoop</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">修改hadoop配置文件</span><br><span class="line">  vi hadoop-env.sh</span><br><span class="line">  在25位置，配置如下</span><br><span class="line">  export JAVA_HOME=/app/appflink/jdk1.8.0_101</span><br><span class="line"></span><br><span class="line">  创建hadoop需要的目录</span><br><span class="line">  mkdir -p /app/appflink/data/hadoop/hdfs/name</span><br><span class="line">  mkdir -p /app/appflink/data/hadoop/hdfs/data</span><br><span class="line">  mkdir -p /app/appflink/data/hadoop/tmp</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br></pre></td><td class="code"><pre><span class="line">vi hdfs-site.xml</span><br><span class="line">  配置如下:</span><br><span class="line">&lt;property&gt;</span><br><span class="line">   &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</span><br><span class="line">   &lt;value&gt;file:/app/appflink/data/hadoop/hdfs/name&lt;/value&gt;</span><br><span class="line">   &lt;!--HDFS namenode数据镜象目录--&gt;</span><br><span class="line">   &lt;description&gt;  &lt;/description&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;file:/app/appflink/data/hadoop/hdfs/data&lt;/value&gt;</span><br><span class="line">  &lt;!-- HDFS datanode数据镜象存储路径,可以配置多个不同的分区和磁盘中,使用,号分隔 --&gt;</span><br><span class="line">  &lt;description&gt; &lt;/description&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.namenode.http-address&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;flink-master:50070&lt;/value&gt;</span><br><span class="line">  &lt;!---HDFS Web查看主机和端口--&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;flink-master:50090&lt;/value&gt;</span><br><span class="line">  &lt;!--辅控HDFS web查看主机和端口--&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;3&lt;/value&gt;</span><br><span class="line">  &lt;!--HDFS数据保存份数，通常是3--&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.datanode.du.reserved&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;1073741824&lt;/value&gt;</span><br><span class="line">  &lt;!-- datanode 写磁盘会预留 1G空间 给其他程序使用,而非写满,单位 bytes--&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.block.size&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;134217728&lt;/value&gt;</span><br><span class="line">  &lt;!--HDFS数据块大小，当前设置为128M/Blocka--&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.permissions.enabled&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;false&lt;/value&gt;</span><br><span class="line">  &lt;!-- HDFS 关闭文件权限 --&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  //vi cre-site.xml</span><br><span class="line">  配置内容如下</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">  &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;hdfs://flink-master:9000&lt;/value&gt;</span><br><span class="line">  &lt;!--hadoop namenode 服务器地址和端口，以域名形式--&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.namenode.checkpoint.period&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;1800&lt;/value&gt;</span><br><span class="line">  &lt;!-- editlog每隔30分钟触发一次合并，默认为60分钟 --&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;property&gt;</span><br><span class="line">  &lt;name&gt;fs.checkpoint.size&lt;/name&gt;</span><br><span class="line"> &lt;value&gt;67108864&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;property&gt;</span><br><span class="line">  &lt;name&gt;fs.trash.interval&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;1440&lt;/value&gt;</span><br><span class="line">  &lt;!-- Hadoop文件回收站,自动回收时间,单位分钟,这里设置是1天，默认为0。--&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;property&gt;</span><br><span class="line"> &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;file:/app/appflink/data/hadoop/tmp&lt;/value&gt;</span><br><span class="line">  &lt;!-- Hadoop的默认临时路径，这个最好配置，如果在新增节点或者其他情况下莫名其妙的DataNode启动不了，就删除此文件中的tmp目录即可。不过如果删除了NameNode机器的此目录，那么就需要重新执行NameNode格式化的命令。/data/hadoop/tmp这里给的路径不需要创建会自动生成.--&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;property&gt;</span><br><span class="line">  &lt;name&gt;io.file.buffer.size&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;131702&lt;/value&gt;</span><br><span class="line">  &lt;!-- 流文件的缓冲区--&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  配置mapred-site.xml</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">      &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  配置yarn-site.xml,内容如下</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;flink-master:18040&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;flink-master:18030&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;flink-master:18088&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;flink-master:18025&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;flink-master:18141&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br></pre></td></tr></table></figure><p>  配置hadoop环境变量</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">set hadoop path</span><br><span class="line">  #添加如下配置</span><br><span class="line">  export HADOOP_HOME=/app/appflink/hadoop-2.8.3</span><br><span class="line">  export PATH=$PATH:$HADOOP_HOME/bin</span><br><span class="line"></span><br><span class="line">  #确认生效</span><br><span class="line">  cd /app/appflink/hadoop-2.8.3/etc/hadoop</span><br><span class="line">  source hadoop-env.sh</span><br><span class="line">  hadoop Version</span><br><span class="line">  #格式化数据目录，只需要一次，下次启动不再需要格式化，只需start-all.sh</span><br><span class="line">  hadoop namenode -format</span><br><span class="line"></span><br><span class="line">  #启动hadoop</span><br><span class="line">  cd /app/appflink/hadoop-2.8.3/sbin</span><br><span class="line">  ./start-all.sh</span><br><span class="line">  #使用jsp查看进程是否都启动了，然后我们可以登陆web控制台创建目录节点</span><br></pre></td></tr></table></figure><h2 id="六、搭建flink集群"><a href="#六、搭建flink集群" class="headerlink" title="六、搭建flink集群"></a>六、搭建flink集群</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">#编辑flink-conf.yaml文件</span><br><span class="line">vi flink-conf.yaml</span><br><span class="line">#主要内容如下:</span><br><span class="line">jobmanager.rpc.address: 192.168.3.60   #job进程监听的地址</span><br><span class="line">fs.hdfs.hadoopconf: /app/flink/hadoop/conf/ #高可用时候，hadoop配置地址</span><br><span class="line">high-availability: zookeeper     #使用zk实现高可用</span><br><span class="line">#下面两个目录需要在hadoop上面创建，分别是/flinkshare/ha, /ZooKeeper/ha</span><br><span class="line">high-availability.storageDir: hdfs://flink-master:9000/flinkshare/ha/</span><br><span class="line">recovery.zookeeper.storageDir: hdfs://flink-master:9000/ZooKeeper/ha/</span><br><span class="line">#通过zk来选举</span><br><span class="line">high-availability.zookeeper.quorum: flink-slave1:2181,flink-slave2:2181,flink-slave3:2181</span><br><span class="line"></span><br><span class="line">#编辑master文件，写入两个机器ip和端口</span><br><span class="line">192.168.3.60:8081</span><br><span class="line">192.168.3.61:8081</span><br><span class="line"></span><br><span class="line">#编辑slaves文件，写入所有task进程机器</span><br><span class="line">flink-slave1</span><br><span class="line">flink-slave2</span><br><span class="line">flink-slave3</span><br><span class="line"></span><br><span class="line">#编辑zoo.cfg,将机器列表填入</span><br><span class="line">server.1=flink-slave1:2888:3888</span><br><span class="line">server.2=flink-slave2:2888:3888</span><br><span class="line">server.3=flink-slave3:2888:3888</span><br><span class="line"></span><br><span class="line">#将文件通过scp拷贝到其它机器</span><br><span class="line">scp -r /app/appflink/bin/flink-1.4.0 appflink@192.168.3.61:/app/appflink/bin/</span><br><span class="line">scp -r /app/appflink/bin/flink-1.4.0 appflink@192.168.3.62:/app/appflink/bin/</span><br><span class="line">scp -r /app/appflink/bin/flink-1.4.0 appflink@192.168.3.63:/app/appflink/bin/</span><br><span class="line"></span><br><span class="line">#接下来，启动flink集群</span><br><span class="line"></span><br><span class="line">cd /app/appflink/bin/flink-1.4.0/bin</span><br><span class="line">./start-cluster.sh cluster start</span><br><span class="line"></span><br><span class="line">#登陆web控制台，http://192.168.3.60:8081,正常情况下，就能看到3个taskmanager，2个jobmanager</span><br><span class="line">#为了验证高可用，可以随便结束一个jobmanager进程，看看是不是都能访问</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;一、部署说明&quot;&gt;&lt;a href=&quot;#一、部署说明&quot; class=&quot;headerlink&quot; title=&quot;一、部署说明&quot;&gt;&lt;/a&gt;一、部署说明&lt;/h2&gt;&lt;hr&gt;
&lt;p&gt;flink是apache一款大数据实时计算应用，在生产环境中，用来实时计算应用产生的日志，数据等，
      
    
    </summary>
    
      <category term="实用技术" scheme="http://ellenadams.github.io/categories/%E5%AE%9E%E7%94%A8%E6%8A%80%E6%9C%AF/"/>
    
      <category term="Flink" scheme="http://ellenadams.github.io/categories/%E5%AE%9E%E7%94%A8%E6%8A%80%E6%9C%AF/Flink/"/>
    
    
      <category term="flink" scheme="http://ellenadams.github.io/tags/flink/"/>
    
      <category term="yarn" scheme="http://ellenadams.github.io/tags/yarn/"/>
    
  </entry>
  
  <entry>
    <title>flink on yarn 部署</title>
    <link href="http://ellenadams.github.io/2019/07/27/flinkOnYarn/"/>
    <id>http://ellenadams.github.io/2019/07/27/flinkOnYarn/</id>
    <published>2019-07-27T01:50:59.536Z</published>
    <updated>2019-07-27T01:50:59.536Z</updated>
    
    <content type="html"><![CDATA[<p>flink on yarn需要的组件与版本如下</p><ol><li>Zookeeper 3.4.9 用于做Flink的JobManager的HA服务</li><li>hadoop 2.7.2 搭建HDFS和Yarn</li><li>flink 1.3.2 或者 1.4.1版本（scala 2.11）</li></ol><p>Zookeeper, HDFS 和 Yarn 的组件的安装可以参照网上的教程。</p><p>在zookeeper，HDFS 和Yarn的组件的安装好的前提下，在客户机上提交Flink任务，具体流程如下：</p><ul><li><p>在启动Yarn-Session 之前， 设置好HADOOP_HOME,YARN_CONF_DIR ， HADOOP_CONF_DIR环境变量中三者的一个。如下所示， 根据具体的hadoop 路径来设置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ export HADOOP_HOME=/usr/local/hadoop-current</span><br></pre></td></tr></table></figure></li><li><p>配置flink 目录下的flink-conf.yaml, 如下所示</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">jobmanager.rpc.address:</span> <span class="string">localhost</span></span><br><span class="line"><span class="string">jobmanager.rpc.port:</span> <span class="number">6123</span></span><br><span class="line"><span class="string">jobmanager.heap.mb:</span> <span class="number">256</span></span><br><span class="line"><span class="string">taskmanager.heap.mb:</span> <span class="number">512</span></span><br><span class="line"><span class="string">taskmanager.numberOfTaskSlots:</span> <span class="number">1</span></span><br><span class="line"><span class="string">taskmanager.memory.preallocate:</span> <span class="literal">false</span></span><br><span class="line"><span class="string">parallelism.default:</span> <span class="number">1</span></span><br><span class="line"><span class="string">jobmanager.web.port:</span> <span class="number">8081</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># yarn</span></span><br><span class="line"><span class="string">yarn.maximum-failed-containers:</span> <span class="number">99999</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#akka config</span></span><br><span class="line"><span class="string">akka.watch.heartbeat.interval:</span> <span class="number">5</span> <span class="string">s</span></span><br><span class="line"><span class="string">akka.watch.heartbeat.pause:</span> <span class="number">20</span> <span class="string">s</span></span><br><span class="line"><span class="string">akka.ask.timeout:</span> <span class="number">60</span> <span class="string">s</span></span><br><span class="line"><span class="string">akka.framesize:</span> <span class="number">20971520</span><span class="string">b</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#high-avaliability</span></span><br><span class="line"><span class="attr">high-availability:</span> <span class="string">zookeeper</span></span><br><span class="line"><span class="comment">## 根据安装的zookeeper信息填写</span></span><br><span class="line"><span class="string">high-availability.zookeeper.quorum:</span> <span class="number">10.141</span><span class="number">.61</span><span class="number">.226</span><span class="string">:2181,10.141.53.244:2181,10.141.18.219:2181</span></span><br><span class="line"><span class="string">high-availability.zookeeper.path.root:</span> <span class="string">/flink</span></span><br><span class="line"><span class="comment">## HA 信息存储到HDFS的目录，根据各自的Hdfs情况修改</span></span><br><span class="line"><span class="string">high-availability.zookeeper.storageDir:</span> <span class="attr">hdfs://hdcluster/flink/recovery/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#checkpoint config</span></span><br><span class="line"><span class="string">state.backend:</span> <span class="string">rocksdb</span></span><br><span class="line"><span class="comment">## checkpoint到HDFS的目录 根据各自安装的HDFS情况修改</span></span><br><span class="line"><span class="string">state.backend.fs.checkpointdir:</span> <span class="attr">hdfs://hdcluster/flink/checkpoint</span></span><br><span class="line"><span class="comment">## 对外checkpoint到HDFS的目录</span></span><br><span class="line"><span class="string">state.checkpoints.dir:</span> <span class="attr">hdfs://hdcluster/flink/savepoint</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#memory config</span></span><br><span class="line"><span class="string">env.java.opts:</span> <span class="attr">-XX:+UseConcMarkSweepGC</span> <span class="attr">-XX:CMSInitiatingOccupancyFraction=75</span> <span class="attr">-XX:+UseCMSInitiatingOccupancyOnly</span> <span class="attr">-XX:+AlwaysPreTouch</span> <span class="bullet">-server</span> <span class="attr">-XX:+HeapDumpOnOutOfMemoryError</span></span><br><span class="line"><span class="string">yarn.heap-cutoff-ratio:</span> <span class="number">0.2</span></span><br><span class="line"><span class="string">taskmanager.memory.off-heap:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure></li><li><p>提交Yarn-Session，切换到flink的bin 目录下,提交命令如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ./yarn-session.sh -n 2 -s 6 -jm 3072 -tm 6144 -nm test -d</span><br></pre></td></tr></table></figure></li></ul><p>启动yarn-session的参数解释如下</p><table><thead><tr><th>参数</th><th>参数解释</th><th>设置推荐</th></tr></thead><tbody><tr><td>-n(–container)</td><td>taskmanager的数量</td><td></td></tr><tr><td>-s(–slots)</td><td>用启动应用所需的slot数量/ -s 的值向上取整，有时可以多一些taskmanager，做冗余 每个taskmanager的slot数量，默认一个slot一个core，默认每个taskmanager的slot的个数为1</td><td>6～10</td></tr><tr><td>-jm</td><td>jobmanager的内存（单位MB)</td><td>3072</td></tr><tr><td>-tm</td><td>每个taskmanager的内存（单位MB)</td><td>根据core 与内存的比例来设置，-s的值＊ （core与内存的比）来算</td></tr><tr><td>-nm</td><td>yarn 的appName(现在yarn的ui上的名字)｜</td><td></td></tr><tr><td>-d</td><td>后台执行</td><td></td></tr></tbody></table><ul><li>提交yarn－session 后，可以在yarn的ui上看到一个应用（应用有一个appId）, 切换到flink的bin目录下，提交flink 应用。命令如下<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ./flink -run file:///home/yarn/test.jar -a 1 -p 12 -yid appId -nm flink-test -d</span><br></pre></td></tr></table></figure></li></ul><p>启动flink 应用的参数解释如下</p><table><thead><tr><th>参数</th><th>参数解释</th></tr></thead><tbody><tr><td>-j</td><td>运行flink 应用的jar所在的目录</td></tr><tr><td>-a</td><td>运行flink 应用的主方法的参数</td></tr><tr><td>-p</td><td>运行flink应用的并行度</td></tr><tr><td>-c</td><td>运行flink应用的主类, 可以通过在打包设置主类</td></tr><tr><td>-nm</td><td>flink 应用名字，在flink-ui 上面展示</td></tr><tr><td>-d</td><td>后台执行</td></tr><tr><td>–fromsavepoint</td><td>flink 应用启动的状态恢复点</td></tr></tbody></table><ul><li>启动flink应用成功，即可在yarn ui 点击对应应用的ApplicationMaster链接,既可以查看flink-ui ，并查看flink 应用运行情况。</li></ul><p>注：在安装部署遇到任何问题，可以在小象问答，微信群以及私聊提出，我们一般会在晚上作答（由于白天要上班，作答不及时请谅解。）</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;flink on yarn需要的组件与版本如下&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Zookeeper 3.4.9 用于做Flink的JobManager的HA服务&lt;/li&gt;
&lt;li&gt;hadoop 2.7.2 搭建HDFS和Yarn&lt;/li&gt;
&lt;li&gt;flink 1.3.2 或者 1
      
    
    </summary>
    
      <category term="实用技术" scheme="http://ellenadams.github.io/categories/%E5%AE%9E%E7%94%A8%E6%8A%80%E6%9C%AF/"/>
    
      <category term="Flink" scheme="http://ellenadams.github.io/categories/%E5%AE%9E%E7%94%A8%E6%8A%80%E6%9C%AF/Flink/"/>
    
    
      <category term="flink" scheme="http://ellenadams.github.io/tags/flink/"/>
    
      <category term="yarn" scheme="http://ellenadams.github.io/tags/yarn/"/>
    
  </entry>
  
  <entry>
    <title>Flink Java Opts设置详解</title>
    <link href="http://ellenadams.github.io/2019/07/27/flinkOpt/"/>
    <id>http://ellenadams.github.io/2019/07/27/flinkOpt/</id>
    <published>2019-07-27T01:47:43.318Z</published>
    <updated>2019-07-27T01:47:43.318Z</updated>
    
    <content type="html"><![CDATA[<h1 id="设置Java-Opts"><a href="#设置Java-Opts" class="headerlink" title="设置Java Opts"></a>设置Java Opts</h1><ul><li><p>可以手动设置环境变量JAVA_HOME或配置项env.java.home中conf/flink-conf.yaml，如果你想手动覆盖Java运行时使用。</p></li><li><p>所有配置都已完成conf/flink-conf.yaml，预计将是具有格式的YAML键值对的扁平集合key: value。</p></li><li><p>系统和运行脚本在启动时解析配置。对配置文件的更改需要重新启动Flink JobManager和TaskManagers。TaskManagers的配置文件可能不同，Flink不承担集群中的统一机器。</p></li></ul><h2 id="1-flink-conf-yaml"><a href="#1-flink-conf-yaml" class="headerlink" title="1.flink-conf.yaml"></a>1.flink-conf.yaml</h2><ul><li>flink-conf.yaml中设置：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">env.java.opts: -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=75 -XX:+UseCMSInitiatingOccupancyOnly -XX:+AlwaysPreTouch -server -XX:+HeapDumpOnOutOfMemoryError</span><br></pre></td></tr></table></figure></li></ul><h2 id="2-flink启动脚本"><a href="#2-flink启动脚本" class="headerlink" title="2.flink启动脚本"></a>2.flink启动脚本</h2><ul><li><p>jvm相关参数：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">堆设置</span><br><span class="line">-Xms :初始堆大小</span><br><span class="line">-Xmx :最大堆大小</span><br><span class="line">-XX:NewSize=n :设置年轻代大小</span><br><span class="line">-XX:NewRatio=n: 设置年轻代和年老代的比值。如:为3，表示年轻代与年老代比值为1：3，年轻代占整个年轻代年老代和的1/4</span><br><span class="line">-XX:SurvivorRatio=n :年轻代中Eden区与两个Survivor区的比值。注意Survivor区有两个。如：3，表示Eden：Survivor=3：2，一个Survivor区占整个年轻代的1/5</span><br><span class="line">-XX:MaxPermSize=n :设置持久代大小</span><br><span class="line">收集器设置</span><br><span class="line">-XX:+UseSerialGC :设置串行收集器</span><br><span class="line">-XX:+UseParallelGC :设置并行收集器</span><br><span class="line">-XX:+UseParalledlOldGC :设置并行年老代收集器</span><br><span class="line">-XX:+UseConcMarkSweepGC :设置并发收集器</span><br><span class="line">垃圾回收统计信息</span><br><span class="line">-XX:+PrintHeapAtGC GC的heap详情</span><br><span class="line">-XX:+PrintGCDetails  GC详情</span><br><span class="line">-XX:+PrintGCTimeStamps  打印GC时间信息</span><br><span class="line">-XX:+PrintTenuringDistribution    打印年龄信息等</span><br><span class="line">-XX:+HandlePromotionFailure   老年代分配担保（true  or false）</span><br><span class="line">并行收集器设置</span><br><span class="line">-XX:ParallelGCThreads=n :设置并行收集器收集时使用的CPU数。并行收集线程数。</span><br><span class="line">-XX:MaxGCPauseMillis=n :设置并行收集最大暂停时间</span><br><span class="line">-XX:GCTimeRatio=n :设置垃圾回收时间占程序运行时间的百分比。公式为1/(1+n)</span><br><span class="line">并发收集器设置</span><br><span class="line">-XX:+CMSIncrementalMode :设置为增量模式。适用于单CPU情况。</span><br><span class="line">-XX:ParallelGCThreads=n :设置并发收集器年轻代收集方式为并行收集时，使用的CPU数。并行收集线程数</span><br></pre></td></tr></table></figure></li><li><p>flink启动脚本:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">./flink-1.2.0/bin/flink run -m yarn-cluster -yn 4 -yjm 2048 -ytm 8086 -c beam.count.OpsCount -yqu data-default \</span><br><span class="line">-yD taskmanager.heap.size=4096 -yD yarn.heap-cutoff-ratio=0.6 -yD taskmanager.debug.memory.startLogThread=true -yD taskmanager.debug.memory.logIntervalMs=600000 \</span><br><span class="line">-yz toratest -yst -yd ./beampoc-bundled-0.0.1-SNAPSHOT.jar --parallelism=4</span><br><span class="line">-yD env.java.opts=&quot;-XX:NewRatio=2&quot;</span><br></pre></td></tr></table></figure></li><li><p>默认flink 4container slot4 的jmap输出:</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">Heap Configuration:</span><br><span class="line">   MinHeapFreeRatio         = 0</span><br><span class="line">   MaxHeapFreeRatio         = 100</span><br><span class="line">   MaxHeapSize              = 2359296000 (2250.0MB)</span><br><span class="line">   NewSize                  = 786432000 (750.0MB)</span><br><span class="line">   MaxNewSize               = 786432000 (750.0MB)</span><br><span class="line">   OldSize                  = 1572864000 (1500.0MB)</span><br><span class="line">   NewRatio                 = 2</span><br><span class="line">   SurvivorRatio            = 8</span><br><span class="line">   MetaspaceSize            = 21807104 (20.796875MB)</span><br><span class="line">   CompressedClassSpaceSize = 1073741824 (1024.0MB)</span><br><span class="line">   MaxMetaspaceSize         = 17592186044415 MB</span><br><span class="line">   G1HeapRegionSize         = 0 (0.0MB)</span><br><span class="line"></span><br><span class="line">Heap Usage:</span><br><span class="line">PS Young Generation</span><br><span class="line">Eden Space:</span><br><span class="line">   capacity = 476053504 (454.0MB)</span><br><span class="line">   used     = 224818576 (214.40370178222656MB)</span><br><span class="line">   free     = 251234928 (239.59629821777344MB)</span><br><span class="line">   47.225484974058716% used</span><br><span class="line">From Space:</span><br><span class="line">   capacity = 101187584 (96.5MB)</span><br><span class="line">   used     = 85147536 (81.20301818847656MB)</span><br><span class="line">   free     = 16040048 (15.296981811523438MB)</span><br><span class="line">   84.14820537665965% used</span><br><span class="line">To Space:</span><br><span class="line">   capacity = 155189248 (148.0MB)</span><br><span class="line">   used     = 0 (0.0MB)</span><br><span class="line">   free     = 155189248 (148.0MB)</span><br><span class="line">   0.0% used</span><br><span class="line">PS Old Generation</span><br><span class="line">   capacity = 1572864000 (1500.0MB)</span><br><span class="line">   used     = 922110224 (879.3928375244141MB)</span><br><span class="line">   free     = 650753776 (620.6071624755859MB)</span><br><span class="line">   58.62618916829427% used</span><br><span class="line"></span><br><span class="line">22206 interned Strings occupying 2255248 bytes.</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;设置Java-Opts&quot;&gt;&lt;a href=&quot;#设置Java-Opts&quot; class=&quot;headerlink&quot; title=&quot;设置Java Opts&quot;&gt;&lt;/a&gt;设置Java Opts&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;可以手动设置环境变量JAVA_HOME或配置项en
      
    
    </summary>
    
      <category term="实用技术" scheme="http://ellenadams.github.io/categories/%E5%AE%9E%E7%94%A8%E6%8A%80%E6%9C%AF/"/>
    
      <category term="Flink" scheme="http://ellenadams.github.io/categories/%E5%AE%9E%E7%94%A8%E6%8A%80%E6%9C%AF/Flink/"/>
    
    
      <category term="flink" scheme="http://ellenadams.github.io/tags/flink/"/>
    
      <category term="java" scheme="http://ellenadams.github.io/tags/java/"/>
    
  </entry>
  
</feed>
